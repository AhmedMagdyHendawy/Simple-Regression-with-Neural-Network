{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Simple_regression_task.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QjlEFdXpMgvw"
      },
      "source": [
        "# Deep learning programming I-A: Regression\n",
        "Felix Wiewel, Institute of Signal Processing and System Theory, University of Stuttgart, 24.04.2020\n",
        "\n",
        "## Introduction\n",
        "This programming exercise is the first of a series of exercises, which are intended as a supplement to the theoretical part of the Deep Learning course offered by the ISS. The goal is to introduce you to basic tasks and applications of methods you have encountered in the lecture. After completing the exercise you should be familiar with the basic ideas and one, possibly simple, way of solving the respective task. It is worth mentioning that most of the tasks can be solved in many different, not necessarily deep learning based, ways and the solution presented here is just one of them.\n",
        "\n",
        "## Regression\n",
        "\n",
        "In this exercise we consider the problem of regression, where we are interested in modeling a functional dependence between different variables with, possibly noisy, observations of input-output pairs. Mathematically such a dependence can be formulated as\n",
        "\n",
        "$\\mathbf{y}=f(\\mathbf{x})+\\boldsymbol{\\epsilon}$,\n",
        "\n",
        "where $\\mathbf{y}\\in\\mathbb{R}^{M}$ and $\\mathbf{x}\\in\\mathbb{R}^{N}$ are the input and output observations, $f:\\mathbb{R}^{N}\\rightarrow\\mathbb{R}^{M}$ is the function mapping inputs to outputs and $\\boldsymbol{\\epsilon}\\in\\mathbb{R}^{M}$ is a random vector, which models noise in our observations. Note that this assumes additive noise that only acts on the output and not on the input variable, which might not be true in all practical applications but is a reasonable approximation. For regression we are now interested in estimating the functional relationship $f$ between the inputs and outputs. This can be done in many different ways, not just with neural networks, but for this exercise we focus on approximating this relationship with a neural network $g_{\\boldsymbol{\\theta}}:\\mathbb{R}^{N}\\rightarrow\\mathbb{R}^{M}$ with parameter vector $\\boldsymbol{\\theta}$. The task is now to choose the parameters of the neural network in a way that results in a \"good\" approximation of $f$ with $g_{\\boldsymbol{\\theta}}$.\n",
        "\n",
        "In order to quantify how \"good\" our neural network can approximate $f$, we adopt a probabilistic view. For this we make the assumption that the noise $\\boldsymbol{\\epsilon}$ is a random vector drawn from a known dustribution, which enables us to derive a suitable cost function for training our neural network and also for quantifying a \"good\" approximation.\n",
        "\n",
        "### Mathematical formulation\n",
        "If we assume that the noise $\\boldsymbol{\\epsilon}$ is drawn from a gaussian distribution, e.g. $\\boldsymbol{\\epsilon}\\sim\\mathcal{N}(\\mathbf{0},\\sigma^{2}\\mathbf{I})$, we can use\n",
        "\n",
        "$\\mathbf{y}=g_{\\boldsymbol{\\theta}}(\\mathbf{x})+\\boldsymbol{\\epsilon}\\Rightarrow \\mathbf{y}-g_{\\boldsymbol{\\theta}}(\\mathbf{x})=\\boldsymbol{\\epsilon}$\n",
        "\n",
        "to derive a log likelihood. Since the probability density function (pdf) of a multivariate normal distribution is given by\n",
        "\n",
        "$p(\\mathbf{x})=\\dfrac{1}{\\sqrt{(2\\pi)^{D}\\vert\\mathbf{C}\\vert}}\\mathrm{e}^{-\\dfrac{1}{2}(\\mathbf{x}-\\boldsymbol{\\mu})\\mathbf{C}^{-1}(\\mathbf{x}-\\boldsymbol{\\mu})^{T}}$,\n",
        "\n",
        "we get\n",
        "\n",
        "$\\ln{p(\\boldsymbol{\\epsilon})}=\\ln{\\dfrac{1}{\\sqrt{(2\\pi)^{M}\\sigma^{2}}}\\mathrm{e}^{-\\dfrac{1}{2\\sigma^{2}}\\Vert\\boldsymbol{\\epsilon}\\Vert_{2}^{2}}}=-\\dfrac{1}{2\\sigma^{2}}\\Vert\\boldsymbol{\\epsilon}\\Vert_{2}^{2}-\\dfrac{1}{2}\\ln{(2\\pi)^{M}\\sigma^{2}}$.\n",
        "\n",
        "Replacing $\\boldsymbol{\\epsilon}$ by $\\mathbf{y}-g_{\\boldsymbol{\\theta}}(\\mathbf{x})$ yields the log likelihood for one particular input-output pair:\n",
        "\n",
        "$\\mathcal{L}(\\mathbf{x},\\mathbf{y},\\boldsymbol{\\theta})=\\ln {p(\\mathbf{y}\\vert\\mathbf{x},\\boldsymbol{\\theta})}=-\\dfrac{1}{2\\sigma^{2}}\\Vert\\boldsymbol{\\mathbf{y}-g_{\\boldsymbol{\\theta}}(\\mathbf{x})}\\Vert_{2}^{2}-\\dfrac{1}{2}\\ln{(2\\pi)^{M}\\sigma^{2}}$\n",
        "\n",
        "This log likelihood measures how likely the input-output pair is and we can use it to train our neural network. For this we maximize the expected log likelihood over all input-output pairs under the assumption that the noise is idependent and identically distributed (i.i.d.) over all input-output pairs. This corresponds to finding the parameters $\\boldsymbol{\\theta}^{\\star}$ of our neural network, which maximize the the expected probability for observing the corresponding input-output pairs. Mathematically the optimal parameters for our neural network are given by\n",
        "\n",
        "$\\boldsymbol{\\theta}^{\\star}=\\arg\\max_{\\boldsymbol{\\theta}}\\mathbb{E}\\left[\\mathcal{L}(\\mathbf{x},\\mathbf{y},\\boldsymbol{\\theta})\\right]=\\arg\\max_{\\boldsymbol{\\theta}}\\mathbb{E}\\left[-\\Vert\\boldsymbol{\\mathbf{y}-g_{\\boldsymbol{\\theta}}(\\mathbf{x})}\\Vert_{2}^{2}\\right]\\approx\\arg\\min_{\\boldsymbol{\\theta}}\\dfrac{1}{N_{D}}\\sum_{i=1}^{N_{D}}\\Vert\\boldsymbol{\\mathbf{y}_{i}-g_{\\boldsymbol{\\theta}}(\\mathbf{x}_{i})}\\Vert_{2}^{2}$,\n",
        "\n",
        "where all terms, which are independent of $\\boldsymbol{\\theta}$, are ignored and the expectation operator is approximated by the mean over all $N_{D}$ input-output pairs. In other words we are maximizing the log likelihood by minimizing the mean squared error loss over all input-output pairs in our dataset, hence this approach is called Maximum Likelihood (ML) estimation. For solving this optimization problem and obtaining the optimal network parameters, stochastic gradient descent (SGD) or one of it's many variants is typically used.\n",
        "\n",
        "It is worth noting, that choosing different distributions for the noise $\\boldsymbol{\\epsilon}$ leads to different log likelihoods and therefore different cost functions for training the neural network. Another commonly used distribution for modelling the noise in regression tasks is the laplace distribution. Deriving the log likelihood and the corresponding costfunction leads to the mean absolute error, which is given by the $l_{1}$-norm of the difference between observations predictions of the neural network. This cost function is considered more robust against outliers since these have less influence on the averall loss compared to the mean squared error.\n",
        "\n",
        "###  Implementation\n",
        "\n",
        "In the following we consider a simple regression task, implement a neural network and train it based on the mathematical fomrulation above. For this we first need to create a set of input-output pairs, which then needs to be partitioned into a training, validation and test set. We also define some constants to be used for partitioning the data and the hyperparameters for our neural network.\n",
        "\n",
        "But before we can start, we need to import the necessary packages tensorflow, numpy and matplotlib."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CPuVp2lyNK2J",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "J84v9uucMgv5"
      },
      "source": [
        "Next we define our constants and set the random seeds of tensorflow and numpy in order to get reproducable results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xwC-1OnHMgv7",
        "colab": {}
      },
      "source": [
        "N_train_samples = 600\n",
        "N_validation_samples = 100\n",
        "N_test_samples = 100\n",
        "N_samples = N_train_samples + N_validation_samples + N_test_samples\n",
        "noise_sig = 0.1\n",
        "N_epochs = 150\n",
        "batch_size = 8\n",
        "learning_rate = 0.01\n",
        "\n",
        "tf.random.set_seed(0)\n",
        "np.random.seed(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ngFFSyG-MgwA"
      },
      "source": [
        "We create $600$ training samples, $100$ validation samples to optimize our hyperparameters and $100$ test samples, which are used to check if our model can generalize to unseen data. Furthermore we set the level of noise added to the observations. For training the model we plan to train it for $150$ epochs with a batch size of $8$ and a learning rate of $0.01$. Next we create the actual input-output pairs $\\mathbf{x},\\mathbf{y}$ for which we want to learn the regression model and plot them. In this simple example we choose scalar inputs as well as output but in general $\\mathbf{x}$ and $\\mathbf{y}$ can be vectors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4s8AtsdQMgwB",
        "outputId": "5f1aabca-1dd3-46f4-857a-a65d306fa5b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "x = np.linspace(0.0, 3.0, N_samples, dtype=np.float32)\n",
        "y = np.expand_dims(np.sin(1.0+x*x) + noise_sig*np.random.randn(N_samples).astype(np.float32), axis=-1)\n",
        "y_true = np.sin(1.0+x*x)\n",
        "\n",
        "plt.plot(x, y)\n",
        "plt.plot(x, y_true)\n",
        "plt.legend([\"Observation\", \"Ground truth\"])\n",
        "plt.show()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Y3wx8vJlMgwI"
      },
      "source": [
        "With the input-output pairs created, your first task is now to partition the data in the training, validation and test sets. Keep in mind that we have created the data in a structured way, i.e. the input-output pairs are ordered. This means you need to shuffle the data before partitioning it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kDIMUZs0MgwK",
        "colab": {}
      },
      "source": [
        "\"\"\" Shuffle and partition the data set accordingly. you can use the predefined constants \"N_train_samples\", \"N_validation_samples\" and \"N_test_samples\". Use the variable names that are already in the below code \n",
        "to store the final shuffled and partitioned data. Hint: Shuffle the data and the labels in such a way that the pairing between an image and it's label is preserved.\"\"\"\n",
        "# Shuffle the data\n",
        "y=y.reshape(-1) # reshape the data to be a vector of 800 datapoints\n",
        "idx = np.random.permutation(x.shape[0])\n",
        "x_shuffled,y_shuffled = x[idx], y[idx]\n",
        "# # Partition the data\n",
        "x_train = x_shuffled[0:N_train_samples]\n",
        "y_train = y_shuffled[0:N_train_samples]\n",
        "x_validation = x_shuffled[N_train_samples:N_train_samples+N_validation_samples]\n",
        "y_validation = y_shuffled[N_train_samples:N_train_samples+N_validation_samples]\n",
        "x_test = x_shuffled[N_train_samples+N_validation_samples:]\n",
        "y_test = y_shuffled[N_train_samples+N_validation_samples:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-ucvKRhOMgwN"
      },
      "source": [
        "In order to feed the data to our model, we will use the Dataset class provided by Tensorflow. This class is simple to use and provides all the functionality we need for shuffling, batching and feeding the data to our model. It is also tightly integrated into the Tensorflow framework, which makes it very performant. Performance is not an aspect we need to worry about in this exercise, but it is important in more demanding applications.\n",
        "\n",
        "In this exercise we instantiate a separate Dataset object for the training, validation and test data sets, where we shuffle and repeat just the training data set. Shuffling the validation and test data sets is not necessary, since we only evaluate the loss on those data sets and do not perform SGD on it. Please fill in the missing part of the code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HifQ63iPMgwP",
        "colab": {}
      },
      "source": [
        "\"\"\" Create three tensorflow Dataset objects that can be used to feed the training test and validation data to a neural network. Hint: For the training data set use shuffling, batching with the size according to\n",
        "the predefined constant \"batch_size\" and repeat the data set indefinetly. For the validation and test data sets no shuffling or batching is needed.\"\"\"\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(x_train.shape[0]).batch(batch_size).repeat()\n",
        "validation_ds = tf.data.Dataset.from_tensor_slices((x_validation, y_validation))\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5Crr6fIkMgwT"
      },
      "source": [
        "In this exercise we will create a a simple neural network with two hidden layers containing $10$ neurons. For creating a model and keeping track of its weights a class called MyModel is used. When initializing an instance of this class the necessary variables are created and stored in a list called \"trainable_variables\". This makes it easy to get all trainable variables of the model. We also override the \\__call__ method of this class in order to implement the forward pass of the neural network. This method should accept the inputs to the neural network and should return the result of the forward pass as an output. Please fill in the missing part of the code and select suitable activation functions for the different layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Nq8ri416MgwX",
        "colab": {}
      },
      "source": [
        "\"\"\" Implement a neural network with two hidden dense layers containing 10 neurons each. As an activation function use the tangens hyperbolicus (tf.nn.tanh()). Since we are not using Keras, we need to create and \n",
        "manage all the variables that we need ourselves. The varaibles are created in the constructor of our model class. Since we want to be able to just call the class with some inputs in order to make a prediction, \n",
        "we implement a __call__ method which computes the forward pass and returns the output of the network.\"\"\"\n",
        "\n",
        "class MyModel(object):\n",
        "    def __init__(self):\n",
        "        # Create model variables\n",
        "        self.W0 = tf.Variable(tf.random.normal([1,10]))\n",
        "        self.b0 = tf.Variable(tf.random.normal([1,10]))\n",
        "        self.W1 = tf.Variable(tf.random.normal([10,10]))\n",
        "        self.b1 = tf.Variable(tf.random.normal([1,10]))\n",
        "        self.W2 = tf.Variable(tf.random.normal([10,1]))\n",
        "        self.b2 = tf.Variable(tf.random.normal([1,1]))\n",
        "        self.trainable_variables = [self.W0, self.b0, self.W1, self.b1, self.W2, self.b2]\n",
        "\n",
        "    def __call__(self, inputs):\n",
        "        # Compute forward pass\n",
        "        output = tf.reshape(inputs, [-1, 1])\n",
        "        output = tf.nn.tanh(tf.add(tf.matmul(output, self.W0), self.b0))\n",
        "        output = tf.nn.tanh(tf.add(tf.matmul(output, self.W1), self.b1))\n",
        "        output = tf.add(tf.matmul(output, self.W2), self.b2)\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uf6m8zXoMgwb"
      },
      "source": [
        "Now after the model class is defined we can instantiate a MyModel object by running"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nSfI8wjLMgwb",
        "colab": {}
      },
      "source": [
        "mdl = MyModel()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KraeH6MsMgwh"
      },
      "source": [
        "We can now use the model to make predictions by calling it. In the following we predict on the inputs an plot the result."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "K1at5RObMgwi",
        "outputId": "24dcab9d-4c65-489a-e219-6a20157731bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "\"\"\" We want to plot a prediction on the complete data set with a model before training. For this make a prediction on the variable \"x\". \"\"\"\n",
        "\n",
        "y_pred = mdl(x)\n",
        "plt.plot(x, y)\n",
        "plt.plot(x, y_true)\n",
        "plt.plot(x, y_pred.numpy())\n",
        "plt.legend([\"Observation\", \"Target\", \"Prediction\"])\n",
        "plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "utFkv4F3NULQ"
      },
      "source": [
        "Since we have initialized the variables of the neural network randomly, it's prediction is also random. In order to fit the model we need to minimize the expected mean squared error over all input-ouput pairs in our training data set. For this we need to create a function, that performs a training step when provided with the model, an optimizer and a batch of input-ouput pairs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o4zFN0-kOdu7",
        "colab": {}
      },
      "source": [
        "\"\"\" For training we need to implement a function that executes one training step. Fill in the missing code pieces for this function.\"\"\"\n",
        "\n",
        "def train_step(model, optimizer, x, y):\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(model.trainable_variables)\n",
        "        y_pred = model(x)\n",
        "        loss_val = tf.reduce_mean(tf.square(y-tf.reshape(y_pred,(-1))))\n",
        "#         loss_val = tf.compat.v1.losses.mean_squared_error(y,tf.reshape(y_pred,(-1)))\n",
        "    grads = tape.gradient(loss_val, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "    return loss_val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ax-Kfd-tOm7I"
      },
      "source": [
        "This function uses the GradientTape to record the operations for which gradients have to be calculated. In our case this is the forward pass through our model and the computation of the loss function. After these operations are recoded we can get their gradients and apply these through the use of an optimizer. Finally we return the loss value in order to print it.\n",
        "\n",
        "With the training step function defined we now need to choose a suitable optimizer. Tensorflow offers a wide variety of optimizers but in this exercise we will use the RMSprop optimizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PahsqMscPcKD",
        "colab": {}
      },
      "source": [
        "opt = tf.optimizers.RMSprop(learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8_WjHrAwQB9e"
      },
      "source": [
        "We now have everything we need to start training the model. For this we repeatedly sample a batch of input-output pairs from our training data set and use the train_step function to minimize the loss function over this batch. We repeat this until we have iterated over the complete training data set once. After this we compute the loss on the validation data set, print it and repeat with another epoch until we have reached $N\\_epochs$ epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "x3LqS3d_QrX6",
        "outputId": "518f5c85-56f3-4fc6-d1b9-91a89996b314",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\"\"\" We can now use the train_step function to perform the training. Fill in the missing code parts.\"\"\"\n",
        "import math\n",
        "epoch = 0\n",
        "train_iters = 0\n",
        "train_loss = 0.0\n",
        "for x_t, y_t in train_ds:\n",
        "    # Perform a training step with the model \"mdl\" and the optimizer \"opt\" on the inputs \"x_t\" and the corresponding targets \"y_t\"\n",
        "    train_loss += train_step(mdl,opt,x_t,y_t)\n",
        "    train_iters += 1\n",
        "    if train_iters == math.ceil(N_train_samples/batch_size):\n",
        "        for x_v, y_v in validation_ds:\n",
        "            y_pred = mdl(x_v)\n",
        "            validation_loss = tf.reduce_mean(tf.square(y_v-tf.reshape(y_pred,(-1))))\n",
        "            # Compute the Mean Squared Error (MSE) for the prediction \"y_pred\" and the targets \"y_v\"\n",
        "        print(\"Epoch: {} Train loss: {:.5} Validation loss: {:.5}\".format(epoch, train_loss/train_iters, validation_loss))\n",
        "        train_iters = 0\n",
        "        train_loss = 0.0\n",
        "        epoch += 1\n",
        "    if (epoch == N_epochs):\n",
        "        break"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 Train loss: 0.53526 Validation loss: 0.063128\n",
            "Epoch: 1 Train loss: 0.1315 Validation loss: 0.0097249\n",
            "Epoch: 2 Train loss: 0.1134 Validation loss: 0.031424\n",
            "Epoch: 3 Train loss: 0.10209 Validation loss: 0.051571\n",
            "Epoch: 4 Train loss: 0.093799 Validation loss: 0.0071331\n",
            "Epoch: 5 Train loss: 0.085293 Validation loss: 0.0097444\n",
            "Epoch: 6 Train loss: 0.072669 Validation loss: 6.7018e-05\n",
            "Epoch: 7 Train loss: 0.064268 Validation loss: 0.00019359\n",
            "Epoch: 8 Train loss: 0.056643 Validation loss: 0.00040506\n",
            "Epoch: 9 Train loss: 0.050579 Validation loss: 0.081008\n",
            "Epoch: 10 Train loss: 0.043914 Validation loss: 0.024142\n",
            "Epoch: 11 Train loss: 0.037956 Validation loss: 0.013204\n",
            "Epoch: 12 Train loss: 0.033816 Validation loss: 0.020166\n",
            "Epoch: 13 Train loss: 0.033564 Validation loss: 0.02109\n",
            "Epoch: 14 Train loss: 0.029883 Validation loss: 0.036454\n",
            "Epoch: 15 Train loss: 0.028353 Validation loss: 0.0042309\n",
            "Epoch: 16 Train loss: 0.026295 Validation loss: 0.0053769\n",
            "Epoch: 17 Train loss: 0.029389 Validation loss: 0.001497\n",
            "Epoch: 18 Train loss: 0.025917 Validation loss: 0.0043619\n",
            "Epoch: 19 Train loss: 0.025997 Validation loss: 0.0038241\n",
            "Epoch: 20 Train loss: 0.023511 Validation loss: 0.0018803\n",
            "Epoch: 21 Train loss: 0.025773 Validation loss: 0.0017691\n",
            "Epoch: 22 Train loss: 0.025421 Validation loss: 0.001023\n",
            "Epoch: 23 Train loss: 0.023637 Validation loss: 0.0031713\n",
            "Epoch: 24 Train loss: 0.022585 Validation loss: 0.00049608\n",
            "Epoch: 25 Train loss: 0.024833 Validation loss: 0.00076764\n",
            "Epoch: 26 Train loss: 0.023953 Validation loss: 5.0264e-06\n",
            "Epoch: 27 Train loss: 0.021975 Validation loss: 0.004112\n",
            "Epoch: 28 Train loss: 0.02381 Validation loss: 0.0096648\n",
            "Epoch: 29 Train loss: 0.022613 Validation loss: 0.0027344\n",
            "Epoch: 30 Train loss: 0.024686 Validation loss: 0.00041729\n",
            "Epoch: 31 Train loss: 0.024355 Validation loss: 0.00054522\n",
            "Epoch: 32 Train loss: 0.021317 Validation loss: 0.0039546\n",
            "Epoch: 33 Train loss: 0.023375 Validation loss: 4.212e-05\n",
            "Epoch: 34 Train loss: 0.024011 Validation loss: 0.00087852\n",
            "Epoch: 35 Train loss: 0.022992 Validation loss: 0.010158\n",
            "Epoch: 36 Train loss: 0.021843 Validation loss: 0.0038642\n",
            "Epoch: 37 Train loss: 0.022457 Validation loss: 4.6076e-05\n",
            "Epoch: 38 Train loss: 0.023681 Validation loss: 0.0019841\n",
            "Epoch: 39 Train loss: 0.02262 Validation loss: 0.00030509\n",
            "Epoch: 40 Train loss: 0.023553 Validation loss: 0.00029602\n",
            "Epoch: 41 Train loss: 0.022665 Validation loss: 0.0014839\n",
            "Epoch: 42 Train loss: 0.024683 Validation loss: 7.9847e-05\n",
            "Epoch: 43 Train loss: 0.021852 Validation loss: 0.0093638\n",
            "Epoch: 44 Train loss: 0.024729 Validation loss: 0.0017604\n",
            "Epoch: 45 Train loss: 0.021192 Validation loss: 0.014008\n",
            "Epoch: 46 Train loss: 0.022113 Validation loss: 0.00038268\n",
            "Epoch: 47 Train loss: 0.023059 Validation loss: 9.9063e-05\n",
            "Epoch: 48 Train loss: 0.023393 Validation loss: 0.0021405\n",
            "Epoch: 49 Train loss: 0.021664 Validation loss: 0.0013091\n",
            "Epoch: 50 Train loss: 0.023927 Validation loss: 0.00083658\n",
            "Epoch: 51 Train loss: 0.022292 Validation loss: 0.0066269\n",
            "Epoch: 52 Train loss: 0.022608 Validation loss: 0.0030579\n",
            "Epoch: 53 Train loss: 0.022922 Validation loss: 0.00048421\n",
            "Epoch: 54 Train loss: 0.023761 Validation loss: 0.0062898\n",
            "Epoch: 55 Train loss: 0.022311 Validation loss: 0.0040587\n",
            "Epoch: 56 Train loss: 0.022942 Validation loss: 0.014797\n",
            "Epoch: 57 Train loss: 0.021457 Validation loss: 0.00097114\n",
            "Epoch: 58 Train loss: 0.022279 Validation loss: 0.0088009\n",
            "Epoch: 59 Train loss: 0.02152 Validation loss: 0.0094743\n",
            "Epoch: 60 Train loss: 0.022449 Validation loss: 0.00088605\n",
            "Epoch: 61 Train loss: 0.021267 Validation loss: 0.00629\n",
            "Epoch: 62 Train loss: 0.021262 Validation loss: 0.0032897\n",
            "Epoch: 63 Train loss: 0.022136 Validation loss: 0.0019978\n",
            "Epoch: 64 Train loss: 0.024223 Validation loss: 0.00049373\n",
            "Epoch: 65 Train loss: 0.021073 Validation loss: 0.0013114\n",
            "Epoch: 66 Train loss: 0.021025 Validation loss: 5.7649e-05\n",
            "Epoch: 67 Train loss: 0.020663 Validation loss: 0.00014492\n",
            "Epoch: 68 Train loss: 0.022545 Validation loss: 0.0001048\n",
            "Epoch: 69 Train loss: 0.019419 Validation loss: 0.0019841\n",
            "Epoch: 70 Train loss: 0.020367 Validation loss: 0.0022084\n",
            "Epoch: 71 Train loss: 0.020944 Validation loss: 0.0024585\n",
            "Epoch: 72 Train loss: 0.021586 Validation loss: 0.0041897\n",
            "Epoch: 73 Train loss: 0.0207 Validation loss: 0.00092874\n",
            "Epoch: 74 Train loss: 0.020916 Validation loss: 0.0090112\n",
            "Epoch: 75 Train loss: 0.019652 Validation loss: 0.0013086\n",
            "Epoch: 76 Train loss: 0.022008 Validation loss: 0.00010508\n",
            "Epoch: 77 Train loss: 0.022771 Validation loss: 0.0040995\n",
            "Epoch: 78 Train loss: 0.023964 Validation loss: 7.55e-05\n",
            "Epoch: 79 Train loss: 0.021921 Validation loss: 0.0014103\n",
            "Epoch: 80 Train loss: 0.021477 Validation loss: 0.00049511\n",
            "Epoch: 81 Train loss: 0.021552 Validation loss: 0.00023469\n",
            "Epoch: 82 Train loss: 0.020854 Validation loss: 2.6248e-05\n",
            "Epoch: 83 Train loss: 0.021612 Validation loss: 0.0010291\n",
            "Epoch: 84 Train loss: 0.019275 Validation loss: 0.0010306\n",
            "Epoch: 85 Train loss: 0.021532 Validation loss: 0.000811\n",
            "Epoch: 86 Train loss: 0.019556 Validation loss: 0.0023149\n",
            "Epoch: 87 Train loss: 0.019758 Validation loss: 0.0024075\n",
            "Epoch: 88 Train loss: 0.020336 Validation loss: 0.00022609\n",
            "Epoch: 89 Train loss: 0.020416 Validation loss: 0.0019478\n",
            "Epoch: 90 Train loss: 0.020502 Validation loss: 0.0057582\n",
            "Epoch: 91 Train loss: 0.020875 Validation loss: 0.00025167\n",
            "Epoch: 92 Train loss: 0.019221 Validation loss: 6.4096e-05\n",
            "Epoch: 93 Train loss: 0.020736 Validation loss: 0.0021021\n",
            "Epoch: 94 Train loss: 0.022283 Validation loss: 0.0013724\n",
            "Epoch: 95 Train loss: 0.019121 Validation loss: 0.00067041\n",
            "Epoch: 96 Train loss: 0.019627 Validation loss: 0.0018917\n",
            "Epoch: 97 Train loss: 0.022441 Validation loss: 0.0079947\n",
            "Epoch: 98 Train loss: 0.022122 Validation loss: 0.010891\n",
            "Epoch: 99 Train loss: 0.020252 Validation loss: 6.7437e-06\n",
            "Epoch: 100 Train loss: 0.021251 Validation loss: 0.0004529\n",
            "Epoch: 101 Train loss: 0.021002 Validation loss: 0.0020123\n",
            "Epoch: 102 Train loss: 0.020672 Validation loss: 5.2493e-05\n",
            "Epoch: 103 Train loss: 0.021517 Validation loss: 0.002127\n",
            "Epoch: 104 Train loss: 0.019469 Validation loss: 0.0011024\n",
            "Epoch: 105 Train loss: 0.021285 Validation loss: 0.0012575\n",
            "Epoch: 106 Train loss: 0.021291 Validation loss: 0.0075055\n",
            "Epoch: 107 Train loss: 0.020456 Validation loss: 0.0014106\n",
            "Epoch: 108 Train loss: 0.020388 Validation loss: 0.0002\n",
            "Epoch: 109 Train loss: 0.019236 Validation loss: 3.091e-05\n",
            "Epoch: 110 Train loss: 0.018994 Validation loss: 0.0056408\n",
            "Epoch: 111 Train loss: 0.021531 Validation loss: 0.00046134\n",
            "Epoch: 112 Train loss: 0.020932 Validation loss: 0.00018552\n",
            "Epoch: 113 Train loss: 0.021661 Validation loss: 0.0057692\n",
            "Epoch: 114 Train loss: 0.020382 Validation loss: 2.3174e-08\n",
            "Epoch: 115 Train loss: 0.021745 Validation loss: 0.00049384\n",
            "Epoch: 116 Train loss: 0.02122 Validation loss: 0.0015152\n",
            "Epoch: 117 Train loss: 0.02096 Validation loss: 0.001204\n",
            "Epoch: 118 Train loss: 0.020826 Validation loss: 0.00071467\n",
            "Epoch: 119 Train loss: 0.020765 Validation loss: 0.0023003\n",
            "Epoch: 120 Train loss: 0.022417 Validation loss: 0.018511\n",
            "Epoch: 121 Train loss: 0.019868 Validation loss: 0.021238\n",
            "Epoch: 122 Train loss: 0.018895 Validation loss: 0.0041662\n",
            "Epoch: 123 Train loss: 0.022089 Validation loss: 0.0085256\n",
            "Epoch: 124 Train loss: 0.021522 Validation loss: 0.013777\n",
            "Epoch: 125 Train loss: 0.020025 Validation loss: 0.0074852\n",
            "Epoch: 126 Train loss: 0.020718 Validation loss: 8.7755e-08\n",
            "Epoch: 127 Train loss: 0.020008 Validation loss: 0.0033737\n",
            "Epoch: 128 Train loss: 0.020803 Validation loss: 0.0012139\n",
            "Epoch: 129 Train loss: 0.019537 Validation loss: 0.0013478\n",
            "Epoch: 130 Train loss: 0.019272 Validation loss: 0.0012813\n",
            "Epoch: 131 Train loss: 0.020561 Validation loss: 0.0011341\n",
            "Epoch: 132 Train loss: 0.020321 Validation loss: 0.0019447\n",
            "Epoch: 133 Train loss: 0.01999 Validation loss: 0.00014017\n",
            "Epoch: 134 Train loss: 0.021423 Validation loss: 0.0015639\n",
            "Epoch: 135 Train loss: 0.020232 Validation loss: 0.0012347\n",
            "Epoch: 136 Train loss: 0.018302 Validation loss: 0.0035642\n",
            "Epoch: 137 Train loss: 0.019863 Validation loss: 4.422e-06\n",
            "Epoch: 138 Train loss: 0.020161 Validation loss: 0.02361\n",
            "Epoch: 139 Train loss: 0.020127 Validation loss: 0.00016743\n",
            "Epoch: 140 Train loss: 0.018865 Validation loss: 4.689e-05\n",
            "Epoch: 141 Train loss: 0.020511 Validation loss: 0.0066065\n",
            "Epoch: 142 Train loss: 0.020017 Validation loss: 0.006815\n",
            "Epoch: 143 Train loss: 0.019598 Validation loss: 5.743e-06\n",
            "Epoch: 144 Train loss: 0.020733 Validation loss: 0.002342\n",
            "Epoch: 145 Train loss: 0.01962 Validation loss: 0.00027782\n",
            "Epoch: 146 Train loss: 0.019534 Validation loss: 2.3746e-05\n",
            "Epoch: 147 Train loss: 0.019397 Validation loss: 0.005407\n",
            "Epoch: 148 Train loss: 0.019147 Validation loss: 0.0028924\n",
            "Epoch: 149 Train loss: 0.019943 Validation loss: 0.0033228\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DduaR_pCQ0k-"
      },
      "source": [
        "After completion of the training process we use the test data set to test the models generalization to unseen data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3ofClNnHRAUy",
        "outputId": "b8294813-2f52-420a-c636-9290ada40553",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "for x_t, y_t in test_ds:\n",
        "    y_pred = mdl(x_t)\n",
        "    # Compute a prediction with \"mdl\" on the input \"x_t\"\n",
        "    test_loss = tf.reduce_mean(tf.square(y_t-tf.reshape(y_pred,(-1))))\n",
        "#     test_loss = tf.compat.v1.losses.mean_squared_error(y_t,tf.reshape(y_pred,(-1)))\n",
        "    # Compute the Mean Squared Error (MSE) for the prediction \"y_pred\" and the targets \"y_t\"\n",
        "print(\"Test loss: {:.5}\".format(test_loss))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.024781\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NzJ7wOZmRbez"
      },
      "source": [
        "After we have verified that our model achieves a similar loss on the test as on the validation and training data set, we can conclude that our model is not overfitting or underfitting and generalizes to unseen data. We can now predict on the inputs again and plot the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tyvFN03bR8ez",
        "outputId": "4093dbf0-6d3f-4a19-ee68-40cac2e4416c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "\"\"\" Now we want to plot the prediction after training. Predict on the variable \"x\" again. \"\"\"\n",
        "\n",
        "y_pred = mdl(x)\n",
        "# Compute a prediction on the variable \"x\"\n",
        "plt.plot(x, y)\n",
        "plt.plot(x, y_true)\n",
        "plt.plot(x, y_pred.numpy())\n",
        "plt.legend([\"Observation\", \"Target\", \"Prediction\"])\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WKmuAAmLSmiR"
      },
      "source": [
        "Now our model has learned to approximate the function mapping from the input to the output. The capability of neural networks to learn from input-ouput pairs alone and approximate an arbitrary function, see universal approximation theorem, can be very useful if the mapping between the input and output is too complex to be captured with model based approaches. But learning from input-ouput pairs alone implies that the model will only be able to make accurate predictions over input ranges it has seen during training. In order to demonstrate this we will predict on an interval that exeeds the $\\left[0,3\\right]$ interval the model was trained on, i.e. we will predict on the interval $\\left[-2,5\\right]$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZRF8hAmmVFcH",
        "outputId": "08c6a89e-12b8-46e0-f39a-bfdf27cd3037",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "x_generalize = np.linspace(-2.0, 5.0, N_samples, dtype=np.float32)\n",
        "y_generalize = np.sin(1.0+x_generalize*x_generalize) + noise_sig*np.random.randn(N_samples).astype(np.float32)\n",
        "y_truey_generalize = np.sin(1.0+x_generalize*x_generalize)\n",
        "y_pred = mdl(x_generalize)\n",
        "plt.plot(x_generalize, y_generalize)\n",
        "plt.plot(x_generalize, y_truey_generalize)\n",
        "plt.plot(x_generalize, y_pred.numpy())\n",
        "plt.legend([\"Observation\", \"Target\", \"Prediction\"])\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "J2yr-0UCVIli"
      },
      "source": [
        "As expected, the model is able to make farely accurate predictions on the interval it was trained on but makes unreliable predictions outside this interval.\n",
        "\n",
        "### Regularization\n",
        "In this section we will explore the concept of regularization. As there is no theorem that can be used to determine the required size and structure of a neural network given a certain task, one has to find a suitable neural architecture by trial and error. This can result in choosing a architecture with a capacity that is higher than required for solving the given task and hence overfitting might occur. A common way to prevent large neural networks networks from overfitting is to employ some sort of regularization, e.g. weight norm penalty, dropout, early stopping and data augmentation. In this section we will focus on weight norm penalty as a regularization and derive a probabilistic interpretation for some of those.\n",
        "\n",
        "We start by restating the conditional probability of the output $\\mathbf{y}$ given the input $\\mathbf{x}$ and the networks parameters $\\boldsymbol{\\theta}$\n",
        "\n",
        "$p(\\mathbf{y}\\vert\\mathbf{x},\\boldsymbol{\\theta})=\\dfrac{1}{\\sqrt{(2\\pi)^{M}\\sigma^{2}}}\\mathrm{e}^{-\\dfrac{1}{2\\sigma^{2}}\\Vert\\boldsymbol{\\mathbf{y}-g_{\\boldsymbol{\\theta}}(\\mathbf{x})}\\Vert_{2}^{2}}$,\n",
        "\n",
        "which we used to derive the log likelihood. If we have some prior knowledge about the parameters of the neural network, which is given by a pdf $p(\\boldsymbol{\\theta})$ over the weights, we can use Bayes theorem to derive a posterior distribution\n",
        "\n",
        "$p(\\boldsymbol{\\theta}\\vert\\mathbf{x},\\mathbf{y})=\\dfrac{p(\\boldsymbol{\\theta},\\mathbf{y}\\vert\\mathbf{x})}{p(\\mathbf{y})}=\\dfrac{p(\\mathbf{y}\\vert\\mathbf{x},\\boldsymbol{\\theta})p(\\boldsymbol{\\theta})}{p(\\mathbf{y})}$\n",
        "\n",
        "where $p(\\boldsymbol{\\theta})$ is the  prior over the networks parameters. Similar to the derivation at the beginning of the exercise, we can use this posterior distribution to derive a cost function for training the neural network. In this case, however, we are not maximizing the log likelihood but the posterior distribution over the weights, hence this approach is called Maximum A Posteori (MAP) estimation of the parameters. Mathematically we can formulate this as\n",
        "\n",
        "$\\boldsymbol{\\theta}^{\\star}=\\arg\\max_{\\boldsymbol{\\theta}}\\mathbb{E}\\left[p(\\boldsymbol{\\theta}\\vert\\mathbf{x},\\mathbf{y})\\right]=\\arg\\max_{\\boldsymbol{\\theta}}\\mathbb{E}\\left[\\ln{p(\\boldsymbol{\\theta}\\vert\\mathbf{x},\\mathbf{y})}\\right]=\\arg\\max_{\\boldsymbol{\\theta}}\\ln{p(\\boldsymbol{\\theta})}+\\mathbb{E}\\left[\\ln{p(\\mathbf{y}\\vert\\mathbf{x},\\boldsymbol{\\theta})}\\right]$,\n",
        "\n",
        "where we used the fact that applying a strictly increasing function, e.g. $\\ln{}$, does not change the position of the maximum of a cost function, ignored $p(\\mathbf{y})$, since it is independent of the network parameters and dropped the expectation operator for $\\ln{p(\\boldsymbol{\\theta})}$, since it is not depending on the random variable $\\mathbf{x}$. Comparing the MAP estimate of the parameters with the ML estimate we derived above, shows that the only difference is the addition of $\\ln{p(\\boldsymbol{\\theta})}$. This term is the regularization, i.e. the weight norm penalty. Depending on the distribution over $\\boldsymbol{\\theta}$ it can have different forms. If we choose a standard normal distribution, i.e. $\\boldsymbol{\\theta\\sim\\mathcal{N}(\\mathbf{0},\\mathbf{I})}$,  we get\n",
        "\n",
        "$\\boldsymbol{\\theta}^{\\star}=\\arg\\min_{\\boldsymbol{\\theta}}\\lambda\\Vert\\boldsymbol{\\theta}\\Vert_{2}^{2}+\\dfrac{1}{N_{D}}\\sum_{i=1}^{N_{D}}\\Vert\\boldsymbol{\\mathbf{y}_{i}-g_{\\boldsymbol{\\theta}}(\\mathbf{x}_{i})}\\Vert_{2}^{2}$,\n",
        "\n",
        "where we have made the same simplifications as for the ML estimation and also introduced the parameter $\\lambda=\\sigma^{2}$, which is used to control the strength of the regularization. This form of regularization is commonly known as $l_{2}$-norm or weight decay regularization. Choosing a prior where the weights follow an i.i.d laplacian distribution, i.e. $p(\\boldsymbol{\\theta})=\\prod_{j}\\dfrac{1}{2}\\mathrm{e}^{\\vert\\theta_{j}\\vert}$, leads to\n",
        "\n",
        "$\\boldsymbol{\\theta}^{\\star}=\\arg\\min_{\\boldsymbol{\\theta}}\\lambda\\Vert\\boldsymbol{\\theta}\\Vert_{1}+\\dfrac{1}{N_{D}}\\sum_{i=1}^{N_{D}}\\Vert\\boldsymbol{\\mathbf{y}_{i}-g_{\\boldsymbol{\\theta}}(\\mathbf{x}_{i})}\\Vert_{2}^{2}$,\n",
        "\n",
        "where the strength of the regularization is again controlled by $\\lambda=\\sigma^{2}$. This type of regularization is known as  $l_{1}$-norm and it has the property to induce sparsity in the parameters of the network.\n",
        "\n",
        "With this theoretical background on regularization we can now implement it and observe it's effects on the regression problem covered in this exercise. For this we will define a model with a high capacity and train it for a extended time to provoke overfitting. For this, we will increase the number of hidden neurons in both hidden layers to $100$ and $50$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "T2Fv2J-VK_vw",
        "colab": {}
      },
      "source": [
        "\"\"\" Implement a bigger model with again two hidden layers contatining 100 and 50 neurons. As an activation use the tangens hyperbolicus function where it is appropiate. \"\"\"\n",
        "\n",
        "class MyBigModel(object):\n",
        "    def __init__(self):\n",
        "        # Create model variables\n",
        "        self.W0 = tf.Variable(tf.random.normal([1,100]))\n",
        "        self.b0 = tf.Variable(tf.random.normal([100]))\n",
        "        self.W1 = tf.Variable(tf.random.normal([100,50]))\n",
        "        self.b1 = tf.Variable(tf.random.normal([50]))\n",
        "        self.W2 = tf.Variable(tf.random.normal([50,1]))\n",
        "        self.b2 = tf.Variable(tf.random.normal([1]))\n",
        "        self.trainable_variables = [self.W0, self.b0, self.W1, self.b1, self.W2, self.b2]\n",
        "\n",
        "    def __call__(self, inputs):\n",
        "        # Compute forward pass\n",
        "        output = tf.reshape(inputs, [-1, 1])\n",
        "        output = tf.nn.tanh(tf.add(tf.matmul(output, self.W0), self.b0))\n",
        "        output = tf.nn.tanh(tf.add(tf.matmul(output, self.W1), self.b1))\n",
        "        output = tf.add(tf.matmul(output, self.W2), self.b2)\n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Y1XpaZTNLV-p"
      },
      "source": [
        "After creating one instance of this class we can again train it on our data set. We will also create a new optimizer for training this bigger model, since some optimizers adapt the learning rates for individual parameters during a training process and we do not want to train our bigger model with learning rates adopted from an earlier training run."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "b7Yq-a1FLi0X",
        "colab": {}
      },
      "source": [
        "big_mdl = MyBigModel()\n",
        "big_opt = tf.optimizers.SGD(learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dBrf0I68MnMy"
      },
      "source": [
        "Now we are ready to train this bigger model using the same training step and training loop. In order to provoke overfitting we also reduce the number of samples in the training data set a lot, increase the batch size and train for a more epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Nz_lXM8LMwXo",
        "outputId": "52f14c3c-20cc-4ff9-c162-4f9ef82b0523",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\"\"\" Implement the training for the bigger model similar to the training of the small model before. \"\"\"\n",
        "\n",
        "N_train_samples_overfit = 30\n",
        "N_epochs = 1000\n",
        "batch_size = 30\n",
        "\n",
        "sel_idx = np.arange(0, N_train_samples)\n",
        "sel_idx = np.random.choice(sel_idx, N_train_samples_overfit)\n",
        "x_train_overfit = x_train[sel_idx]\n",
        "y_train_overfit = y_train[sel_idx]\n",
        "\n",
        "train_overfit_ds = tf.data.Dataset.from_tensor_slices((x_train_overfit, y_train_overfit)).shuffle(N_train_samples_overfit).batch(batch_size).repeat()\n",
        "\n",
        "epoch = 0\n",
        "train_iters = 0\n",
        "train_loss = 0.0\n",
        "for x_t, y_t in train_overfit_ds:\n",
        "    train_loss += train_step(big_mdl,big_opt,x_t,y_t)\n",
        "    # Perform a training step with the model \"big_mdl\" and the optimizer \"big_opt\" on the inputs \"x_t\" and the corresponding targets \"y_t\"\n",
        "    train_iters += 1\n",
        "    if train_iters == math.ceil(N_train_samples_overfit/batch_size):\n",
        "        for x_v, y_v in validation_ds:\n",
        "            y_pred = big_mdl(x_v)\n",
        "            # Compute a prediction with \"big_mdl\" on the input \"x_v\"\n",
        "            validation_loss = tf.reduce_mean(tf.square(y_v-tf.reshape(y_pred,(-1))))\n",
        "#             validation_loss = tf.compat.v1.losses.mean_squared_error(y_v,tf.reshape(y_pred,(-1)))\n",
        "            # Compute the Mean Squared Error (MSE) for the prediction \"y_pred\" and the targets \"y_v\"\n",
        "        print(\"Epoch: {} Train loss: {:.5} Validation loss: {:.5}\".format(epoch, train_loss/train_iters, validation_loss))\n",
        "        train_iters = 0\n",
        "        train_loss = 0.0\n",
        "        epoch += 1\n",
        "    if (epoch == N_epochs):\n",
        "        break"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 Train loss: 16.319 Validation loss: 5.3368\n",
            "Epoch: 1 Train loss: 13.248 Validation loss: 0.64794\n",
            "Epoch: 2 Train loss: 5.1306 Validation loss: 0.41886\n",
            "Epoch: 3 Train loss: 2.2976 Validation loss: 0.0010899\n",
            "Epoch: 4 Train loss: 0.77901 Validation loss: 0.041207\n",
            "Epoch: 5 Train loss: 0.44266 Validation loss: 0.018011\n",
            "Epoch: 6 Train loss: 0.26719 Validation loss: 0.019389\n",
            "Epoch: 7 Train loss: 0.17813 Validation loss: 0.01356\n",
            "Epoch: 8 Train loss: 0.14522 Validation loss: 0.008566\n",
            "Epoch: 9 Train loss: 0.13027 Validation loss: 0.0045248\n",
            "Epoch: 10 Train loss: 0.12047 Validation loss: 0.0027671\n",
            "Epoch: 11 Train loss: 0.11264 Validation loss: 0.0017246\n",
            "Epoch: 12 Train loss: 0.10586 Validation loss: 0.001373\n",
            "Epoch: 13 Train loss: 0.099788 Validation loss: 0.0011787\n",
            "Epoch: 14 Train loss: 0.094292 Validation loss: 0.0012251\n",
            "Epoch: 15 Train loss: 0.0893 Validation loss: 0.0013118\n",
            "Epoch: 16 Train loss: 0.08476 Validation loss: 0.0015314\n",
            "Epoch: 17 Train loss: 0.080633 Validation loss: 0.0017657\n",
            "Epoch: 18 Train loss: 0.076883 Validation loss: 0.0020923\n",
            "Epoch: 19 Train loss: 0.073476 Validation loss: 0.0024198\n",
            "Epoch: 20 Train loss: 0.070379 Validation loss: 0.0028122\n",
            "Epoch: 21 Train loss: 0.067564 Validation loss: 0.0031934\n",
            "Epoch: 22 Train loss: 0.065003 Validation loss: 0.0036186\n",
            "Epoch: 23 Train loss: 0.062671 Validation loss: 0.0040228\n",
            "Epoch: 24 Train loss: 0.060546 Validation loss: 0.004455\n",
            "Epoch: 25 Train loss: 0.058608 Validation loss: 0.0048598\n",
            "Epoch: 26 Train loss: 0.056838 Validation loss: 0.0052812\n",
            "Epoch: 27 Train loss: 0.05522 Validation loss: 0.005671\n",
            "Epoch: 28 Train loss: 0.05374 Validation loss: 0.0060686\n",
            "Epoch: 29 Train loss: 0.052385 Validation loss: 0.0064337\n",
            "Epoch: 30 Train loss: 0.051143 Validation loss: 0.0068006\n",
            "Epoch: 31 Train loss: 0.050004 Validation loss: 0.0071346\n",
            "Epoch: 32 Train loss: 0.048958 Validation loss: 0.0074678\n",
            "Epoch: 33 Train loss: 0.047996 Validation loss: 0.0077683\n",
            "Epoch: 34 Train loss: 0.047112 Validation loss: 0.0080652\n",
            "Epoch: 35 Train loss: 0.046297 Validation loss: 0.0083317\n",
            "Epoch: 36 Train loss: 0.045547 Validation loss: 0.0085934\n",
            "Epoch: 37 Train loss: 0.044855 Validation loss: 0.0088265\n",
            "Epoch: 38 Train loss: 0.044216 Validation loss: 0.0090552\n",
            "Epoch: 39 Train loss: 0.043625 Validation loss: 0.009257\n",
            "Epoch: 40 Train loss: 0.043079 Validation loss: 0.009454\n",
            "Epoch: 41 Train loss: 0.042573 Validation loss: 0.0096274\n",
            "Epoch: 42 Train loss: 0.042104 Validation loss: 0.009796\n",
            "Epoch: 43 Train loss: 0.041669 Validation loss: 0.0099436\n",
            "Epoch: 44 Train loss: 0.041264 Validation loss: 0.010087\n",
            "Epoch: 45 Train loss: 0.040888 Validation loss: 0.010211\n",
            "Epoch: 46 Train loss: 0.040538 Validation loss: 0.010332\n",
            "Epoch: 47 Train loss: 0.040211 Validation loss: 0.010436\n",
            "Epoch: 48 Train loss: 0.039906 Validation loss: 0.010537\n",
            "Epoch: 49 Train loss: 0.039621 Validation loss: 0.010623\n",
            "Epoch: 50 Train loss: 0.039353 Validation loss: 0.010707\n",
            "Epoch: 51 Train loss: 0.039103 Validation loss: 0.010779\n",
            "Epoch: 52 Train loss: 0.038867 Validation loss: 0.010848\n",
            "Epoch: 53 Train loss: 0.038645 Validation loss: 0.010906\n",
            "Epoch: 54 Train loss: 0.038437 Validation loss: 0.010963\n",
            "Epoch: 55 Train loss: 0.038239 Validation loss: 0.011011\n",
            "Epoch: 56 Train loss: 0.038053 Validation loss: 0.011056\n",
            "Epoch: 57 Train loss: 0.037876 Validation loss: 0.011095\n",
            "Epoch: 58 Train loss: 0.037708 Validation loss: 0.011132\n",
            "Epoch: 59 Train loss: 0.037549 Validation loss: 0.011162\n",
            "Epoch: 60 Train loss: 0.037397 Validation loss: 0.011192\n",
            "Epoch: 61 Train loss: 0.037252 Validation loss: 0.011216\n",
            "Epoch: 62 Train loss: 0.037113 Validation loss: 0.011239\n",
            "Epoch: 63 Train loss: 0.036981 Validation loss: 0.011258\n",
            "Epoch: 64 Train loss: 0.036854 Validation loss: 0.011277\n",
            "Epoch: 65 Train loss: 0.036732 Validation loss: 0.011291\n",
            "Epoch: 66 Train loss: 0.036615 Validation loss: 0.011306\n",
            "Epoch: 67 Train loss: 0.036502 Validation loss: 0.011317\n",
            "Epoch: 68 Train loss: 0.036392 Validation loss: 0.011328\n",
            "Epoch: 69 Train loss: 0.036287 Validation loss: 0.011337\n",
            "Epoch: 70 Train loss: 0.036185 Validation loss: 0.011345\n",
            "Epoch: 71 Train loss: 0.036086 Validation loss: 0.01135\n",
            "Epoch: 72 Train loss: 0.03599 Validation loss: 0.011356\n",
            "Epoch: 73 Train loss: 0.035897 Validation loss: 0.01136\n",
            "Epoch: 74 Train loss: 0.035806 Validation loss: 0.011365\n",
            "Epoch: 75 Train loss: 0.035718 Validation loss: 0.011367\n",
            "Epoch: 76 Train loss: 0.035631 Validation loss: 0.01137\n",
            "Epoch: 77 Train loss: 0.035547 Validation loss: 0.011371\n",
            "Epoch: 78 Train loss: 0.035465 Validation loss: 0.011373\n",
            "Epoch: 79 Train loss: 0.035384 Validation loss: 0.011374\n",
            "Epoch: 80 Train loss: 0.035305 Validation loss: 0.011375\n",
            "Epoch: 81 Train loss: 0.035228 Validation loss: 0.011375\n",
            "Epoch: 82 Train loss: 0.035152 Validation loss: 0.011376\n",
            "Epoch: 83 Train loss: 0.035078 Validation loss: 0.011376\n",
            "Epoch: 84 Train loss: 0.035005 Validation loss: 0.011375\n",
            "Epoch: 85 Train loss: 0.034933 Validation loss: 0.011375\n",
            "Epoch: 86 Train loss: 0.034862 Validation loss: 0.011374\n",
            "Epoch: 87 Train loss: 0.034793 Validation loss: 0.011374\n",
            "Epoch: 88 Train loss: 0.034724 Validation loss: 0.011373\n",
            "Epoch: 89 Train loss: 0.034657 Validation loss: 0.011372\n",
            "Epoch: 90 Train loss: 0.03459 Validation loss: 0.011371\n",
            "Epoch: 91 Train loss: 0.034524 Validation loss: 0.01137\n",
            "Epoch: 92 Train loss: 0.03446 Validation loss: 0.011369\n",
            "Epoch: 93 Train loss: 0.034395 Validation loss: 0.011368\n",
            "Epoch: 94 Train loss: 0.034332 Validation loss: 0.011367\n",
            "Epoch: 95 Train loss: 0.03427 Validation loss: 0.011366\n",
            "Epoch: 96 Train loss: 0.034208 Validation loss: 0.011365\n",
            "Epoch: 97 Train loss: 0.034146 Validation loss: 0.011365\n",
            "Epoch: 98 Train loss: 0.034086 Validation loss: 0.011364\n",
            "Epoch: 99 Train loss: 0.034026 Validation loss: 0.011363\n",
            "Epoch: 100 Train loss: 0.033967 Validation loss: 0.011362\n",
            "Epoch: 101 Train loss: 0.033908 Validation loss: 0.011361\n",
            "Epoch: 102 Train loss: 0.033849 Validation loss: 0.01136\n",
            "Epoch: 103 Train loss: 0.033791 Validation loss: 0.011361\n",
            "Epoch: 104 Train loss: 0.033734 Validation loss: 0.01136\n",
            "Epoch: 105 Train loss: 0.033677 Validation loss: 0.011359\n",
            "Epoch: 106 Train loss: 0.033621 Validation loss: 0.011359\n",
            "Epoch: 107 Train loss: 0.033565 Validation loss: 0.011358\n",
            "Epoch: 108 Train loss: 0.033509 Validation loss: 0.011358\n",
            "Epoch: 109 Train loss: 0.033454 Validation loss: 0.011357\n",
            "Epoch: 110 Train loss: 0.0334 Validation loss: 0.011357\n",
            "Epoch: 111 Train loss: 0.033345 Validation loss: 0.011357\n",
            "Epoch: 112 Train loss: 0.033291 Validation loss: 0.011357\n",
            "Epoch: 113 Train loss: 0.033238 Validation loss: 0.011357\n",
            "Epoch: 114 Train loss: 0.033185 Validation loss: 0.011356\n",
            "Epoch: 115 Train loss: 0.033132 Validation loss: 0.011357\n",
            "Epoch: 116 Train loss: 0.033079 Validation loss: 0.011356\n",
            "Epoch: 117 Train loss: 0.033027 Validation loss: 0.011356\n",
            "Epoch: 118 Train loss: 0.032975 Validation loss: 0.011356\n",
            "Epoch: 119 Train loss: 0.032923 Validation loss: 0.011356\n",
            "Epoch: 120 Train loss: 0.032872 Validation loss: 0.011356\n",
            "Epoch: 121 Train loss: 0.032821 Validation loss: 0.011357\n",
            "Epoch: 122 Train loss: 0.03277 Validation loss: 0.011357\n",
            "Epoch: 123 Train loss: 0.032719 Validation loss: 0.011358\n",
            "Epoch: 124 Train loss: 0.032669 Validation loss: 0.011358\n",
            "Epoch: 125 Train loss: 0.032619 Validation loss: 0.011358\n",
            "Epoch: 126 Train loss: 0.032569 Validation loss: 0.011359\n",
            "Epoch: 127 Train loss: 0.03252 Validation loss: 0.011359\n",
            "Epoch: 128 Train loss: 0.03247 Validation loss: 0.011359\n",
            "Epoch: 129 Train loss: 0.032421 Validation loss: 0.01136\n",
            "Epoch: 130 Train loss: 0.032372 Validation loss: 0.01136\n",
            "Epoch: 131 Train loss: 0.032323 Validation loss: 0.011361\n",
            "Epoch: 132 Train loss: 0.032275 Validation loss: 0.011362\n",
            "Epoch: 133 Train loss: 0.032227 Validation loss: 0.011362\n",
            "Epoch: 134 Train loss: 0.032179 Validation loss: 0.011362\n",
            "Epoch: 135 Train loss: 0.032131 Validation loss: 0.011363\n",
            "Epoch: 136 Train loss: 0.032083 Validation loss: 0.011364\n",
            "Epoch: 137 Train loss: 0.032035 Validation loss: 0.011364\n",
            "Epoch: 138 Train loss: 0.031988 Validation loss: 0.011365\n",
            "Epoch: 139 Train loss: 0.031941 Validation loss: 0.011366\n",
            "Epoch: 140 Train loss: 0.031893 Validation loss: 0.011367\n",
            "Epoch: 141 Train loss: 0.031847 Validation loss: 0.011367\n",
            "Epoch: 142 Train loss: 0.0318 Validation loss: 0.011368\n",
            "Epoch: 143 Train loss: 0.031753 Validation loss: 0.011369\n",
            "Epoch: 144 Train loss: 0.031707 Validation loss: 0.01137\n",
            "Epoch: 145 Train loss: 0.031661 Validation loss: 0.011371\n",
            "Epoch: 146 Train loss: 0.031614 Validation loss: 0.011372\n",
            "Epoch: 147 Train loss: 0.031568 Validation loss: 0.011372\n",
            "Epoch: 148 Train loss: 0.031523 Validation loss: 0.011373\n",
            "Epoch: 149 Train loss: 0.031477 Validation loss: 0.011374\n",
            "Epoch: 150 Train loss: 0.031431 Validation loss: 0.011375\n",
            "Epoch: 151 Train loss: 0.031386 Validation loss: 0.011376\n",
            "Epoch: 152 Train loss: 0.03134 Validation loss: 0.011377\n",
            "Epoch: 153 Train loss: 0.031295 Validation loss: 0.011377\n",
            "Epoch: 154 Train loss: 0.03125 Validation loss: 0.011378\n",
            "Epoch: 155 Train loss: 0.031205 Validation loss: 0.011379\n",
            "Epoch: 156 Train loss: 0.03116 Validation loss: 0.01138\n",
            "Epoch: 157 Train loss: 0.031115 Validation loss: 0.011381\n",
            "Epoch: 158 Train loss: 0.03107 Validation loss: 0.011382\n",
            "Epoch: 159 Train loss: 0.031026 Validation loss: 0.011383\n",
            "Epoch: 160 Train loss: 0.030981 Validation loss: 0.011384\n",
            "Epoch: 161 Train loss: 0.030937 Validation loss: 0.011385\n",
            "Epoch: 162 Train loss: 0.030893 Validation loss: 0.011386\n",
            "Epoch: 163 Train loss: 0.030848 Validation loss: 0.011387\n",
            "Epoch: 164 Train loss: 0.030804 Validation loss: 0.011388\n",
            "Epoch: 165 Train loss: 0.03076 Validation loss: 0.011389\n",
            "Epoch: 166 Train loss: 0.030716 Validation loss: 0.01139\n",
            "Epoch: 167 Train loss: 0.030672 Validation loss: 0.011391\n",
            "Epoch: 168 Train loss: 0.030629 Validation loss: 0.011392\n",
            "Epoch: 169 Train loss: 0.030585 Validation loss: 0.011393\n",
            "Epoch: 170 Train loss: 0.030541 Validation loss: 0.011395\n",
            "Epoch: 171 Train loss: 0.030498 Validation loss: 0.011396\n",
            "Epoch: 172 Train loss: 0.030454 Validation loss: 0.011397\n",
            "Epoch: 173 Train loss: 0.030411 Validation loss: 0.011398\n",
            "Epoch: 174 Train loss: 0.030368 Validation loss: 0.011399\n",
            "Epoch: 175 Train loss: 0.030325 Validation loss: 0.0114\n",
            "Epoch: 176 Train loss: 0.030281 Validation loss: 0.011401\n",
            "Epoch: 177 Train loss: 0.030238 Validation loss: 0.011402\n",
            "Epoch: 178 Train loss: 0.030195 Validation loss: 0.011403\n",
            "Epoch: 179 Train loss: 0.030152 Validation loss: 0.011405\n",
            "Epoch: 180 Train loss: 0.030109 Validation loss: 0.011405\n",
            "Epoch: 181 Train loss: 0.030066 Validation loss: 0.011407\n",
            "Epoch: 182 Train loss: 0.030024 Validation loss: 0.011408\n",
            "Epoch: 183 Train loss: 0.029981 Validation loss: 0.011409\n",
            "Epoch: 184 Train loss: 0.029938 Validation loss: 0.011411\n",
            "Epoch: 185 Train loss: 0.029895 Validation loss: 0.011412\n",
            "Epoch: 186 Train loss: 0.029853 Validation loss: 0.011413\n",
            "Epoch: 187 Train loss: 0.02981 Validation loss: 0.011414\n",
            "Epoch: 188 Train loss: 0.029768 Validation loss: 0.011415\n",
            "Epoch: 189 Train loss: 0.029725 Validation loss: 0.011417\n",
            "Epoch: 190 Train loss: 0.029683 Validation loss: 0.011418\n",
            "Epoch: 191 Train loss: 0.02964 Validation loss: 0.011419\n",
            "Epoch: 192 Train loss: 0.029598 Validation loss: 0.011421\n",
            "Epoch: 193 Train loss: 0.029556 Validation loss: 0.011422\n",
            "Epoch: 194 Train loss: 0.029514 Validation loss: 0.011424\n",
            "Epoch: 195 Train loss: 0.029471 Validation loss: 0.011425\n",
            "Epoch: 196 Train loss: 0.029429 Validation loss: 0.011426\n",
            "Epoch: 197 Train loss: 0.029387 Validation loss: 0.011428\n",
            "Epoch: 198 Train loss: 0.029345 Validation loss: 0.011429\n",
            "Epoch: 199 Train loss: 0.029303 Validation loss: 0.01143\n",
            "Epoch: 200 Train loss: 0.029261 Validation loss: 0.011432\n",
            "Epoch: 201 Train loss: 0.029219 Validation loss: 0.011433\n",
            "Epoch: 202 Train loss: 0.029177 Validation loss: 0.011435\n",
            "Epoch: 203 Train loss: 0.029135 Validation loss: 0.011436\n",
            "Epoch: 204 Train loss: 0.029093 Validation loss: 0.011437\n",
            "Epoch: 205 Train loss: 0.029051 Validation loss: 0.011439\n",
            "Epoch: 206 Train loss: 0.029009 Validation loss: 0.01144\n",
            "Epoch: 207 Train loss: 0.028967 Validation loss: 0.011441\n",
            "Epoch: 208 Train loss: 0.028925 Validation loss: 0.011443\n",
            "Epoch: 209 Train loss: 0.028883 Validation loss: 0.011445\n",
            "Epoch: 210 Train loss: 0.028842 Validation loss: 0.011446\n",
            "Epoch: 211 Train loss: 0.0288 Validation loss: 0.011447\n",
            "Epoch: 212 Train loss: 0.028758 Validation loss: 0.011449\n",
            "Epoch: 213 Train loss: 0.028716 Validation loss: 0.01145\n",
            "Epoch: 214 Train loss: 0.028674 Validation loss: 0.011452\n",
            "Epoch: 215 Train loss: 0.028633 Validation loss: 0.011454\n",
            "Epoch: 216 Train loss: 0.028591 Validation loss: 0.011455\n",
            "Epoch: 217 Train loss: 0.028549 Validation loss: 0.011456\n",
            "Epoch: 218 Train loss: 0.028507 Validation loss: 0.011458\n",
            "Epoch: 219 Train loss: 0.028466 Validation loss: 0.01146\n",
            "Epoch: 220 Train loss: 0.028424 Validation loss: 0.011461\n",
            "Epoch: 221 Train loss: 0.028382 Validation loss: 0.011463\n",
            "Epoch: 222 Train loss: 0.02834 Validation loss: 0.011465\n",
            "Epoch: 223 Train loss: 0.028299 Validation loss: 0.011467\n",
            "Epoch: 224 Train loss: 0.028257 Validation loss: 0.011468\n",
            "Epoch: 225 Train loss: 0.028215 Validation loss: 0.01147\n",
            "Epoch: 226 Train loss: 0.028174 Validation loss: 0.011471\n",
            "Epoch: 227 Train loss: 0.028132 Validation loss: 0.011474\n",
            "Epoch: 228 Train loss: 0.02809 Validation loss: 0.011475\n",
            "Epoch: 229 Train loss: 0.028048 Validation loss: 0.011477\n",
            "Epoch: 230 Train loss: 0.028007 Validation loss: 0.011479\n",
            "Epoch: 231 Train loss: 0.027965 Validation loss: 0.01148\n",
            "Epoch: 232 Train loss: 0.027923 Validation loss: 0.011482\n",
            "Epoch: 233 Train loss: 0.027881 Validation loss: 0.011483\n",
            "Epoch: 234 Train loss: 0.027839 Validation loss: 0.011485\n",
            "Epoch: 235 Train loss: 0.027797 Validation loss: 0.011487\n",
            "Epoch: 236 Train loss: 0.027756 Validation loss: 0.011489\n",
            "Epoch: 237 Train loss: 0.027714 Validation loss: 0.01149\n",
            "Epoch: 238 Train loss: 0.027672 Validation loss: 0.011492\n",
            "Epoch: 239 Train loss: 0.02763 Validation loss: 0.011494\n",
            "Epoch: 240 Train loss: 0.027588 Validation loss: 0.011496\n",
            "Epoch: 241 Train loss: 0.027546 Validation loss: 0.011498\n",
            "Epoch: 242 Train loss: 0.027504 Validation loss: 0.011499\n",
            "Epoch: 243 Train loss: 0.027462 Validation loss: 0.011502\n",
            "Epoch: 244 Train loss: 0.02742 Validation loss: 0.011503\n",
            "Epoch: 245 Train loss: 0.027378 Validation loss: 0.011505\n",
            "Epoch: 246 Train loss: 0.027336 Validation loss: 0.011507\n",
            "Epoch: 247 Train loss: 0.027294 Validation loss: 0.011509\n",
            "Epoch: 248 Train loss: 0.027251 Validation loss: 0.011511\n",
            "Epoch: 249 Train loss: 0.027209 Validation loss: 0.011513\n",
            "Epoch: 250 Train loss: 0.027167 Validation loss: 0.011515\n",
            "Epoch: 251 Train loss: 0.027125 Validation loss: 0.011517\n",
            "Epoch: 252 Train loss: 0.027082 Validation loss: 0.011519\n",
            "Epoch: 253 Train loss: 0.02704 Validation loss: 0.01152\n",
            "Epoch: 254 Train loss: 0.026997 Validation loss: 0.011522\n",
            "Epoch: 255 Train loss: 0.026955 Validation loss: 0.011524\n",
            "Epoch: 256 Train loss: 0.026913 Validation loss: 0.011526\n",
            "Epoch: 257 Train loss: 0.02687 Validation loss: 0.011528\n",
            "Epoch: 258 Train loss: 0.026827 Validation loss: 0.01153\n",
            "Epoch: 259 Train loss: 0.026785 Validation loss: 0.011532\n",
            "Epoch: 260 Train loss: 0.026742 Validation loss: 0.011535\n",
            "Epoch: 261 Train loss: 0.026699 Validation loss: 0.011537\n",
            "Epoch: 262 Train loss: 0.026656 Validation loss: 0.011539\n",
            "Epoch: 263 Train loss: 0.026613 Validation loss: 0.011541\n",
            "Epoch: 264 Train loss: 0.02657 Validation loss: 0.011543\n",
            "Epoch: 265 Train loss: 0.026527 Validation loss: 0.011545\n",
            "Epoch: 266 Train loss: 0.026484 Validation loss: 0.011548\n",
            "Epoch: 267 Train loss: 0.026441 Validation loss: 0.01155\n",
            "Epoch: 268 Train loss: 0.026398 Validation loss: 0.011552\n",
            "Epoch: 269 Train loss: 0.026355 Validation loss: 0.011554\n",
            "Epoch: 270 Train loss: 0.026311 Validation loss: 0.011556\n",
            "Epoch: 271 Train loss: 0.026268 Validation loss: 0.011558\n",
            "Epoch: 272 Train loss: 0.026224 Validation loss: 0.011561\n",
            "Epoch: 273 Train loss: 0.02618 Validation loss: 0.011562\n",
            "Epoch: 274 Train loss: 0.026137 Validation loss: 0.011565\n",
            "Epoch: 275 Train loss: 0.026093 Validation loss: 0.011567\n",
            "Epoch: 276 Train loss: 0.026049 Validation loss: 0.011569\n",
            "Epoch: 277 Train loss: 0.026005 Validation loss: 0.011571\n",
            "Epoch: 278 Train loss: 0.025961 Validation loss: 0.011574\n",
            "Epoch: 279 Train loss: 0.025917 Validation loss: 0.011576\n",
            "Epoch: 280 Train loss: 0.025872 Validation loss: 0.011579\n",
            "Epoch: 281 Train loss: 0.025828 Validation loss: 0.01158\n",
            "Epoch: 282 Train loss: 0.025783 Validation loss: 0.011583\n",
            "Epoch: 283 Train loss: 0.025739 Validation loss: 0.011586\n",
            "Epoch: 284 Train loss: 0.025694 Validation loss: 0.011587\n",
            "Epoch: 285 Train loss: 0.025649 Validation loss: 0.01159\n",
            "Epoch: 286 Train loss: 0.025604 Validation loss: 0.011592\n",
            "Epoch: 287 Train loss: 0.025559 Validation loss: 0.011594\n",
            "Epoch: 288 Train loss: 0.025514 Validation loss: 0.011597\n",
            "Epoch: 289 Train loss: 0.025469 Validation loss: 0.011599\n",
            "Epoch: 290 Train loss: 0.025423 Validation loss: 0.011601\n",
            "Epoch: 291 Train loss: 0.025378 Validation loss: 0.011604\n",
            "Epoch: 292 Train loss: 0.025332 Validation loss: 0.011606\n",
            "Epoch: 293 Train loss: 0.025286 Validation loss: 0.011609\n",
            "Epoch: 294 Train loss: 0.02524 Validation loss: 0.011611\n",
            "Epoch: 295 Train loss: 0.025194 Validation loss: 0.011614\n",
            "Epoch: 296 Train loss: 0.025148 Validation loss: 0.011616\n",
            "Epoch: 297 Train loss: 0.025101 Validation loss: 0.011619\n",
            "Epoch: 298 Train loss: 0.025054 Validation loss: 0.011622\n",
            "Epoch: 299 Train loss: 0.025008 Validation loss: 0.011624\n",
            "Epoch: 300 Train loss: 0.024961 Validation loss: 0.011627\n",
            "Epoch: 301 Train loss: 0.024914 Validation loss: 0.011629\n",
            "Epoch: 302 Train loss: 0.024866 Validation loss: 0.011631\n",
            "Epoch: 303 Train loss: 0.024819 Validation loss: 0.011635\n",
            "Epoch: 304 Train loss: 0.024771 Validation loss: 0.011637\n",
            "Epoch: 305 Train loss: 0.024723 Validation loss: 0.01164\n",
            "Epoch: 306 Train loss: 0.024675 Validation loss: 0.011642\n",
            "Epoch: 307 Train loss: 0.024627 Validation loss: 0.011645\n",
            "Epoch: 308 Train loss: 0.024579 Validation loss: 0.011647\n",
            "Epoch: 309 Train loss: 0.02453 Validation loss: 0.01165\n",
            "Epoch: 310 Train loss: 0.024482 Validation loss: 0.011653\n",
            "Epoch: 311 Train loss: 0.024433 Validation loss: 0.011655\n",
            "Epoch: 312 Train loss: 0.024384 Validation loss: 0.011658\n",
            "Epoch: 313 Train loss: 0.024334 Validation loss: 0.01166\n",
            "Epoch: 314 Train loss: 0.024284 Validation loss: 0.011663\n",
            "Epoch: 315 Train loss: 0.024235 Validation loss: 0.011666\n",
            "Epoch: 316 Train loss: 0.024185 Validation loss: 0.011669\n",
            "Epoch: 317 Train loss: 0.024134 Validation loss: 0.011672\n",
            "Epoch: 318 Train loss: 0.024084 Validation loss: 0.011674\n",
            "Epoch: 319 Train loss: 0.024033 Validation loss: 0.011677\n",
            "Epoch: 320 Train loss: 0.023982 Validation loss: 0.01168\n",
            "Epoch: 321 Train loss: 0.023931 Validation loss: 0.011682\n",
            "Epoch: 322 Train loss: 0.023879 Validation loss: 0.011685\n",
            "Epoch: 323 Train loss: 0.023828 Validation loss: 0.011688\n",
            "Epoch: 324 Train loss: 0.023776 Validation loss: 0.011691\n",
            "Epoch: 325 Train loss: 0.023724 Validation loss: 0.011694\n",
            "Epoch: 326 Train loss: 0.023671 Validation loss: 0.011696\n",
            "Epoch: 327 Train loss: 0.023618 Validation loss: 0.011699\n",
            "Epoch: 328 Train loss: 0.023565 Validation loss: 0.011702\n",
            "Epoch: 329 Train loss: 0.023512 Validation loss: 0.011704\n",
            "Epoch: 330 Train loss: 0.023458 Validation loss: 0.011708\n",
            "Epoch: 331 Train loss: 0.023405 Validation loss: 0.01171\n",
            "Epoch: 332 Train loss: 0.023351 Validation loss: 0.011713\n",
            "Epoch: 333 Train loss: 0.023296 Validation loss: 0.011716\n",
            "Epoch: 334 Train loss: 0.023241 Validation loss: 0.011718\n",
            "Epoch: 335 Train loss: 0.023186 Validation loss: 0.011722\n",
            "Epoch: 336 Train loss: 0.023131 Validation loss: 0.011724\n",
            "Epoch: 337 Train loss: 0.023076 Validation loss: 0.011727\n",
            "Epoch: 338 Train loss: 0.02302 Validation loss: 0.01173\n",
            "Epoch: 339 Train loss: 0.022963 Validation loss: 0.011732\n",
            "Epoch: 340 Train loss: 0.022907 Validation loss: 0.011735\n",
            "Epoch: 341 Train loss: 0.02285 Validation loss: 0.011738\n",
            "Epoch: 342 Train loss: 0.022793 Validation loss: 0.011741\n",
            "Epoch: 343 Train loss: 0.022736 Validation loss: 0.011744\n",
            "Epoch: 344 Train loss: 0.022678 Validation loss: 0.011746\n",
            "Epoch: 345 Train loss: 0.02262 Validation loss: 0.01175\n",
            "Epoch: 346 Train loss: 0.022562 Validation loss: 0.011752\n",
            "Epoch: 347 Train loss: 0.022503 Validation loss: 0.011755\n",
            "Epoch: 348 Train loss: 0.022444 Validation loss: 0.011757\n",
            "Epoch: 349 Train loss: 0.022385 Validation loss: 0.01176\n",
            "Epoch: 350 Train loss: 0.022325 Validation loss: 0.011762\n",
            "Epoch: 351 Train loss: 0.022266 Validation loss: 0.011766\n",
            "Epoch: 352 Train loss: 0.022206 Validation loss: 0.011768\n",
            "Epoch: 353 Train loss: 0.022145 Validation loss: 0.011771\n",
            "Epoch: 354 Train loss: 0.022085 Validation loss: 0.011773\n",
            "Epoch: 355 Train loss: 0.022024 Validation loss: 0.011776\n",
            "Epoch: 356 Train loss: 0.021962 Validation loss: 0.011779\n",
            "Epoch: 357 Train loss: 0.021901 Validation loss: 0.011782\n",
            "Epoch: 358 Train loss: 0.021839 Validation loss: 0.011784\n",
            "Epoch: 359 Train loss: 0.021777 Validation loss: 0.011786\n",
            "Epoch: 360 Train loss: 0.021714 Validation loss: 0.011789\n",
            "Epoch: 361 Train loss: 0.021652 Validation loss: 0.011791\n",
            "Epoch: 362 Train loss: 0.021589 Validation loss: 0.011793\n",
            "Epoch: 363 Train loss: 0.021526 Validation loss: 0.011796\n",
            "Epoch: 364 Train loss: 0.021463 Validation loss: 0.011798\n",
            "Epoch: 365 Train loss: 0.021399 Validation loss: 0.0118\n",
            "Epoch: 366 Train loss: 0.021335 Validation loss: 0.011802\n",
            "Epoch: 367 Train loss: 0.021271 Validation loss: 0.011804\n",
            "Epoch: 368 Train loss: 0.021207 Validation loss: 0.011807\n",
            "Epoch: 369 Train loss: 0.021143 Validation loss: 0.011809\n",
            "Epoch: 370 Train loss: 0.021078 Validation loss: 0.011811\n",
            "Epoch: 371 Train loss: 0.021014 Validation loss: 0.011813\n",
            "Epoch: 372 Train loss: 0.020949 Validation loss: 0.011815\n",
            "Epoch: 373 Train loss: 0.020884 Validation loss: 0.011816\n",
            "Epoch: 374 Train loss: 0.020819 Validation loss: 0.011818\n",
            "Epoch: 375 Train loss: 0.020754 Validation loss: 0.01182\n",
            "Epoch: 376 Train loss: 0.020688 Validation loss: 0.011821\n",
            "Epoch: 377 Train loss: 0.020623 Validation loss: 0.011823\n",
            "Epoch: 378 Train loss: 0.020558 Validation loss: 0.011824\n",
            "Epoch: 379 Train loss: 0.020492 Validation loss: 0.011826\n",
            "Epoch: 380 Train loss: 0.020426 Validation loss: 0.011826\n",
            "Epoch: 381 Train loss: 0.020361 Validation loss: 0.011828\n",
            "Epoch: 382 Train loss: 0.020295 Validation loss: 0.011829\n",
            "Epoch: 383 Train loss: 0.02023 Validation loss: 0.01183\n",
            "Epoch: 384 Train loss: 0.020164 Validation loss: 0.011831\n",
            "Epoch: 385 Train loss: 0.020098 Validation loss: 0.011832\n",
            "Epoch: 386 Train loss: 0.020033 Validation loss: 0.011832\n",
            "Epoch: 387 Train loss: 0.019967 Validation loss: 0.011833\n",
            "Epoch: 388 Train loss: 0.019902 Validation loss: 0.011834\n",
            "Epoch: 389 Train loss: 0.019837 Validation loss: 0.011834\n",
            "Epoch: 390 Train loss: 0.019771 Validation loss: 0.011835\n",
            "Epoch: 391 Train loss: 0.019706 Validation loss: 0.011835\n",
            "Epoch: 392 Train loss: 0.019641 Validation loss: 0.011835\n",
            "Epoch: 393 Train loss: 0.019576 Validation loss: 0.011835\n",
            "Epoch: 394 Train loss: 0.019512 Validation loss: 0.011835\n",
            "Epoch: 395 Train loss: 0.019447 Validation loss: 0.011835\n",
            "Epoch: 396 Train loss: 0.019383 Validation loss: 0.011835\n",
            "Epoch: 397 Train loss: 0.019319 Validation loss: 0.011834\n",
            "Epoch: 398 Train loss: 0.019255 Validation loss: 0.011834\n",
            "Epoch: 399 Train loss: 0.019191 Validation loss: 0.011833\n",
            "Epoch: 400 Train loss: 0.019127 Validation loss: 0.011832\n",
            "Epoch: 401 Train loss: 0.019064 Validation loss: 0.011832\n",
            "Epoch: 402 Train loss: 0.019001 Validation loss: 0.011831\n",
            "Epoch: 403 Train loss: 0.018938 Validation loss: 0.01183\n",
            "Epoch: 404 Train loss: 0.018875 Validation loss: 0.011829\n",
            "Epoch: 405 Train loss: 0.018813 Validation loss: 0.011828\n",
            "Epoch: 406 Train loss: 0.018751 Validation loss: 0.011827\n",
            "Epoch: 407 Train loss: 0.018689 Validation loss: 0.011825\n",
            "Epoch: 408 Train loss: 0.018628 Validation loss: 0.011824\n",
            "Epoch: 409 Train loss: 0.018566 Validation loss: 0.011822\n",
            "Epoch: 410 Train loss: 0.018505 Validation loss: 0.011821\n",
            "Epoch: 411 Train loss: 0.018445 Validation loss: 0.011819\n",
            "Epoch: 412 Train loss: 0.018384 Validation loss: 0.011817\n",
            "Epoch: 413 Train loss: 0.018324 Validation loss: 0.011815\n",
            "Epoch: 414 Train loss: 0.018264 Validation loss: 0.011813\n",
            "Epoch: 415 Train loss: 0.018205 Validation loss: 0.011811\n",
            "Epoch: 416 Train loss: 0.018146 Validation loss: 0.011809\n",
            "Epoch: 417 Train loss: 0.018087 Validation loss: 0.011807\n",
            "Epoch: 418 Train loss: 0.018029 Validation loss: 0.011805\n",
            "Epoch: 419 Train loss: 0.01797 Validation loss: 0.011802\n",
            "Epoch: 420 Train loss: 0.017913 Validation loss: 0.0118\n",
            "Epoch: 421 Train loss: 0.017855 Validation loss: 0.011798\n",
            "Epoch: 422 Train loss: 0.017798 Validation loss: 0.011795\n",
            "Epoch: 423 Train loss: 0.017741 Validation loss: 0.011793\n",
            "Epoch: 424 Train loss: 0.017685 Validation loss: 0.01179\n",
            "Epoch: 425 Train loss: 0.017629 Validation loss: 0.011787\n",
            "Epoch: 426 Train loss: 0.017573 Validation loss: 0.011785\n",
            "Epoch: 427 Train loss: 0.017517 Validation loss: 0.011782\n",
            "Epoch: 428 Train loss: 0.017462 Validation loss: 0.011779\n",
            "Epoch: 429 Train loss: 0.017408 Validation loss: 0.011776\n",
            "Epoch: 430 Train loss: 0.017353 Validation loss: 0.011773\n",
            "Epoch: 431 Train loss: 0.017299 Validation loss: 0.01177\n",
            "Epoch: 432 Train loss: 0.017245 Validation loss: 0.011767\n",
            "Epoch: 433 Train loss: 0.017192 Validation loss: 0.011764\n",
            "Epoch: 434 Train loss: 0.017139 Validation loss: 0.011761\n",
            "Epoch: 435 Train loss: 0.017086 Validation loss: 0.011757\n",
            "Epoch: 436 Train loss: 0.017034 Validation loss: 0.011754\n",
            "Epoch: 437 Train loss: 0.016982 Validation loss: 0.011751\n",
            "Epoch: 438 Train loss: 0.01693 Validation loss: 0.011748\n",
            "Epoch: 439 Train loss: 0.016879 Validation loss: 0.011745\n",
            "Epoch: 440 Train loss: 0.016828 Validation loss: 0.011742\n",
            "Epoch: 441 Train loss: 0.016777 Validation loss: 0.011739\n",
            "Epoch: 442 Train loss: 0.016727 Validation loss: 0.011736\n",
            "Epoch: 443 Train loss: 0.016677 Validation loss: 0.011732\n",
            "Epoch: 444 Train loss: 0.016627 Validation loss: 0.011729\n",
            "Epoch: 445 Train loss: 0.016578 Validation loss: 0.011725\n",
            "Epoch: 446 Train loss: 0.016529 Validation loss: 0.011722\n",
            "Epoch: 447 Train loss: 0.01648 Validation loss: 0.011719\n",
            "Epoch: 448 Train loss: 0.016432 Validation loss: 0.011716\n",
            "Epoch: 449 Train loss: 0.016384 Validation loss: 0.011713\n",
            "Epoch: 450 Train loss: 0.016336 Validation loss: 0.011709\n",
            "Epoch: 451 Train loss: 0.016289 Validation loss: 0.011706\n",
            "Epoch: 452 Train loss: 0.016242 Validation loss: 0.011702\n",
            "Epoch: 453 Train loss: 0.016195 Validation loss: 0.011699\n",
            "Epoch: 454 Train loss: 0.016148 Validation loss: 0.011696\n",
            "Epoch: 455 Train loss: 0.016102 Validation loss: 0.011693\n",
            "Epoch: 456 Train loss: 0.016057 Validation loss: 0.011689\n",
            "Epoch: 457 Train loss: 0.016011 Validation loss: 0.011687\n",
            "Epoch: 458 Train loss: 0.015966 Validation loss: 0.011683\n",
            "Epoch: 459 Train loss: 0.015921 Validation loss: 0.011679\n",
            "Epoch: 460 Train loss: 0.015876 Validation loss: 0.011676\n",
            "Epoch: 461 Train loss: 0.015832 Validation loss: 0.011673\n",
            "Epoch: 462 Train loss: 0.015788 Validation loss: 0.01167\n",
            "Epoch: 463 Train loss: 0.015745 Validation loss: 0.011667\n",
            "Epoch: 464 Train loss: 0.015701 Validation loss: 0.011664\n",
            "Epoch: 465 Train loss: 0.015658 Validation loss: 0.011661\n",
            "Epoch: 466 Train loss: 0.015615 Validation loss: 0.011658\n",
            "Epoch: 467 Train loss: 0.015573 Validation loss: 0.011654\n",
            "Epoch: 468 Train loss: 0.015531 Validation loss: 0.011651\n",
            "Epoch: 469 Train loss: 0.015489 Validation loss: 0.011648\n",
            "Epoch: 470 Train loss: 0.015447 Validation loss: 0.011645\n",
            "Epoch: 471 Train loss: 0.015406 Validation loss: 0.011642\n",
            "Epoch: 472 Train loss: 0.015365 Validation loss: 0.011639\n",
            "Epoch: 473 Train loss: 0.015324 Validation loss: 0.011636\n",
            "Epoch: 474 Train loss: 0.015283 Validation loss: 0.011633\n",
            "Epoch: 475 Train loss: 0.015243 Validation loss: 0.01163\n",
            "Epoch: 476 Train loss: 0.015203 Validation loss: 0.011627\n",
            "Epoch: 477 Train loss: 0.015163 Validation loss: 0.011624\n",
            "Epoch: 478 Train loss: 0.015124 Validation loss: 0.011621\n",
            "Epoch: 479 Train loss: 0.015085 Validation loss: 0.011619\n",
            "Epoch: 480 Train loss: 0.015046 Validation loss: 0.011616\n",
            "Epoch: 481 Train loss: 0.015007 Validation loss: 0.011612\n",
            "Epoch: 482 Train loss: 0.014969 Validation loss: 0.01161\n",
            "Epoch: 483 Train loss: 0.014931 Validation loss: 0.011607\n",
            "Epoch: 484 Train loss: 0.014893 Validation loss: 0.011604\n",
            "Epoch: 485 Train loss: 0.014855 Validation loss: 0.011602\n",
            "Epoch: 486 Train loss: 0.014818 Validation loss: 0.011599\n",
            "Epoch: 487 Train loss: 0.014781 Validation loss: 0.011596\n",
            "Epoch: 488 Train loss: 0.014744 Validation loss: 0.011594\n",
            "Epoch: 489 Train loss: 0.014707 Validation loss: 0.011591\n",
            "Epoch: 490 Train loss: 0.014671 Validation loss: 0.011588\n",
            "Epoch: 491 Train loss: 0.014634 Validation loss: 0.011586\n",
            "Epoch: 492 Train loss: 0.014598 Validation loss: 0.011583\n",
            "Epoch: 493 Train loss: 0.014563 Validation loss: 0.011581\n",
            "Epoch: 494 Train loss: 0.014527 Validation loss: 0.011578\n",
            "Epoch: 495 Train loss: 0.014492 Validation loss: 0.011575\n",
            "Epoch: 496 Train loss: 0.014457 Validation loss: 0.011573\n",
            "Epoch: 497 Train loss: 0.014422 Validation loss: 0.011571\n",
            "Epoch: 498 Train loss: 0.014388 Validation loss: 0.011568\n",
            "Epoch: 499 Train loss: 0.014353 Validation loss: 0.011566\n",
            "Epoch: 500 Train loss: 0.014319 Validation loss: 0.011564\n",
            "Epoch: 501 Train loss: 0.014285 Validation loss: 0.011561\n",
            "Epoch: 502 Train loss: 0.014251 Validation loss: 0.011559\n",
            "Epoch: 503 Train loss: 0.014218 Validation loss: 0.011556\n",
            "Epoch: 504 Train loss: 0.014185 Validation loss: 0.011554\n",
            "Epoch: 505 Train loss: 0.014152 Validation loss: 0.011552\n",
            "Epoch: 506 Train loss: 0.014119 Validation loss: 0.01155\n",
            "Epoch: 507 Train loss: 0.014086 Validation loss: 0.011548\n",
            "Epoch: 508 Train loss: 0.014054 Validation loss: 0.011546\n",
            "Epoch: 509 Train loss: 0.014021 Validation loss: 0.011544\n",
            "Epoch: 510 Train loss: 0.013989 Validation loss: 0.011541\n",
            "Epoch: 511 Train loss: 0.013958 Validation loss: 0.01154\n",
            "Epoch: 512 Train loss: 0.013926 Validation loss: 0.011538\n",
            "Epoch: 513 Train loss: 0.013894 Validation loss: 0.011535\n",
            "Epoch: 514 Train loss: 0.013863 Validation loss: 0.011533\n",
            "Epoch: 515 Train loss: 0.013832 Validation loss: 0.011531\n",
            "Epoch: 516 Train loss: 0.013801 Validation loss: 0.01153\n",
            "Epoch: 517 Train loss: 0.01377 Validation loss: 0.011528\n",
            "Epoch: 518 Train loss: 0.01374 Validation loss: 0.011526\n",
            "Epoch: 519 Train loss: 0.01371 Validation loss: 0.011524\n",
            "Epoch: 520 Train loss: 0.01368 Validation loss: 0.011522\n",
            "Epoch: 521 Train loss: 0.01365 Validation loss: 0.01152\n",
            "Epoch: 522 Train loss: 0.01362 Validation loss: 0.011519\n",
            "Epoch: 523 Train loss: 0.01359 Validation loss: 0.011517\n",
            "Epoch: 524 Train loss: 0.013561 Validation loss: 0.011515\n",
            "Epoch: 525 Train loss: 0.013532 Validation loss: 0.011513\n",
            "Epoch: 526 Train loss: 0.013502 Validation loss: 0.011512\n",
            "Epoch: 527 Train loss: 0.013474 Validation loss: 0.01151\n",
            "Epoch: 528 Train loss: 0.013445 Validation loss: 0.011509\n",
            "Epoch: 529 Train loss: 0.013416 Validation loss: 0.011507\n",
            "Epoch: 530 Train loss: 0.013388 Validation loss: 0.011506\n",
            "Epoch: 531 Train loss: 0.01336 Validation loss: 0.011504\n",
            "Epoch: 532 Train loss: 0.013332 Validation loss: 0.011503\n",
            "Epoch: 533 Train loss: 0.013304 Validation loss: 0.011501\n",
            "Epoch: 534 Train loss: 0.013276 Validation loss: 0.0115\n",
            "Epoch: 535 Train loss: 0.013248 Validation loss: 0.011498\n",
            "Epoch: 536 Train loss: 0.013221 Validation loss: 0.011497\n",
            "Epoch: 537 Train loss: 0.013194 Validation loss: 0.011495\n",
            "Epoch: 538 Train loss: 0.013167 Validation loss: 0.011494\n",
            "Epoch: 539 Train loss: 0.01314 Validation loss: 0.011493\n",
            "Epoch: 540 Train loss: 0.013113 Validation loss: 0.011492\n",
            "Epoch: 541 Train loss: 0.013086 Validation loss: 0.011491\n",
            "Epoch: 542 Train loss: 0.01306 Validation loss: 0.011489\n",
            "Epoch: 543 Train loss: 0.013033 Validation loss: 0.011488\n",
            "Epoch: 544 Train loss: 0.013007 Validation loss: 0.011487\n",
            "Epoch: 545 Train loss: 0.012981 Validation loss: 0.011486\n",
            "Epoch: 546 Train loss: 0.012955 Validation loss: 0.011484\n",
            "Epoch: 547 Train loss: 0.01293 Validation loss: 0.011484\n",
            "Epoch: 548 Train loss: 0.012904 Validation loss: 0.011482\n",
            "Epoch: 549 Train loss: 0.012878 Validation loss: 0.011481\n",
            "Epoch: 550 Train loss: 0.012853 Validation loss: 0.01148\n",
            "Epoch: 551 Train loss: 0.012828 Validation loss: 0.011479\n",
            "Epoch: 552 Train loss: 0.012803 Validation loss: 0.011478\n",
            "Epoch: 553 Train loss: 0.012778 Validation loss: 0.011477\n",
            "Epoch: 554 Train loss: 0.012753 Validation loss: 0.011476\n",
            "Epoch: 555 Train loss: 0.012729 Validation loss: 0.011476\n",
            "Epoch: 556 Train loss: 0.012704 Validation loss: 0.011474\n",
            "Epoch: 557 Train loss: 0.01268 Validation loss: 0.011474\n",
            "Epoch: 558 Train loss: 0.012655 Validation loss: 0.011473\n",
            "Epoch: 559 Train loss: 0.012631 Validation loss: 0.011472\n",
            "Epoch: 560 Train loss: 0.012607 Validation loss: 0.011471\n",
            "Epoch: 561 Train loss: 0.012583 Validation loss: 0.011471\n",
            "Epoch: 562 Train loss: 0.01256 Validation loss: 0.01147\n",
            "Epoch: 563 Train loss: 0.012536 Validation loss: 0.011469\n",
            "Epoch: 564 Train loss: 0.012513 Validation loss: 0.011468\n",
            "Epoch: 565 Train loss: 0.012489 Validation loss: 0.011467\n",
            "Epoch: 566 Train loss: 0.012466 Validation loss: 0.011467\n",
            "Epoch: 567 Train loss: 0.012443 Validation loss: 0.011466\n",
            "Epoch: 568 Train loss: 0.01242 Validation loss: 0.011466\n",
            "Epoch: 569 Train loss: 0.012397 Validation loss: 0.011465\n",
            "Epoch: 570 Train loss: 0.012374 Validation loss: 0.011465\n",
            "Epoch: 571 Train loss: 0.012351 Validation loss: 0.011464\n",
            "Epoch: 572 Train loss: 0.012329 Validation loss: 0.011463\n",
            "Epoch: 573 Train loss: 0.012306 Validation loss: 0.011463\n",
            "Epoch: 574 Train loss: 0.012284 Validation loss: 0.011463\n",
            "Epoch: 575 Train loss: 0.012262 Validation loss: 0.011462\n",
            "Epoch: 576 Train loss: 0.01224 Validation loss: 0.011462\n",
            "Epoch: 577 Train loss: 0.012218 Validation loss: 0.011462\n",
            "Epoch: 578 Train loss: 0.012196 Validation loss: 0.011461\n",
            "Epoch: 579 Train loss: 0.012174 Validation loss: 0.01146\n",
            "Epoch: 580 Train loss: 0.012153 Validation loss: 0.01146\n",
            "Epoch: 581 Train loss: 0.012131 Validation loss: 0.01146\n",
            "Epoch: 582 Train loss: 0.01211 Validation loss: 0.01146\n",
            "Epoch: 583 Train loss: 0.012088 Validation loss: 0.011459\n",
            "Epoch: 584 Train loss: 0.012067 Validation loss: 0.011459\n",
            "Epoch: 585 Train loss: 0.012046 Validation loss: 0.011459\n",
            "Epoch: 586 Train loss: 0.012025 Validation loss: 0.011459\n",
            "Epoch: 587 Train loss: 0.012004 Validation loss: 0.011458\n",
            "Epoch: 588 Train loss: 0.011983 Validation loss: 0.011458\n",
            "Epoch: 589 Train loss: 0.011963 Validation loss: 0.011458\n",
            "Epoch: 590 Train loss: 0.011942 Validation loss: 0.011458\n",
            "Epoch: 591 Train loss: 0.011922 Validation loss: 0.011457\n",
            "Epoch: 592 Train loss: 0.011901 Validation loss: 0.011457\n",
            "Epoch: 593 Train loss: 0.011881 Validation loss: 0.011458\n",
            "Epoch: 594 Train loss: 0.011861 Validation loss: 0.011457\n",
            "Epoch: 595 Train loss: 0.01184 Validation loss: 0.011457\n",
            "Epoch: 596 Train loss: 0.011821 Validation loss: 0.011457\n",
            "Epoch: 597 Train loss: 0.011801 Validation loss: 0.011457\n",
            "Epoch: 598 Train loss: 0.011781 Validation loss: 0.011457\n",
            "Epoch: 599 Train loss: 0.011761 Validation loss: 0.011457\n",
            "Epoch: 600 Train loss: 0.011741 Validation loss: 0.011457\n",
            "Epoch: 601 Train loss: 0.011722 Validation loss: 0.011457\n",
            "Epoch: 602 Train loss: 0.011702 Validation loss: 0.011457\n",
            "Epoch: 603 Train loss: 0.011683 Validation loss: 0.011458\n",
            "Epoch: 604 Train loss: 0.011664 Validation loss: 0.011457\n",
            "Epoch: 605 Train loss: 0.011645 Validation loss: 0.011457\n",
            "Epoch: 606 Train loss: 0.011625 Validation loss: 0.011458\n",
            "Epoch: 607 Train loss: 0.011606 Validation loss: 0.011458\n",
            "Epoch: 608 Train loss: 0.011588 Validation loss: 0.011457\n",
            "Epoch: 609 Train loss: 0.011569 Validation loss: 0.011458\n",
            "Epoch: 610 Train loss: 0.01155 Validation loss: 0.011458\n",
            "Epoch: 611 Train loss: 0.011531 Validation loss: 0.011458\n",
            "Epoch: 612 Train loss: 0.011513 Validation loss: 0.011458\n",
            "Epoch: 613 Train loss: 0.011494 Validation loss: 0.011458\n",
            "Epoch: 614 Train loss: 0.011476 Validation loss: 0.011458\n",
            "Epoch: 615 Train loss: 0.011457 Validation loss: 0.011459\n",
            "Epoch: 616 Train loss: 0.011439 Validation loss: 0.011459\n",
            "Epoch: 617 Train loss: 0.011421 Validation loss: 0.01146\n",
            "Epoch: 618 Train loss: 0.011403 Validation loss: 0.011459\n",
            "Epoch: 619 Train loss: 0.011385 Validation loss: 0.01146\n",
            "Epoch: 620 Train loss: 0.011367 Validation loss: 0.011461\n",
            "Epoch: 621 Train loss: 0.011349 Validation loss: 0.011461\n",
            "Epoch: 622 Train loss: 0.011331 Validation loss: 0.011461\n",
            "Epoch: 623 Train loss: 0.011314 Validation loss: 0.011461\n",
            "Epoch: 624 Train loss: 0.011296 Validation loss: 0.011461\n",
            "Epoch: 625 Train loss: 0.011279 Validation loss: 0.011462\n",
            "Epoch: 626 Train loss: 0.011261 Validation loss: 0.011463\n",
            "Epoch: 627 Train loss: 0.011244 Validation loss: 0.011463\n",
            "Epoch: 628 Train loss: 0.011226 Validation loss: 0.011464\n",
            "Epoch: 629 Train loss: 0.011209 Validation loss: 0.011464\n",
            "Epoch: 630 Train loss: 0.011192 Validation loss: 0.011464\n",
            "Epoch: 631 Train loss: 0.011175 Validation loss: 0.011465\n",
            "Epoch: 632 Train loss: 0.011158 Validation loss: 0.011465\n",
            "Epoch: 633 Train loss: 0.011141 Validation loss: 0.011466\n",
            "Epoch: 634 Train loss: 0.011124 Validation loss: 0.011466\n",
            "Epoch: 635 Train loss: 0.011107 Validation loss: 0.011466\n",
            "Epoch: 636 Train loss: 0.01109 Validation loss: 0.011467\n",
            "Epoch: 637 Train loss: 0.011074 Validation loss: 0.011468\n",
            "Epoch: 638 Train loss: 0.011057 Validation loss: 0.011468\n",
            "Epoch: 639 Train loss: 0.01104 Validation loss: 0.011469\n",
            "Epoch: 640 Train loss: 0.011024 Validation loss: 0.01147\n",
            "Epoch: 641 Train loss: 0.011008 Validation loss: 0.01147\n",
            "Epoch: 642 Train loss: 0.010991 Validation loss: 0.011471\n",
            "Epoch: 643 Train loss: 0.010975 Validation loss: 0.011471\n",
            "Epoch: 644 Train loss: 0.010959 Validation loss: 0.011472\n",
            "Epoch: 645 Train loss: 0.010943 Validation loss: 0.011472\n",
            "Epoch: 646 Train loss: 0.010927 Validation loss: 0.011472\n",
            "Epoch: 647 Train loss: 0.010911 Validation loss: 0.011474\n",
            "Epoch: 648 Train loss: 0.010895 Validation loss: 0.011473\n",
            "Epoch: 649 Train loss: 0.010879 Validation loss: 0.011475\n",
            "Epoch: 650 Train loss: 0.010863 Validation loss: 0.011475\n",
            "Epoch: 651 Train loss: 0.010847 Validation loss: 0.011476\n",
            "Epoch: 652 Train loss: 0.010832 Validation loss: 0.011477\n",
            "Epoch: 653 Train loss: 0.010816 Validation loss: 0.011478\n",
            "Epoch: 654 Train loss: 0.0108 Validation loss: 0.011478\n",
            "Epoch: 655 Train loss: 0.010785 Validation loss: 0.011479\n",
            "Epoch: 656 Train loss: 0.010769 Validation loss: 0.011479\n",
            "Epoch: 657 Train loss: 0.010754 Validation loss: 0.01148\n",
            "Epoch: 658 Train loss: 0.010739 Validation loss: 0.011481\n",
            "Epoch: 659 Train loss: 0.010724 Validation loss: 0.011482\n",
            "Epoch: 660 Train loss: 0.010708 Validation loss: 0.011483\n",
            "Epoch: 661 Train loss: 0.010693 Validation loss: 0.011483\n",
            "Epoch: 662 Train loss: 0.010678 Validation loss: 0.011484\n",
            "Epoch: 663 Train loss: 0.010663 Validation loss: 0.011485\n",
            "Epoch: 664 Train loss: 0.010648 Validation loss: 0.011485\n",
            "Epoch: 665 Train loss: 0.010633 Validation loss: 0.011486\n",
            "Epoch: 666 Train loss: 0.010618 Validation loss: 0.011487\n",
            "Epoch: 667 Train loss: 0.010604 Validation loss: 0.011488\n",
            "Epoch: 668 Train loss: 0.010589 Validation loss: 0.011489\n",
            "Epoch: 669 Train loss: 0.010574 Validation loss: 0.011489\n",
            "Epoch: 670 Train loss: 0.01056 Validation loss: 0.01149\n",
            "Epoch: 671 Train loss: 0.010545 Validation loss: 0.011491\n",
            "Epoch: 672 Train loss: 0.01053 Validation loss: 0.011492\n",
            "Epoch: 673 Train loss: 0.010516 Validation loss: 0.011493\n",
            "Epoch: 674 Train loss: 0.010502 Validation loss: 0.011494\n",
            "Epoch: 675 Train loss: 0.010487 Validation loss: 0.011495\n",
            "Epoch: 676 Train loss: 0.010473 Validation loss: 0.011496\n",
            "Epoch: 677 Train loss: 0.010459 Validation loss: 0.011497\n",
            "Epoch: 678 Train loss: 0.010444 Validation loss: 0.011498\n",
            "Epoch: 679 Train loss: 0.01043 Validation loss: 0.011499\n",
            "Epoch: 680 Train loss: 0.010416 Validation loss: 0.011499\n",
            "Epoch: 681 Train loss: 0.010402 Validation loss: 0.011501\n",
            "Epoch: 682 Train loss: 0.010388 Validation loss: 0.011501\n",
            "Epoch: 683 Train loss: 0.010374 Validation loss: 0.011503\n",
            "Epoch: 684 Train loss: 0.01036 Validation loss: 0.011503\n",
            "Epoch: 685 Train loss: 0.010347 Validation loss: 0.011505\n",
            "Epoch: 686 Train loss: 0.010333 Validation loss: 0.011505\n",
            "Epoch: 687 Train loss: 0.010319 Validation loss: 0.011506\n",
            "Epoch: 688 Train loss: 0.010305 Validation loss: 0.011507\n",
            "Epoch: 689 Train loss: 0.010292 Validation loss: 0.011508\n",
            "Epoch: 690 Train loss: 0.010278 Validation loss: 0.011509\n",
            "Epoch: 691 Train loss: 0.010265 Validation loss: 0.01151\n",
            "Epoch: 692 Train loss: 0.010251 Validation loss: 0.011511\n",
            "Epoch: 693 Train loss: 0.010238 Validation loss: 0.011512\n",
            "Epoch: 694 Train loss: 0.010224 Validation loss: 0.011513\n",
            "Epoch: 695 Train loss: 0.010211 Validation loss: 0.011514\n",
            "Epoch: 696 Train loss: 0.010197 Validation loss: 0.011515\n",
            "Epoch: 697 Train loss: 0.010184 Validation loss: 0.011516\n",
            "Epoch: 698 Train loss: 0.010171 Validation loss: 0.011517\n",
            "Epoch: 699 Train loss: 0.010158 Validation loss: 0.011518\n",
            "Epoch: 700 Train loss: 0.010145 Validation loss: 0.01152\n",
            "Epoch: 701 Train loss: 0.010132 Validation loss: 0.01152\n",
            "Epoch: 702 Train loss: 0.010119 Validation loss: 0.011522\n",
            "Epoch: 703 Train loss: 0.010106 Validation loss: 0.011523\n",
            "Epoch: 704 Train loss: 0.010093 Validation loss: 0.011524\n",
            "Epoch: 705 Train loss: 0.01008 Validation loss: 0.011525\n",
            "Epoch: 706 Train loss: 0.010067 Validation loss: 0.011526\n",
            "Epoch: 707 Train loss: 0.010054 Validation loss: 0.011526\n",
            "Epoch: 708 Train loss: 0.010041 Validation loss: 0.011528\n",
            "Epoch: 709 Train loss: 0.010029 Validation loss: 0.011529\n",
            "Epoch: 710 Train loss: 0.010016 Validation loss: 0.01153\n",
            "Epoch: 711 Train loss: 0.010003 Validation loss: 0.011531\n",
            "Epoch: 712 Train loss: 0.0099907 Validation loss: 0.011532\n",
            "Epoch: 713 Train loss: 0.0099781 Validation loss: 0.011533\n",
            "Epoch: 714 Train loss: 0.0099656 Validation loss: 0.011534\n",
            "Epoch: 715 Train loss: 0.0099532 Validation loss: 0.011535\n",
            "Epoch: 716 Train loss: 0.0099407 Validation loss: 0.011537\n",
            "Epoch: 717 Train loss: 0.0099284 Validation loss: 0.011537\n",
            "Epoch: 718 Train loss: 0.009916 Validation loss: 0.011539\n",
            "Epoch: 719 Train loss: 0.0099037 Validation loss: 0.01154\n",
            "Epoch: 720 Train loss: 0.0098913 Validation loss: 0.011541\n",
            "Epoch: 721 Train loss: 0.0098792 Validation loss: 0.011542\n",
            "Epoch: 722 Train loss: 0.0098669 Validation loss: 0.011543\n",
            "Epoch: 723 Train loss: 0.0098548 Validation loss: 0.011545\n",
            "Epoch: 724 Train loss: 0.0098427 Validation loss: 0.011546\n",
            "Epoch: 725 Train loss: 0.0098306 Validation loss: 0.011547\n",
            "Epoch: 726 Train loss: 0.0098186 Validation loss: 0.011548\n",
            "Epoch: 727 Train loss: 0.0098066 Validation loss: 0.011549\n",
            "Epoch: 728 Train loss: 0.0097946 Validation loss: 0.011551\n",
            "Epoch: 729 Train loss: 0.0097827 Validation loss: 0.011552\n",
            "Epoch: 730 Train loss: 0.0097708 Validation loss: 0.011553\n",
            "Epoch: 731 Train loss: 0.0097589 Validation loss: 0.011554\n",
            "Epoch: 732 Train loss: 0.0097472 Validation loss: 0.011555\n",
            "Epoch: 733 Train loss: 0.0097354 Validation loss: 0.011556\n",
            "Epoch: 734 Train loss: 0.0097237 Validation loss: 0.011557\n",
            "Epoch: 735 Train loss: 0.009712 Validation loss: 0.011559\n",
            "Epoch: 736 Train loss: 0.0097003 Validation loss: 0.01156\n",
            "Epoch: 737 Train loss: 0.0096887 Validation loss: 0.011562\n",
            "Epoch: 738 Train loss: 0.0096771 Validation loss: 0.011562\n",
            "Epoch: 739 Train loss: 0.0096655 Validation loss: 0.011564\n",
            "Epoch: 740 Train loss: 0.0096541 Validation loss: 0.011565\n",
            "Epoch: 741 Train loss: 0.0096425 Validation loss: 0.011566\n",
            "Epoch: 742 Train loss: 0.0096311 Validation loss: 0.011567\n",
            "Epoch: 743 Train loss: 0.0096197 Validation loss: 0.011568\n",
            "Epoch: 744 Train loss: 0.0096083 Validation loss: 0.01157\n",
            "Epoch: 745 Train loss: 0.009597 Validation loss: 0.011571\n",
            "Epoch: 746 Train loss: 0.0095857 Validation loss: 0.011573\n",
            "Epoch: 747 Train loss: 0.0095744 Validation loss: 0.011574\n",
            "Epoch: 748 Train loss: 0.0095632 Validation loss: 0.011575\n",
            "Epoch: 749 Train loss: 0.009552 Validation loss: 0.011576\n",
            "Epoch: 750 Train loss: 0.0095408 Validation loss: 0.011577\n",
            "Epoch: 751 Train loss: 0.0095297 Validation loss: 0.011579\n",
            "Epoch: 752 Train loss: 0.0095186 Validation loss: 0.01158\n",
            "Epoch: 753 Train loss: 0.0095075 Validation loss: 0.011581\n",
            "Epoch: 754 Train loss: 0.0094965 Validation loss: 0.011583\n",
            "Epoch: 755 Train loss: 0.0094855 Validation loss: 0.011584\n",
            "Epoch: 756 Train loss: 0.0094745 Validation loss: 0.011585\n",
            "Epoch: 757 Train loss: 0.0094636 Validation loss: 0.011586\n",
            "Epoch: 758 Train loss: 0.0094526 Validation loss: 0.011587\n",
            "Epoch: 759 Train loss: 0.0094417 Validation loss: 0.011589\n",
            "Epoch: 760 Train loss: 0.009431 Validation loss: 0.011589\n",
            "Epoch: 761 Train loss: 0.0094201 Validation loss: 0.011591\n",
            "Epoch: 762 Train loss: 0.0094093 Validation loss: 0.011593\n",
            "Epoch: 763 Train loss: 0.0093986 Validation loss: 0.011594\n",
            "Epoch: 764 Train loss: 0.0093879 Validation loss: 0.011595\n",
            "Epoch: 765 Train loss: 0.0093772 Validation loss: 0.011597\n",
            "Epoch: 766 Train loss: 0.0093666 Validation loss: 0.011598\n",
            "Epoch: 767 Train loss: 0.009356 Validation loss: 0.011599\n",
            "Epoch: 768 Train loss: 0.0093453 Validation loss: 0.0116\n",
            "Epoch: 769 Train loss: 0.0093348 Validation loss: 0.011601\n",
            "Epoch: 770 Train loss: 0.0093243 Validation loss: 0.011603\n",
            "Epoch: 771 Train loss: 0.0093137 Validation loss: 0.011604\n",
            "Epoch: 772 Train loss: 0.0093033 Validation loss: 0.011605\n",
            "Epoch: 773 Train loss: 0.0092929 Validation loss: 0.011607\n",
            "Epoch: 774 Train loss: 0.0092825 Validation loss: 0.011608\n",
            "Epoch: 775 Train loss: 0.009272 Validation loss: 0.011609\n",
            "Epoch: 776 Train loss: 0.0092617 Validation loss: 0.01161\n",
            "Epoch: 777 Train loss: 0.0092514 Validation loss: 0.011612\n",
            "Epoch: 778 Train loss: 0.0092411 Validation loss: 0.011613\n",
            "Epoch: 779 Train loss: 0.0092308 Validation loss: 0.011614\n",
            "Epoch: 780 Train loss: 0.0092206 Validation loss: 0.011616\n",
            "Epoch: 781 Train loss: 0.0092104 Validation loss: 0.011617\n",
            "Epoch: 782 Train loss: 0.0092002 Validation loss: 0.011619\n",
            "Epoch: 783 Train loss: 0.0091901 Validation loss: 0.01162\n",
            "Epoch: 784 Train loss: 0.00918 Validation loss: 0.011621\n",
            "Epoch: 785 Train loss: 0.0091699 Validation loss: 0.011622\n",
            "Epoch: 786 Train loss: 0.0091598 Validation loss: 0.011623\n",
            "Epoch: 787 Train loss: 0.0091498 Validation loss: 0.011625\n",
            "Epoch: 788 Train loss: 0.0091398 Validation loss: 0.011627\n",
            "Epoch: 789 Train loss: 0.0091298 Validation loss: 0.011628\n",
            "Epoch: 790 Train loss: 0.0091198 Validation loss: 0.011629\n",
            "Epoch: 791 Train loss: 0.0091099 Validation loss: 0.01163\n",
            "Epoch: 792 Train loss: 0.0091 Validation loss: 0.011631\n",
            "Epoch: 793 Train loss: 0.00909 Validation loss: 0.011633\n",
            "Epoch: 794 Train loss: 0.0090803 Validation loss: 0.011634\n",
            "Epoch: 795 Train loss: 0.0090704 Validation loss: 0.011635\n",
            "Epoch: 796 Train loss: 0.0090607 Validation loss: 0.011637\n",
            "Epoch: 797 Train loss: 0.0090509 Validation loss: 0.011638\n",
            "Epoch: 798 Train loss: 0.0090412 Validation loss: 0.011639\n",
            "Epoch: 799 Train loss: 0.0090314 Validation loss: 0.011641\n",
            "Epoch: 800 Train loss: 0.0090217 Validation loss: 0.011642\n",
            "Epoch: 801 Train loss: 0.0090121 Validation loss: 0.011643\n",
            "Epoch: 802 Train loss: 0.0090024 Validation loss: 0.011645\n",
            "Epoch: 803 Train loss: 0.0089929 Validation loss: 0.011646\n",
            "Epoch: 804 Train loss: 0.0089833 Validation loss: 0.011647\n",
            "Epoch: 805 Train loss: 0.0089736 Validation loss: 0.011649\n",
            "Epoch: 806 Train loss: 0.0089641 Validation loss: 0.01165\n",
            "Epoch: 807 Train loss: 0.0089547 Validation loss: 0.011652\n",
            "Epoch: 808 Train loss: 0.0089452 Validation loss: 0.011653\n",
            "Epoch: 809 Train loss: 0.0089357 Validation loss: 0.011654\n",
            "Epoch: 810 Train loss: 0.0089263 Validation loss: 0.011656\n",
            "Epoch: 811 Train loss: 0.0089168 Validation loss: 0.011657\n",
            "Epoch: 812 Train loss: 0.0089075 Validation loss: 0.011658\n",
            "Epoch: 813 Train loss: 0.0088981 Validation loss: 0.011659\n",
            "Epoch: 814 Train loss: 0.0088888 Validation loss: 0.01166\n",
            "Epoch: 815 Train loss: 0.0088796 Validation loss: 0.011662\n",
            "Epoch: 816 Train loss: 0.0088702 Validation loss: 0.011663\n",
            "Epoch: 817 Train loss: 0.008861 Validation loss: 0.011665\n",
            "Epoch: 818 Train loss: 0.0088518 Validation loss: 0.011665\n",
            "Epoch: 819 Train loss: 0.0088425 Validation loss: 0.011667\n",
            "Epoch: 820 Train loss: 0.0088333 Validation loss: 0.011669\n",
            "Epoch: 821 Train loss: 0.0088241 Validation loss: 0.01167\n",
            "Epoch: 822 Train loss: 0.008815 Validation loss: 0.011671\n",
            "Epoch: 823 Train loss: 0.0088059 Validation loss: 0.011673\n",
            "Epoch: 824 Train loss: 0.0087968 Validation loss: 0.011674\n",
            "Epoch: 825 Train loss: 0.0087877 Validation loss: 0.011675\n",
            "Epoch: 826 Train loss: 0.0087787 Validation loss: 0.011677\n",
            "Epoch: 827 Train loss: 0.0087697 Validation loss: 0.011678\n",
            "Epoch: 828 Train loss: 0.0087607 Validation loss: 0.011679\n",
            "Epoch: 829 Train loss: 0.0087517 Validation loss: 0.011681\n",
            "Epoch: 830 Train loss: 0.0087428 Validation loss: 0.011682\n",
            "Epoch: 831 Train loss: 0.0087338 Validation loss: 0.011683\n",
            "Epoch: 832 Train loss: 0.0087249 Validation loss: 0.011684\n",
            "Epoch: 833 Train loss: 0.008716 Validation loss: 0.011686\n",
            "Epoch: 834 Train loss: 0.0087071 Validation loss: 0.011687\n",
            "Epoch: 835 Train loss: 0.0086983 Validation loss: 0.011688\n",
            "Epoch: 836 Train loss: 0.0086895 Validation loss: 0.01169\n",
            "Epoch: 837 Train loss: 0.0086807 Validation loss: 0.011691\n",
            "Epoch: 838 Train loss: 0.0086719 Validation loss: 0.011692\n",
            "Epoch: 839 Train loss: 0.0086632 Validation loss: 0.011693\n",
            "Epoch: 840 Train loss: 0.0086544 Validation loss: 0.011695\n",
            "Epoch: 841 Train loss: 0.0086457 Validation loss: 0.011696\n",
            "Epoch: 842 Train loss: 0.008637 Validation loss: 0.011697\n",
            "Epoch: 843 Train loss: 0.0086284 Validation loss: 0.011699\n",
            "Epoch: 844 Train loss: 0.0086197 Validation loss: 0.0117\n",
            "Epoch: 845 Train loss: 0.0086111 Validation loss: 0.011701\n",
            "Epoch: 846 Train loss: 0.0086025 Validation loss: 0.011703\n",
            "Epoch: 847 Train loss: 0.0085939 Validation loss: 0.011704\n",
            "Epoch: 848 Train loss: 0.0085854 Validation loss: 0.011705\n",
            "Epoch: 849 Train loss: 0.0085768 Validation loss: 0.011707\n",
            "Epoch: 850 Train loss: 0.0085683 Validation loss: 0.011708\n",
            "Epoch: 851 Train loss: 0.0085598 Validation loss: 0.011709\n",
            "Epoch: 852 Train loss: 0.0085513 Validation loss: 0.011711\n",
            "Epoch: 853 Train loss: 0.0085429 Validation loss: 0.011713\n",
            "Epoch: 854 Train loss: 0.0085344 Validation loss: 0.011714\n",
            "Epoch: 855 Train loss: 0.008526 Validation loss: 0.011715\n",
            "Epoch: 856 Train loss: 0.0085176 Validation loss: 0.011717\n",
            "Epoch: 857 Train loss: 0.0085093 Validation loss: 0.011718\n",
            "Epoch: 858 Train loss: 0.0085009 Validation loss: 0.011719\n",
            "Epoch: 859 Train loss: 0.0084926 Validation loss: 0.01172\n",
            "Epoch: 860 Train loss: 0.0084843 Validation loss: 0.011721\n",
            "Epoch: 861 Train loss: 0.008476 Validation loss: 0.011722\n",
            "Epoch: 862 Train loss: 0.0084677 Validation loss: 0.011724\n",
            "Epoch: 863 Train loss: 0.0084595 Validation loss: 0.011725\n",
            "Epoch: 864 Train loss: 0.0084512 Validation loss: 0.011727\n",
            "Epoch: 865 Train loss: 0.008443 Validation loss: 0.011728\n",
            "Epoch: 866 Train loss: 0.0084349 Validation loss: 0.011729\n",
            "Epoch: 867 Train loss: 0.0084267 Validation loss: 0.01173\n",
            "Epoch: 868 Train loss: 0.0084185 Validation loss: 0.011732\n",
            "Epoch: 869 Train loss: 0.0084104 Validation loss: 0.011733\n",
            "Epoch: 870 Train loss: 0.0084023 Validation loss: 0.011735\n",
            "Epoch: 871 Train loss: 0.0083942 Validation loss: 0.011736\n",
            "Epoch: 872 Train loss: 0.0083861 Validation loss: 0.011738\n",
            "Epoch: 873 Train loss: 0.0083781 Validation loss: 0.011739\n",
            "Epoch: 874 Train loss: 0.0083701 Validation loss: 0.01174\n",
            "Epoch: 875 Train loss: 0.0083621 Validation loss: 0.011742\n",
            "Epoch: 876 Train loss: 0.0083541 Validation loss: 0.011743\n",
            "Epoch: 877 Train loss: 0.0083461 Validation loss: 0.011744\n",
            "Epoch: 878 Train loss: 0.0083382 Validation loss: 0.011745\n",
            "Epoch: 879 Train loss: 0.0083302 Validation loss: 0.011746\n",
            "Epoch: 880 Train loss: 0.0083223 Validation loss: 0.011748\n",
            "Epoch: 881 Train loss: 0.0083144 Validation loss: 0.011749\n",
            "Epoch: 882 Train loss: 0.0083066 Validation loss: 0.011751\n",
            "Epoch: 883 Train loss: 0.0082987 Validation loss: 0.011752\n",
            "Epoch: 884 Train loss: 0.0082909 Validation loss: 0.011753\n",
            "Epoch: 885 Train loss: 0.008283 Validation loss: 0.011754\n",
            "Epoch: 886 Train loss: 0.0082752 Validation loss: 0.011755\n",
            "Epoch: 887 Train loss: 0.0082675 Validation loss: 0.011758\n",
            "Epoch: 888 Train loss: 0.0082597 Validation loss: 0.011759\n",
            "Epoch: 889 Train loss: 0.0082519 Validation loss: 0.01176\n",
            "Epoch: 890 Train loss: 0.0082442 Validation loss: 0.011762\n",
            "Epoch: 891 Train loss: 0.0082366 Validation loss: 0.011763\n",
            "Epoch: 892 Train loss: 0.0082289 Validation loss: 0.011764\n",
            "Epoch: 893 Train loss: 0.0082212 Validation loss: 0.011765\n",
            "Epoch: 894 Train loss: 0.0082135 Validation loss: 0.011766\n",
            "Epoch: 895 Train loss: 0.0082058 Validation loss: 0.011767\n",
            "Epoch: 896 Train loss: 0.0081983 Validation loss: 0.011769\n",
            "Epoch: 897 Train loss: 0.0081907 Validation loss: 0.011771\n",
            "Epoch: 898 Train loss: 0.0081831 Validation loss: 0.011772\n",
            "Epoch: 899 Train loss: 0.0081755 Validation loss: 0.011773\n",
            "Epoch: 900 Train loss: 0.008168 Validation loss: 0.011774\n",
            "Epoch: 901 Train loss: 0.0081604 Validation loss: 0.011776\n",
            "Epoch: 902 Train loss: 0.008153 Validation loss: 0.011777\n",
            "Epoch: 903 Train loss: 0.0081455 Validation loss: 0.011778\n",
            "Epoch: 904 Train loss: 0.008138 Validation loss: 0.011779\n",
            "Epoch: 905 Train loss: 0.0081306 Validation loss: 0.011781\n",
            "Epoch: 906 Train loss: 0.0081231 Validation loss: 0.011782\n",
            "Epoch: 907 Train loss: 0.0081157 Validation loss: 0.011783\n",
            "Epoch: 908 Train loss: 0.0081082 Validation loss: 0.011785\n",
            "Epoch: 909 Train loss: 0.0081009 Validation loss: 0.011786\n",
            "Epoch: 910 Train loss: 0.0080935 Validation loss: 0.011787\n",
            "Epoch: 911 Train loss: 0.0080862 Validation loss: 0.011788\n",
            "Epoch: 912 Train loss: 0.0080789 Validation loss: 0.01179\n",
            "Epoch: 913 Train loss: 0.0080715 Validation loss: 0.011791\n",
            "Epoch: 914 Train loss: 0.0080643 Validation loss: 0.011792\n",
            "Epoch: 915 Train loss: 0.008057 Validation loss: 0.011793\n",
            "Epoch: 916 Train loss: 0.0080497 Validation loss: 0.011794\n",
            "Epoch: 917 Train loss: 0.0080425 Validation loss: 0.011796\n",
            "Epoch: 918 Train loss: 0.0080352 Validation loss: 0.011797\n",
            "Epoch: 919 Train loss: 0.008028 Validation loss: 0.011798\n",
            "Epoch: 920 Train loss: 0.0080208 Validation loss: 0.011799\n",
            "Epoch: 921 Train loss: 0.0080137 Validation loss: 0.011801\n",
            "Epoch: 922 Train loss: 0.0080065 Validation loss: 0.011802\n",
            "Epoch: 923 Train loss: 0.0079993 Validation loss: 0.011803\n",
            "Epoch: 924 Train loss: 0.0079922 Validation loss: 0.011805\n",
            "Epoch: 925 Train loss: 0.0079851 Validation loss: 0.011806\n",
            "Epoch: 926 Train loss: 0.007978 Validation loss: 0.011808\n",
            "Epoch: 927 Train loss: 0.007971 Validation loss: 0.011809\n",
            "Epoch: 928 Train loss: 0.0079639 Validation loss: 0.01181\n",
            "Epoch: 929 Train loss: 0.0079569 Validation loss: 0.011811\n",
            "Epoch: 930 Train loss: 0.0079498 Validation loss: 0.011812\n",
            "Epoch: 931 Train loss: 0.0079428 Validation loss: 0.011814\n",
            "Epoch: 932 Train loss: 0.0079358 Validation loss: 0.011815\n",
            "Epoch: 933 Train loss: 0.0079289 Validation loss: 0.011816\n",
            "Epoch: 934 Train loss: 0.0079219 Validation loss: 0.011817\n",
            "Epoch: 935 Train loss: 0.007915 Validation loss: 0.011819\n",
            "Epoch: 936 Train loss: 0.007908 Validation loss: 0.01182\n",
            "Epoch: 937 Train loss: 0.0079011 Validation loss: 0.011822\n",
            "Epoch: 938 Train loss: 0.0078942 Validation loss: 0.011823\n",
            "Epoch: 939 Train loss: 0.0078874 Validation loss: 0.011824\n",
            "Epoch: 940 Train loss: 0.0078805 Validation loss: 0.011825\n",
            "Epoch: 941 Train loss: 0.0078737 Validation loss: 0.011826\n",
            "Epoch: 942 Train loss: 0.0078668 Validation loss: 0.011827\n",
            "Epoch: 943 Train loss: 0.00786 Validation loss: 0.011829\n",
            "Epoch: 944 Train loss: 0.0078532 Validation loss: 0.01183\n",
            "Epoch: 945 Train loss: 0.0078464 Validation loss: 0.011832\n",
            "Epoch: 946 Train loss: 0.0078397 Validation loss: 0.011833\n",
            "Epoch: 947 Train loss: 0.0078329 Validation loss: 0.011834\n",
            "Epoch: 948 Train loss: 0.0078261 Validation loss: 0.011835\n",
            "Epoch: 949 Train loss: 0.0078195 Validation loss: 0.011836\n",
            "Epoch: 950 Train loss: 0.0078128 Validation loss: 0.011838\n",
            "Epoch: 951 Train loss: 0.0078061 Validation loss: 0.011839\n",
            "Epoch: 952 Train loss: 0.0077995 Validation loss: 0.01184\n",
            "Epoch: 953 Train loss: 0.0077928 Validation loss: 0.011841\n",
            "Epoch: 954 Train loss: 0.0077862 Validation loss: 0.011842\n",
            "Epoch: 955 Train loss: 0.0077796 Validation loss: 0.011843\n",
            "Epoch: 956 Train loss: 0.0077729 Validation loss: 0.011844\n",
            "Epoch: 957 Train loss: 0.0077663 Validation loss: 0.011846\n",
            "Epoch: 958 Train loss: 0.0077598 Validation loss: 0.011847\n",
            "Epoch: 959 Train loss: 0.0077532 Validation loss: 0.011848\n",
            "Epoch: 960 Train loss: 0.0077467 Validation loss: 0.011849\n",
            "Epoch: 961 Train loss: 0.0077401 Validation loss: 0.011851\n",
            "Epoch: 962 Train loss: 0.0077336 Validation loss: 0.011852\n",
            "Epoch: 963 Train loss: 0.0077272 Validation loss: 0.011853\n",
            "Epoch: 964 Train loss: 0.0077207 Validation loss: 0.011855\n",
            "Epoch: 965 Train loss: 0.0077142 Validation loss: 0.011856\n",
            "Epoch: 966 Train loss: 0.0077077 Validation loss: 0.011857\n",
            "Epoch: 967 Train loss: 0.0077013 Validation loss: 0.011858\n",
            "Epoch: 968 Train loss: 0.0076949 Validation loss: 0.011859\n",
            "Epoch: 969 Train loss: 0.0076886 Validation loss: 0.011861\n",
            "Epoch: 970 Train loss: 0.0076821 Validation loss: 0.011861\n",
            "Epoch: 971 Train loss: 0.0076758 Validation loss: 0.011863\n",
            "Epoch: 972 Train loss: 0.0076694 Validation loss: 0.011864\n",
            "Epoch: 973 Train loss: 0.007663 Validation loss: 0.011865\n",
            "Epoch: 974 Train loss: 0.0076567 Validation loss: 0.011867\n",
            "Epoch: 975 Train loss: 0.0076504 Validation loss: 0.011868\n",
            "Epoch: 976 Train loss: 0.0076441 Validation loss: 0.011869\n",
            "Epoch: 977 Train loss: 0.0076378 Validation loss: 0.01187\n",
            "Epoch: 978 Train loss: 0.0076316 Validation loss: 0.011871\n",
            "Epoch: 979 Train loss: 0.0076253 Validation loss: 0.011873\n",
            "Epoch: 980 Train loss: 0.0076191 Validation loss: 0.011874\n",
            "Epoch: 981 Train loss: 0.0076129 Validation loss: 0.011875\n",
            "Epoch: 982 Train loss: 0.0076066 Validation loss: 0.011876\n",
            "Epoch: 983 Train loss: 0.0076005 Validation loss: 0.011877\n",
            "Epoch: 984 Train loss: 0.0075943 Validation loss: 0.011879\n",
            "Epoch: 985 Train loss: 0.0075881 Validation loss: 0.01188\n",
            "Epoch: 986 Train loss: 0.007582 Validation loss: 0.011881\n",
            "Epoch: 987 Train loss: 0.0075759 Validation loss: 0.011882\n",
            "Epoch: 988 Train loss: 0.0075697 Validation loss: 0.011883\n",
            "Epoch: 989 Train loss: 0.0075637 Validation loss: 0.011884\n",
            "Epoch: 990 Train loss: 0.0075576 Validation loss: 0.011885\n",
            "Epoch: 991 Train loss: 0.0075515 Validation loss: 0.011887\n",
            "Epoch: 992 Train loss: 0.0075454 Validation loss: 0.011888\n",
            "Epoch: 993 Train loss: 0.0075394 Validation loss: 0.011889\n",
            "Epoch: 994 Train loss: 0.0075334 Validation loss: 0.01189\n",
            "Epoch: 995 Train loss: 0.0075274 Validation loss: 0.011891\n",
            "Epoch: 996 Train loss: 0.0075213 Validation loss: 0.011893\n",
            "Epoch: 997 Train loss: 0.0075154 Validation loss: 0.011894\n",
            "Epoch: 998 Train loss: 0.0075095 Validation loss: 0.011895\n",
            "Epoch: 999 Train loss: 0.0075035 Validation loss: 0.011896\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gkaUDmA8Ps6w"
      },
      "source": [
        "Predicting with this model shows overfitting. For recognizing overfitting a comparison of the validation and training loss is very useful. If the training loss decreases during training while the validation loss consistently increases, the model you are training is probably overfitting. Plotting the models prediction and the target also shows that there is a significant discrepancy between the target and the prediction of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3Sq-9xhWPxI4",
        "outputId": "75099240-fe7b-43e9-f6c6-ae4d4403071d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "y_pred = big_mdl(x)\n",
        "# Predict on x with \"big_mdl\"\n",
        "plt.scatter(x_train_overfit, y_train_overfit)\n",
        "plt.plot(x, y_true)\n",
        "plt.plot(x, y_pred.numpy())\n",
        "plt.legend([\"Target\", \"Prediction\", \"Training samples\"])\n",
        "plt.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD4CAYAAADvsV2wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOzdd1hUZ9r48e8zw9B7VZogooKAoFixJlFjqjExiembvkl2s5uN+2o2m92U9xfzuiW7aaaYXkwzpGiiib0rCtilq4ACoiAoZZg5vz8OEERQyjCHGZ7PdXEBZ86cc4/CzTNPuR+hKAqSJEmS/dNpHYAkSZJkHTLhS5Ik9REy4UuSJPURMuFLkiT1ETLhS5Ik9REOWgfQHn9/fyUiIkLrMCRJkmzKrl27TiqKEtDWY7024UdERJCWlqZ1GJIkSTZFCHGkvcdkl44kSVIfIRO+JElSHyETviRJUh8hE74kSVIfIRO+JElSH9FrZ+n0VanpRSxaeZjiihqCvV2YN2MIs5JCtA5LkiQ7IBN+L5KaXsSCZXupMZoAKKqoYcGyvQAy6UuS1G2yS6cXWbTyMDVGEwIz/lTiQAM1RhOLVh7WOjRJslup6UWkLFxD5PzlpCxcQ2p6kdYh9RjZwu9FPCoP8y/DD0zT7cJD1FCluPCRaRovV9ykdWiSZJf62rtqmfB7g/pzsPo5fnB6kxrFiR9MYzmshJGky+ERh++IdjwFynUghEVvK8cLpL6u6V11S03vqu3xd0EmfK2dzIEv7oTSgxyLuJm5udM50eACwPsmyBED+BOfQeZnkHibxW7b11o2ktSW4oqaTh23dbIPX0vHM+Hd6VB1Am7/ish73mL+7HGEeLsggBBvF6Jm/QVCkuGXZ6GhzmK3vljLRpL6imBvl04dt3Wyha+V0oPwwbXg6AF3fwd+UYDaur6ghe35FHw8G/anwvBbLHL7vtaykaS2zJsx5Lx3ugAuBj3zZgzRMKqeI1v4Wqg5DZ/NBQdnuPfH5mTfroFTwTcKdn9gsRD6WstGktoyKymEF2fHn/eu+sXZ8XbbrSlb+FpY9TRUHoPf/Aje4Zc+X6eD+Dmw/iWoLgX3wG6H0NdaNlLf09FJCW2+q7ZTsoVvbUe3QfrHMO5RCBvd8efFXgcocGi5RcLoay0bqW9pmpRQVFGDwq+TEux5jn1HyIRvRanpRex8fx4lijeXp43t3A9fYCx4hUHuGovFMysphM3zLyN/3lA2j9rErKJ/wt6vwNRgsXtIkhbkpIS2WSThCyHeFUKUCiH2tfO4EEL8VwiRI4TYI4QYYYn72pLU9CI+XpbKKPMeljTMJLdS6VyLQwiImAgFm8Bstlxgh5bD6+Ng83/UZP/1fbBkGpTnWu4ekmRlclJC2yzVwn8fuPIij88Eohs/HgTesNB9bcailYe5jRWcUVz41HQ50IUWR+REqDkFpQcsE1TpQZQvf4O5XxwNv9/LsumbeMbwBKeKsjj1ylTWrFttmftIkpVdalKCoig0mCzYcLIRFhm0VRRlgxAi4iKnXA98qCiKAmwTQngLIforinLcEve3BacrTjPDaSffmlKoxrX5eKdaHOFj1c+FO6Ff3CVPrzWayC2rJqe0mqPl5yiurKW4ooYTlbWcqann9bqnCMeR6bn3U74wvfFZyWwSwXzk+CJxa+/lsf0vExeXQFSAO4lh3gR4OHXiVUuSNtqblHDjiBDu/yCN7XnlVNc3EObjyg1JITwwaSDuTvY/h8VarzAEONbi+8LGY+clfCHEg6jvAAgP78DsFRsyx2MfbsY6vjWlnHe8U9MgfSLB2QuOZ1zwUE29ib1FlaQfPU3GsQoOn6iioPwsZuXXc/zcHOnv7UyYrytjTYdIOnqYj/3/gPGkH9T+2m+fpwRzV/18ljn+jT+UPMUNx56jqvGPVKS/G8kDfJg6NJDJgwNw6wO/JJLtaZp80DRLp7+XM4ODPPjvmhz83By5PikYX1dHMgsr+e+abL7aVcibd44kLsRL48h7Vq/6bVUU5S3gLYDk5GTlEqfblIf90jlx3Jcdyq/THjs9DVII6J8IxelU1hjZknOSrXnl7D56moPHqzA1ZvdwX1di+3tyTUJ/BvfzYHCQB+G+rjgb9L9e6+MXqXEO4v9KRnHGeOEgba4SwkPGJ/jY8P/YnZDKnvH/ZdfRCnbkn2bVgRK+3FWIk4OOyYMDuHV0GJMHB6LXWbbWjyR1R9N0S5NZ4Y+fZ/BdZjF3jh3AU1fF4OL46+9CWsEpfv9ZOnPf3sbH941heJi3hlH3LGsl/CIgrMX3oY3HLK43FQRriuVExVkynbdzwH8awWfduhSbyaywp7ACkzGC4cc/YezzK6gxO+DmqGd4mDcPTx7IiHAfEsO88XO/RLfLmWLIXcPnutmcMbafpLeZY1lsuJPHsj5gZMQ4Rk56jAcnQYPJzM6C06zcf4If9hxn1YESQrxduGPsAO4cN6BPvDWWbMeilYf5LrOYP185hEemDLrg8eQIX7787XhufWsrD3yYxve/m0CQp7MGkfY8a/1mfgc8JoRYCowBKnui/z41vYiXl61jIa/zXzGbnRVDNSsI1rI4WZwowJ1zfFEWzrwbOp7kT1TWsiG7jA1ZZWzKOUnFOSNX6714zdDAUyPNDBkxjqRwbwz6To69Zy4Fxcz758Zf9DQXg57Qq/4MWeXw8zMQMhIGjMNBr2NclB/jovx46qoYfjlYwifbj/DST4d4c0Mu96VE8psJkTLxS5r7ce9xFq/P5bYx4Twyrh/seBvyN6ir3b1CYchMGHoNId4uvHPXKG54fTN/WJrBJ/ePQWeH71iFOo7azYsI8RkwBfAHSoC/AQYARVEWCyEE8CrqTJ5zwG8URUm72DWTk5OVtLSLnnKBlIVrKK+oYL3THzmiBHFz/TOAIMTbhc3zL+vsy+qWlIVrKGockL1Pv5y/Gj5hTO2rOHiHtBtLrdHEzoJTbMgqY0PWSQ6XVAEQ4OHEpOgAJg32Z3LAWbzfHgXXvAzJv+lacIsngoMzKScXNMfYWkjLdyC1lfDWFDDWwEMb2l3pm3msglfWZPPLwVICPZxYcNVQZiWGICxc1lmSOqK8uo7L/7WeAX5ufDW1AsMPv4dzJ8EnAtz7QXk2nCuHoHiY/SYEDWPpjqPMX7aXF2bFccfYAVq/hC4RQuxSFCW5rccsNUtn7iUeV4BHLXGviymuqEHBiVcabuAFw3tM0WWyzpyoydzblvccoztEgTmIEnwRLY4rikJuWTXrs06yIauM7fnl1BrNOOp1JEf4MH/EUCZFBxDT3+PXpKko4OgOZYe6FtiZ43BiD1z+N+aNbHsmwwUrbp294OYP4Z0r4Kt74c5U0F/4ozM8zJt37h5F+tHT/P27/fzx80w+2XaUl25SZ/lIkjW9sPwgZ+saeDt6B4Yv/g794mHuZ7+ucDebYP83sPIp9Wf75g+5ZdQVfL+nmEUrD3NtQjBergZNX4Ol2dV77mBvF4oqavjcNJWHHb7nQf0PrDMnalIQrCkWgZlRusOsMql/cPt5OvPj3uONXTUnm1vYA/3duHVUOJMG+zN2oB+uju381wgB/oO7nvBzflY/D57BrKDzZzJcdFyhXzxc829I/S2s/V+44m/t3iIp3IdvHknhq12F/O+Kg1z9340smBnDnWMH2OXbZKn32ZF/im/Si3grdi+BW16EmOvgxnfAocX4lk4P8TdBxAT49GZYejvi9i95+uokrvrvRl5fl8OCq2K0exE9wK4S/q9zb+HjhiuYb1hKPMXcN+MqzWIZ0HAUH1HNDvNQhIATVbX89pPduDs5kDLIj0emRjEpOoAwX9dLX7RJwFDIW9u1wLJXgWeIWqqBThaOSrxNrQW06V8QOgqGtv/vqtMJbh4VxuQhAfzP13v423f7WXOolP/cmoi3q2PXYpekDlAUhZd+OsQM91ymFSyCQdPgpvfafFcKgEc/9V3re1fBl/cQ8+A6ZieF8t6WAu4aH0GIHVWQtataOi0Lgn1hmkIdBv4TlWbVAVtFUcgprabiXD0DA9wYozsIwHYlhnBfV343dRBfPDSO9Gem8eadydw+ZkDnkj1AwBCoOg41FZ0NTi3NEHVZ17dLnPl/0H84fPMwnMq75OlBns68d88onp8Vx9bccq59dRMHis907d6S1AGrD5Zy6Egx/zQsRniHw01L2k/2TVx94dZP1G6eL+7kicsjMJsVlmzMt07QVmJXLXxo1WL9ZgMDD3wLtYvA2bNH7mcyKxw8foYd+afYkX+KtCOnOFldD8AAP1du8j9CjTGY5X++3XL9gQFD1c9lhyF8TMefdzpfnZ0Q2uZ4TscYnNX+/Dcnw6e3wn0rwcWnzVNbT5F9ZGoUS3ccY/Ybm/n3zYnMjO/f9TgkqQ2KovDy6ixedP8ct9rjMPcndQyqI/yiYNbr8PnthOxdzLXDZ7B051Eevzzabvry7aqFf4FR94HxLOz72iKXUxSF45U1rNp/gn+uOsxd7+5g+LOruOaVTTz3wwH2FVcyKTqAF2fHs2HeVNY/OYX4hv24DJpo2R+YwKaE38l+/KLd6ueQkd27v08E3PKx+gdk6e1tbr3YVnnaN9fn8ejUKIYFe/HIp7v5cGtB9+KQpFa25pWjL97NdQ2rEGMf6VyDCCDmGoi7CTYs4tFh9ZyrN/HpjqM9E6wG7K6Ff56QkWpf9e4POz2F8Vx9A7mlZ5tr0ewvrmRv0RlOVqvJTa8TRAe6c31iMKMjfRkd6Ut/r1Z9fWVZcLYMBqS0cYdu8AoHBxe1hd8ZRbvU5wVYYCAqciLMekOtrrnsAbjx3fPeNrdXnnbx+jxW/2kyj32azjPf7qfkTC1PTh8ip25KFvHOhjz+7vQpilsAYsr8rl1k5kuQu4ZBac+REvUXPtxawIOTBtrFSnL7TvhCwIi74af/gRN71ZkmqN0wZ2qMnD5Xz4nKWooqajjeWFisqKKG3NJqiitrmy+j1wkGBbgzeXAACaFexIV4Edvf87zl2W06skn9HDHBsq9LpwP/Qeo84s4o2gXBiZfuz+yo+JvUDdhX/QW4F25cAnr1nczFytM6G/QsvmMET6fu47W1uRhNCgtmDpVJX+qWnNIqDNkrSHI8BFP/DU4eXbuQmz9MfQpWPMkT4/K4MdebDdllTB3S/Z3mtGZ3Cb+yxsifv8rEaFIwmswY6geyGAM/vf8S/9DdR8W5es7Utr3Bh7+7EyHezowZ6EdUgBuDAt2JCnBngJ8bjg5d6P0q2Kwu8PAd2M1X1Qa/aCje3fHzTUY4ngmj7rdsHOMfUz+v+gsYa9UBMieP5mmprTVNkXXQ63hxdjwGvY63NuSh1wn+PEO29KWuW7Ixnz8YlmHyiUKfdFf3LjbyHti+mBFZ/ybI9Xk+33FMJvze6kj5OQx6HQa9wKD3IM11ApfXrmXjoMdwcw/Ey8WAt6v60c/ThWBvZ/p5OePkcIkWe2coChzZDAPGd31GzMX4R8OBVDXJGjpQ96P0ADTUQkgP7D0z/jEwuMCKebBkOtz6aYf2zBVC8Ox1wzApCm+sy8VRr+OP0wZbPj7J7p2ta6Ai8wdidEdg0uvdfxerN8C05xBLb+NvA3bz+4NJnKyuw/9Sdap6ObtL+F4uBn76w6TzD+b9ET68jkVxxyBhjnUCOZ2vTp2MsHD/fRP/waCY1amRQbGXPr9ol/q5uwO27Rl1n/pO5su7YfEEBsTMw0kfQ41RfdjH1cDfrh12wRRZnU7wwvVxGBvM/Gd1NoGeTtw+xjaXtEvaWZ5ZzP0so84tBKeEmy1z0SFXQegopp36FMxxfJdRzL0TIi1zbY3Y9yydJhET1Zkluz+w3j0LNqufB1i4/76JX2PVv4724xftBhdf8O7BZBo1FR7eRJnnMJIy/8bb5qcZJdSZRLXG9ncX0ukEL86OZ+qQAP6auo/VB0t6LkbJLu3a+jMjddk4Tnq8eRyp24SASfMwVBXyqG8aP+wptsx1NdQ3Er5OB0l3QsFG6+3VemQzuPqpi6R6QlPCP9mJhB8ysme6l1ryDueGqj8z33g/4aKUL52eY5njM1xr/oW3f9rR7tMc9DpevW0EcSFePPrpbjKPdXJRmdRnZZVUMfrkMur1bojE2yx78ejp0H8495qXkXm0vN1ig7aibyR8gMTbQegg/SPr3K+gB/vvAZzc1RIJHUn4ddVQdrDnunNaKaqsY6npMibX/ZvnjHfiyTn+z/A2y+vugcUTIPWRXzdNz/lF/WNUnoub8RRLbo/Hz82Jhz7aRVnVhfP7Jam15VszuVa3DVPCrV2fmdOO1IxiFpy8Eq/aQq7Wbef/fuxiDatewu768Nvl2R+iZ0DGpzD1L5Z729eWU3lQeRTG/67n7gFqK78jXTrHM9X+fisl/KYZOrU48a5pJu+ariRB5HGN20EedCmC7J8h45M2nxsAbNQ5ctLkRuErUfiMvQKHhDnqNFRJasVsVnDa+ymOogHGP2TRazctHqw1xnO/Y3/udVjBDXvGMXVooGabKnVX30n4ACPugqwf1QJiQ6/uufvkNhY2i+rhGvz+g2HP5+qMoIu9k2gesO2BGTptuHCGjiDbYTCBV98ITb8oNaehugxqTqlf156BOvVDV3uG2mMFOBWkI9a/BBsWslU3grNTnuOKSROt8hok27Az/yTXNaykLGAMARbuPv118aCO90xX8oLhPUaQxYsrnGXCtwnR09V58bs/7NmEn7cWvMLU2hw9yT9aTZLVpeAR1P55RbvUwVo3/56Np1HrDaTbLLvs4tNuDR6A3elFPJmTiY/5FHP063nY4QcMq2eTVvkCyddatiUn2a79W5YzRpykNuVFi1+75eLBr00TedLhC+51+JFHq3poXM4K+lbC1ztA0u2w6d9qWYKOtAjKc9UuGq9QtWjZpfrkTQ3qFmox1/X8AKl/dGOM2ZdI+Lu7VzCtCzpVdrkNi1YepsGsUIYPr5tm8aVpCq86/pcxu/4MoW6QdIcFo5VsUYPJTEDeMs7p3HCNu9bi12+5eLAGZz4zXcaD+h8Y6HDS4veylr4zaNtk7CPqjlG//P2Ch55O3UvUghVEzF/O1U+9Qf6iyfDKCPjkJnh9LLxzudoffjFHNqtbAkZP65n4W/JrTPgns9o/p7pUHU+wUneOpbQuzVCGN3fVz2eDKR6++x3kb9QoMqm32HroKJeZt1E+4Gp14Z+FzZsxBBfDr4sxP2iYjoJgLiupqjVa/H7W0PcSvps/TPgDHF4Bh39qPvx06l4+3nYUs2Lit/rv+MbwF9yr8/kx+BG4dyVc9Q+oOAbvTFO3RWvPvq/VPyjR03v+tXiGqMXQTua0f46lKmRaWVu7lNXhyPOuC9QFXl/fB+dOaRCZ1FsUbVmKm6gjcOI9PXL9lvtrCEDvHUpOwBXcol/D5gNHeuSePa3vJXyAcY+pGxenPgwlBwD4bPsxAqjgA8NL/I9hKavMyUyr+z8ey58I4WNh9APw6HYIToIvfwO73r/wurVn1D8GQ3umxXGBpiJqF2vhF+1Sp6P2H97z8VhQ69ZVk2tGRau7F509CWue1yAyqTcwmsxEFn3PSUMITpHje+w+s5JC2Dz/MvIXXs3m+Zcx6Jon8BQ1nNn5WY/dsyf1zYTv4AS3fAh6J1gyDX78H/6uX8I6pz8yWneIBcb7eMz4eyrwwKQovz7P1RfuSoVBV8D3j8O2xedfd9f76iDqmIet91r8oi8+NbNol1oi2tHNejFZQOvWVX8vZ7xdDHy/5zi1/sPUP8Bp76lVUKU+J+NAFsnKfioHXd/zY2UtOAwYS5FTFPHHv8Zkan/1eG/VNxM+qN0C9/8CA6fAziXcqN/IavMIZtYv5DPT5YD6Q6Rv/cNkcFG3Qht6jVp2ecM/wGxWa9+vf0n9Y2DN/nL/wVBxVC2i1pqiqBU1baz/vknL1tXWBZfzn7lJ5JRW85/V2TBlgbrIZsM/tA5T0kDJji/RC4XglLnWvbEQnBx6OzHkk5Ox3rr3toC+m/ABvMPU5P3XMl5M/JnfG39HvnL+tntzx4Rd+DwHJ5jzPsTPUbsVXhkBb09Vj1/zb+vE3sQ/+tciaq01bWloY/337Zk8OIBbksN4c30uGSdRSz0f+Lbj5SUku6AoCv0Lf+K4IQyXkHir3z9s0t2cVZww7Vhi9Xt3V99O+E2E4PkbhnPH2PDmFr1eCO4YG84Ls9r5gdIb4Ia34IY3ITAGhs2C+1eDd7gVA+fiRdRsdMD2Yv5yTQxBns7qngejHwa9I2x/U+uwJCs6lJtHonk/pyOusmp3ThNfP3/WO08lqmSV2qCyIX1rHv4lvDArvv0E3xadDobfqn5opbmIWhsDt8e2g8HNMlsa9hKezgaeuz6OBz5M472Mah6MvQ72fgHTn7fOQLmkuaItXxAjFILHa/d7d3zQbTjt/4n6XZ/iOOFRzeLoLNnCt3VO7uqq3tI2ijod3QahIy23pWEvMS02iCtiAnn5l2zKB9+irns4+L3WYUlW4nd0BcX6ELwjkjSLYXDieHabB2Hc8Y46VmYjZMK3B/2Hw/GM84/VVUHJPggbq01MPexv1w7DZFZ4JtNb7Ubb87nWIUlWUFx0lATjXkpCZ2rSndNkVIQvnyvTcDuTBwWbNIujs2TCtwfBiVCeAzUtasgX7lQHc8PHaBdXDwrzdeV3lw1i+b5SjvWfAXnrz3/9kl0q2JaKXij4j5qtaRzOBj0l4TOpEu6QZjuDtzLh24Pgxre2LVv5R7cDAkJHaRKSNTwwaSAD/d14sSAazEbI+unST5JsmmPuKk7iQ2is9u9cR0eH8LlxIsrBH9QSJjZAJnx7EDJSXU17ZMuvx3J+Uf8QOHtpF1cPc3LQ89drYvnxdDDVTkGyH9/O1dWeI+bsTvL9JiB0F67CtraxA/341HQ5wmy03sZK3SQTvj1w8YHgEZCzWv2+ulRdYTtkprZxWcGUIQFMiA5kRV0CSu5aaKjXOiSph+TsWImbqMUQc43WoQAQF+zFcYcw8jxGQtr7YDZd8jlakwnfXgy6XF1VW10K+1MBBQZfqXVUPU4IwVNXxfCLMQ5hPAuF7e+bK9m2mn0/UKM4Ej22B/ey6ARHBx0jBnjzmXmaWpG2qcHVi8mEby/iblKnh219Dba/ASHJ0D9B66isIqa/J/2Hz6BB0VGxd6XW4Ug9QVEILdvAAZcRuLlbdt/a7hgd4cf7p2IxuwXaxOCtTPj2ImAwxF4Hm19WyyxM/JPWEVnVozOTyGQwlfvkwK09Ks1Np59SytkBVthnohNGR/piVBw4MuAmyFqp1rXqxWTCtyfXvKxunD5rMQy9SutorCrQwxlj+ERCa7PZm9u7f+mkziveoe5BETpmlsaRqFLTi0hZuIa5b28D4LUzKeq6gF0faBzZxcmEb09cfWH6C5Bo5QqCvcTwlCvRC4Uff5SzdeyN+9HVHBJRREb28D7RHZCaXsSCZXubtz8E+DpXcDxosrpftqn37oZlkYQvhLhSCHFYCJEjhJjfxuP3CCHKhBAZjR/3W+K+ktSSS+RYzEKP84kdbM8r1zocyUIazp4msvYARf4TEBqurm2yaOVhaoznz8hRFFh0cjycLYVDP2gU2aV1O+ELIfTAa8BMIBaYK4SIbePUzxVFSWz8eKe795WkCzi5Q78Exhuy+ceqwyg2VONEat+x3T+hR8F5aO/ov2+933KT1OoYtcxH2rtWjqjjLNHCHw3kKIqSpyhKPbAUuN4C15WkTtMNGEeiyCGjoIwN2Se1DkeygHMHVlGluDA0earWoQBt77cM4ObsCCPvgfwNvXaPBksk/BDgWIvvCxuPtXajEGKPEOIrIUQbu4qAEOJBIUSaECKtrKzMAqFJfU74WBzMdUz1LOafspVv+xSFwNLN7HUcjp+Xu9bRAG3vtyyAEG8XSLoTdAZ1+81eyFqDtt8DEYqiJAA/A20OZSuK8paiKMmKoiQHBARYKTTJroSPA+CRQeXsKazk5wMlGgckdUddSRYBphIqgydqHUqz1vsth3i7MHagH8UVNZhdAyDmWsj4BIxtd/1oyRIJvwho2WIPbTzWTFGUckVR6hq/fQewny2YpN7FPRA8Q0kQeYT7uvLq2hzZyrdhhWnLAfBO6F2rxlvut7x5/mXcMCKEM7UN5J2shuR7obYC9i3TOswLWCLh7wSihRCRQghH4Fbgu5YnCCFabhR7HXDQAveVpLYFJ6I7kclvp0Sxp7CSjbIv32YpOas5ogSREJeodSgXNSLcB4DdRyogYgIEDIXti3vd5ijdTviKojQAjwErURP5F4qi7BdCPCeEuK7xtN8LIfYLITKB3wP3dPe+ktSuxv0BZsd60M/TmVfX5GgdkdQBTYuZIucvJ2XhGr7dlU9IRRqH3Ebh5tS7d20b6O+Gl4uB3UdPqwuwxv4WTuw5v4JtL2CRPnxFUVYoijJYUZQoRVH+t/HYM4qifNf49QJFUYYpijJcUZSpiqK0sR+fJFlI4/4ATmV7eXDSQHYUnGJH/imNg5IupuViJgUoqqjh69SvcaGW+gFTtA7vknQ6QVK4t5rwARJuARdf2Pa6toG1IlfaSvanf+OGMMUZzB0djp+bI6+ula383qytxUxjlEyMip6QpOkaRdU5I8J9yC6t5kytEQwual/+oeVqbateQiZ8yf64+YFXOBSn4+Ko594JkWzIKmNPodwCsbdqazHTJN0edivRxEe1OYu710kK90ZRIPNY48/ZqPtB5wDb39I2sBZkwpfsU3AiFKcDcNe4AXg6O/CabOX3Wq0XM/lyhnhdAVuU4Rj0tpGmEsO8EaJx4BbAsz/EzVZ3w6qt1Da4RrbxLylJndU/AU7nQ10VHs4G7hw3gFUHSsg/eVbryKQ2tF7MNE53QP1i4GSNIuo8D2cDgwM9fu3HB3Xwtr5aLarWC8iEL9mnoDj1c6k6A/jucREYdDre3ZSvYVBSe1ovZprqeJAqxYUZ02xrm84RA7xJP3oas7lxOmZwEkRMVDcmaqi7+JOtQCZ8yS6tPOkHwFOLl5KycA1bcsu5LjGYL3cd4/RZue9tb9RyMdNkx0OkixiGBvtoHVanJIZ5c6a2gYLyFu8kJz4BVcch8zPtAmskE75kd1LTi/jDT75pRUkAACAASURBVOWcUVwYIo5SVFHDgmV7ifJ3o9Zo5pPtR7QOUbqYM8UE1B/jhO8odDrtyyF3RkKoNwB7i1r02Q+cqrb0N/0bTA0aRaaSCV+yO+oUPzOHlTCG6tS6fjVGEx9vP8qkwQF8sPUIdQ2mS1xF0krFgTUAGAZN0TaQLogOdMfZoCPzWIuELwRMfBJOF8B+bcstyIQv2Z2mKX6HzOHEiKOA0nz8gYmRlFXV8W1GsYYRShdTeWA1FYob0QnjtA6l0xz0OoYFe104BXjIVRAQAxv/BWazNsEhE75kh5qm+B1SwvEU5wimvPn4hEH+DO3nwTsb82RRtV7K48RWdolYYoK9tQ6lSxJCvdhXXEmDqUVi1+nUvvyyg3B4hWaxyYQv2Z2mKX6HzOqCnSG6Y7gY9MybMQQhBA9MHEhWSTXrs+SeC73O6SP41h/nhO9o9DbWf99keKg3tUYz2aXV5z8wbDb4RMK6hZq18mXCl+xO0xS/Ks9oAMa4HufF2fHMSlL35bl2eDCBHk68t7lAwyiltpw5qPbfOw6ynfn3rSWEegGwt7DVYiu9A0x9Ckr2woFvNIhMJnzJTs1KCmHVgmvBO5yHh9Y0J3sARwcdt48ZwPqsMrkQq5epPLiGk4ong+NGax1Kl0X4ueHh5EBmW6U84m6CwGGw5n/BZLR6bDLhS/YtcBiU7L/g8NwxYRj0go+2yimavUFqehEpL65Gf3QT28yx5JTZ7h9inU4QH+rFntYtfPVBuOxpOJWr7opl7disfkdJsqagWCjPgYbzF1sFejgzM64/X+46xtk6bedG93VNpZENZ/IJFqfYao7l6dR9pKYXXfrJvVRCqDeHTpxpe/rvkJkQOhrWvWT1bRBlwpfsW2AsmBvUpN/K3eMHUFXbQGqG7SYWe9BUGrmpfs5Wcyw1RhOLVh7WOLKuSwj1wmhSOHi86sIHhYAr/gZVxVavly8TvmTfAmPUz6UHLnhoRLgPw4I9+XDLETlFU0NN6ybG6Q5wQvEhT+l/3nFb9OvAbTsluSMmwNBrYMM/4cxxq8UlE75k3/yi1ZrkpRduoyyE4O5xERwuqWK73BFLM+q6CYVxugNsNccCosVx2xTi7YKfmyOZbfXjN5n+PJiNsPpZq8UlE75k3xwcwW9Qmwkf4LrEYLxdDXy4tcCqYUm/mjdjCHGGEwSIysaET/O6CVslhCAhtI0Vty35DoRxj6lF1QrTrBKXTPiS/QuMabNLB8DZoOeW5DBW7i/heKXtdiHYsllJITwTp66G3mIeRoi3y3nrJmxVfKg3OaXVF58UMPEJcO8HK+aBuefrO8mEL9m/wFi1cFV921P97hg7ALOi8Mm2o9aNS2oWfmYnhYo/Lz90PZvnX2bzyR4gIcQLswIHj59p/yQnD7Vrp3g37FzS4zHJhC/Zv4ChgAJlbc/6CPN15fKhgSzdeQyjSbvCVn2W2Yznie3sUIY1lxe2B3Eh6sDtvqJLbG8YPweiLlP78isLezQmmfAl+xeo9gu3148PcNuYcE5W17H6YImVgpKale7H1XSGEr/RODrYT0oK8nTC392RfcUXaeGDOk3zmn+DYoblf4IenDFmP/+6ktQe30jQO7Xbjw8weXAg/b2c+WS77NaxtprDawFwip6ibSAWJoRgWLAX+y+V8AF8ImDqXyDrpx6tmS8TvmT/dHoIGHLRFr5eJ7hlVBgbs09y7NQ5KwYnVR1aQ745iLiYWK1Dsbi4EE+yS6qoNXZgQHbMw+rOWMufhKqeeacpE77UNwTGXjThA9wyKgydgKU7ZSvfakwNeJbuYAfDGB7mpXU0FhcX7EWDWSGrpI0Vt63pHWDWYnVywfeP90jXjkz4Ut8QGKMuZa853e4p/b1cuGxoIF+kFcrBW2s5kYmz6Swn/Ebj5KDXOhqL+3XgtgPdOgCBQ2H6CxCRIhO+JHVZ88DtoYueNnd0OGVVcvDWWmqz1wFQ6DmSlIVriJy/nJSFa2y6cFpLoT4ueDo7sK/4EjN1WhrzIIz/nVpZ08Jkwpf6hqaaOmUX79aZMkQdvP10xzErBNV3paYXkbJwDdtWf0u2OYRl2UaKKmpQgKKKGhYs22sXSV8IQVyIF/svNTXTSmTCl/oGr1Bw9LhkP/6vg7dlcvC2hzSVQy6pqGKU7hBbzLG07kGz9WqZLcWFeHHwRFWv6CaUCV/qG4RoLLFw8YQPcHNyGAL4fKds5feEpnLICSIPN1HHVvOwNs+z5WqZLQ0L9qS+wUxO6z1uNSATvtR3BMaou19dYjAs2NuFqUMC+TxNrrztCS3LIQNsNw9t8zxbrpbZUodX3FqBTPhS3xEYCzWn4GzZJU+9bUzT4G2pFQLrW5oS+Xjdfg6YB3AazwvOsfVqmS1F+rnh6qjv2AKsHiYTvtR3XGQzlNYmDw4gyNOJr3bJbh1LmzdjCJ4GMyN1Wc3lkA06gY+rAQF2Uy2ziU4niO3v2Sta+A5aByBJVtOyps7AKRc91UGvY/aIUN7akEfpmVoCPZ17PLy+YlZSCH4nd+K82chWcywh3i7MmzHEbhJ8W+JCvPgi7Rgms4JeJzSLQ7bwpb7DPQBc/TvUwgeYMzIUk1lhmR1MD+xtxol9mBRBzNgr7aYc8sUMC/bkXL2J/JNtl+i2FoskfCHElUKIw0KIHCHE/DYedxJCfN74+HYhRIQl7itJndbBmToAAwPcGRXhwxdpx+SetxZ2Lmste5VIEqMHaB2KVTQN3O7vzAKsHtDthC+E0AOvATOBWGCuEKJ1FaT7gNOKogwC/g281N37SlKXNCX8DibwOclh5JWdZffR9ksySJ1Ufxa3sgy2mYeRHOGrdTRWMSjQHUcHneb9+JZo4Y8GchRFyVMUpR5YClzf6pzrgQ8av/4KuFwIoV1HltR3BcZAfTVUdmww9ur4/rg66vliZ89uTNGnHN2GXmmg0DsZLxeD1tFYhUGvI6afR8dr6vQQSyT8EKDlb09h47E2z1EUpQGoBPxaX0gI8aAQIk0IkVZWdumpc5LUaR3YDKUlNycHrknozw97ii++N6nUYaa89RgVPa6DJmgdilUNC/FiX3Glpt2DvWrQVlGUtxRFSVYUJTkgIEDrcCR7FNC4yKeDA7egrrw9W29ixd7jPRRU31KbtY4MJYoRg+x7oLa1uGAvqmobOHZKuxXElkj4RUBYi+9DG4+1eY4QwgHwAsotcG9J6hwXb/AM6XALH2DkAB8G+rvx5S7ZrdNttZW4nNzLFvMwRvWR/vsmcSHqArNOVc60MEsk/J1AtBAiUgjhCNwKfNfqnO+Auxu/vglYo8hpD5JWAmM61cIXQnBTcig78k9pPq3O5h3Zgg4zxzxH4ufupHU0VjU4yAMHndB04LbbCb+xT/4xYCVwEPhCUZT9QojnhBDXNZ62BPATQuQATwAXTN2UJKsJjIGyLDB3YNu5RjeOCEUnkCtvu8mct4E6xYD7oHFah2J1zgY90UEe7NUw4Vtkpa2iKCuAFa2OPdPi61pgjiXuJUndFhgLpjo4lQ/+gzr0lCBPZ6YMCeSrXYU8MW2IpqslbVld9jp2mwczMipY61A0ERfsyZpDpSiKghYTFXvVoK0kWUUnauq0dHNyKCVn6tiQLWeQdcnZclxOHWCrOZYxkX2r/75JfKgX5WfrOXGmVpP7y4Qv9T3+QwDRqYFbgMuGBuHr5siXabJbp0uObAKgwHNkn61NNCxYXXG7t1Cbbh2Z8KW+x9EVfCM73cJ3dNBxQ1IIPx8o4dTZ+h4Kzn4peRs4hxMeA8doHYpmYvp7oBOwT6NSyTLhS31TYGynEz7AnORQjCaFbzNkQbXOqs9Zxw7TUEZFBWodimZcHR2ICnDXbI9bmfClviloGJTnQF3ntp0b2s+T+BAvvkyTc/I7peoEThU5bDHHMmbgBYvs+5T4xhW3WpAJX+qbQpJBMUNxeqefOic5lAPHz2he+dCm5G8EINdtBCF2snVhVw0L8aLkTB2lVdYfuJUJX+qbQkaqn4vSOv3U64YH46jXyVZ+Jyj566nCFe+okVqHorm4YHXF7X4NCqnJhC/1TW5+4BMJhZ1P+N6ujkwbFsS3GUXUN8hNzi9JUWjIWcdWUwxjBvbd/vsmsY0JX4sVtzLhS31XaDIU7erSU+eMDOX0OSOrD5ZYOCg7dCoPQ9UxNprjGRfVt/vvATycDUT6u2nSjy8TvtR3hSRD1XGo7PyMm4nR6ibnsqBaB+SuASDbfRRhvq4aB9M7xIV4aVIbXyZ8qe8KTVY/d6EfX68TzB4RyrrDpZRqtGrSVii5aykigPBBcVqH0mvEBXtSVFHDaSuv55AJX+q7+sWDgzMc2dqlp88ZGYpZQW5yfjGmBsx5G9jQEMe4Qf5aR9NrNO1xa+1uHZnwpb7LwQnCxkDBxi49fWCAOyMH+PCl3OS8fUW70Bur1P77gTLhNxnWPHBr3W4dmfClvi1yEpTsg7Mnu/T0OSNDyS07S/qxCgsHZify1mJGUOwzin5efbN+Tlu8XR0J83WRLXxJsqrIyernLrbyr07oj7NBzslvj5K7hgPKQGIHRWodSq8TF+xl9RILMuFLfVtwEjh6QO7aLj3dw9nAVXH9+SGzmJr6jm+o0ifUnoHCNNaZ4hgvp2NeIC7Ei4Lyc5ypNVrtnjLhS32b3gEGXQZZP4G5a4uobkoOpaqugZX7T1g4OBtXsBGhmNhkjmdsH6+f05ZhGqy4lQlfkoZeC9UlXV6ENTbSj1AfF76U2x+eL3ctdcKJav8R+Pex/Ws7ommmjjVrMsmEL0nR00DnAId+6NLTdTrBTSND2ZJbTuHpcxYOznYpuWvZZo4heVA/rUPplfzdnejv5WzVEgsy4UuSi7c6eLvv605tbN7SjSNCURT4epeckw9AxVHEqRzWN8junIsZFuxl1c1QZMKXJIARd0HlMchZ3fnnnswhrGgFfwg+wC+79mE2yzn55PwCwAYlgbED++b+tR0RF+JJblk1Z+sarHI/B6vcRZJ6u6FXg1sgpL0Lg6d37DnFGbDyKTiyGYA/AA8rBgq/20v4dU+Drg+3p7J/pkTfD6egoXi7OmodTa8VF+yFosDB42dIjuj5P4x9+CdSklrQGyD5N5D146U3RTGbYcur8M4V6q5Z056H326h9p6fWUcy4Rn/hOVPQF9dfWusRclbx6r6BFKiA7SOpleLD20ssWClfnyZ8CWpybhHwdUPVv21/WRdXQqfzoFVf4Ho6fDINkj5PQQNwzliNOsTXuId83Ww6z3I+NS68fcWRzYjjOdYbRrOxGhZTuFiAj2c8Hd3slo/vkz4ktTE2QumLFBX3W597cLHD62AN1LU7fqu+gfc+gm4nv82/KbkcP63/mZKfUfATwvgTLGVgu9Fsn/GKBxJ18UxygrdFLZMCEFciKds4UuSJkbdD0OvUVvwq/4KJ/ap9dyX3g5L54J7IDy4FkY/AEJc8PQR4d5EBnjwnHgUjOdgwyINXoTGsleRro8nIbI/zga91tH0enHBXmSXVlNr7PmV2jLhS1JLQsBN70LSnbDlv7A4BT66QW31T30aHlgLQcMu8nTBnJFh/FDkQmXsXNj9EVQcteIL0Fh5LpzK5YeaONmd00FxIV6YzAqHTlT1+L1kwpek1hyc4PpX4ffpcOMSuP1reOIgTJ4HDpeeceLqqLZqZ6SNwmhWyPmuD7Xys38GYK05kYlywLZD4kKst8etTPiS1B7fgRB/E0RfAY5uHXpKanoRC388BMAJ/PjJlIx/7td8l5bbk5H2HtmrKHEMo8YtnKH9PLSOxiaEeLvg7WqwSokFmfAlyYIWrTxMTYu+2E9Nl+MtzpK58n3tgrKW+rMoBZv42ajOzhFtjHFIFxJCEB/iReYxmfAlyaYUV9Sc9/1Wcyz55iCm1nZhBa+tyVuPMNXxY108E+R2hp0yPNSbwyVVPV5iWyZ8SbKgYG+XVkcE35vHMU5/UJ3Db88OLadO7852c4wcsO2k4WHemMxKj3fryIQvSRY0b8YQXFpNRfxJGY8eMxz4VqOorMDUAIdXsNNxNIP6+RDoKbcz7IzhYeqK24we3ipTJnxJsqBZSSG8ODueEG8XBGDQCao8oyFgqH0n/GPboeYUn1clyNZ9FwR6OBPi7SITviTZmllJIWyefxn5C69mwVUxHDtdw3vlsRjztzD9xe9JTbfDEsqHlmPSObKmIZ6pQwO1jsYmDQ/zIrNQJnxJslmODuqv2PKaOAzCxKCqHSxYtte+kr6iwKEfyHIbic7JQ5ZT6KLEMG+OnaqhvLqux+7RrYQvhPAVQvwshMhu/OzTznkmIURG48d33bmnJNmSN9ap8+/TlWgqFDem6jKoMZpYtPKwxpFZUMl+qDjCsnOJTBzsj0Ev25FdMTzUG6BHW/nd/Z+ZD6xWFCUaWN34fVtqFEVJbPy4rpv3lCSb0TRN04Se9ebhTNFnIDBTVFFD5PzlpCxcY/ut/UPLURB8czaBKUNkd05XxYd6oROQcbT3JvzrgQ8av/4AmNXN60mSXWk5TXOtKZEAcYY4UQCAAhRV1Nh+F8+hHzjhGc9JvJgyRJZT6CpXRwcGB3mQUdhzUzO7m/CDFEU53vj1CSConfOchRBpQohtQgj5R0HqM1pO09xojgcgRbfvvHNsuounPBdO7GGleTQJoV4EesjpmN2RGOZN5rEKlB7aPOeSCV8I8YsQYl8bH9e3PE9RI2wvygGKoiQDtwEvCyGi2rnXg41/GNLKyso6+1okqddpmqYZ6OFEOV4cNocyXrf/gvNar9C1Gfu/AeCt8uFMld053ZYY5k1ljZGC8nM9cv1LJnxFUa5QFCWujY9vgRIhRH+Axs9tLiVUFKWo8XMesA5Iaue8txRFSVYUJTkgQL41lOzDrKQQdvzlCsZH+bHNPIxkXRYGzt+0+sIVujZi/zeU+yZSrPjJ6ZgWMDysceC2h+bjd7dL5zvg7sav7wYuWFkihPARQjg1fu0PpAAHunlfSbI5d4wdwBZzLK6ijuEip/m4i0HPvBlDNIysi8qyoGQfa/QT8Hd3IiHES+uIbF50oDsuBn2PLcDqbsJfCEwTQmQDVzR+jxAiWQjxTuM5MUCaECITWAssVBRFJnypz5kWG0SO63DMCK50y0KglsZ9cXY8s5JCtA6v8/YvQ0HwWskwpsUGodPJ6pjd5aDXER/q1WMJ36E7T1YUpRy4vI3jacD9jV9vAeK7cx9JsgcGvY6rRseyf9MA7gg6wv1PX611SF2nKLBvGRUByRQc8+Lvw9qbryF11h+vGIyDvmf+eMoVEpJkRbeODmebeRgOxWlgtNGBWoDSA3DyMOscJuDh5MD4KFk/x1LGRfn12GplmfAlyYpCvF04FzIeB8WIsWCb1uF03b5lKELHqydimTo0sLmEhNS7datLx9qMRiOFhYXU1tZqHYrUA5ydnQkNDcVgMGgdSo9KmjgT05dPk5+2ksHRU7UOp/PMZtjzOZX9UsjNd+NPcf20jkjqIJtK+IWFhXh4eBARESG3T7MziqJQXl5OYWEhkZGRWofToybEDuSwLgolf5PWoXRNwUaoPMYvPvfh6KBj8mA5hdpW2NT7sNraWvz8/GSyt0NCCPz8/PrEuzedTlAXMpaouoPkFNngLliZn6E4efLa8aFMivbHzcmm2o19mk0lfEAmezvWl/5vB46agZNoYN2aH7UOpXPqquHAd5yKuJr8SjPTh8nuHFticwlfkuyB5+BJmBHUZq/n9Nl6rcPpuIPfgfEs3zEZg14wI1YmfFsiE34nlJeXk5iYSGJiIv369SMkJKT5+/p6y/7SVlRU8Prrr1v0mlIv4uJNvf8wRioH+XTHUa2j6biMT1F8B7I4z5/JgwPxcrXvAXZ7IxN+J/j5+ZGRkUFGRgYPP/wwf/zjH5u/d3R0bPd5DQ0N7T7WHpnw7Z/zoMmM1GezdEsWRpNZ63AukJpeRMrCNc11+1dt3gEFGzkWNouSqnquSwzWOkSpk2x2tOXZ7/dzoPiMRa8ZG+zJ364d1qnnvP3227z11lvU19czaNAgPvroI1xdXbnnnntwdnYmPT2dlJQUHn30UW6//XbOnj3L9ddfz8svv0x1dTUAixYt4osvvqCuro4bbriBZ599lvnz55Obm0tiYiLTpk1j0aJFFn2tUi8QkYLjttfoX32AFXuHc31i7ymvkJpexIJle6kxmgC1bn/eyg9RdDo+rUvBxdDAFTGyWJqtkS38bpo9ezY7d+4kMzOTmJgYlixZ0vxYYWEhW7Zs4V//+hePP/44jz/+OHv37iU0NLT5nFWrVpGdnc2OHTvIyMhg165dbNiwgYULFxIVFUVGRoZM9vYqfBwKgis9clmyKb/HaqB3xaKVh5uTPYCBBm4Uq9mkG8nSLDPTYoNwdbTZ9mKfZbP/Y51tifeUffv28fTTT1NRUUF1dTUzZsxofmzOnDno9ermF1u3biU1NRWA2267jSeffBJQE/6qVatISlIrRldXV5OdnU14eLiVX4lkda6+iKA4ZhpzeK6wkrQjp3vNBuCt6/PP0O0kQJzhydrLqDAbub5Fd05qehGLVh6muKKGYG8X5s0YYpvF4PoAm034vcU999xDamoqw4cP5/3332fdunXNj7m5uV3y+YqisGDBAh566KHzjhcUFFg4UqlXiphAv13v4+8M72zM6zUJP9jbhaIWSf8Oh184ag5gpz4RH2cHJkari63a6vpZsGwvgEz6vZDs0ummqqoq+vfvj9Fo5JNPPmn3vLFjx/L1118DsHTp0ubjM2bM4N13323uzy8qKqK0tBQPDw+qqqp6NnhJexEpiIYa/jSsmpX7S8gu6R3/5y23ZhwkChmrO8gXyhXUmdRE3lQ7p3XXD9j4lo12Tib8bnr++ecZM2YMKSkpDB06tN3zXn75Zf71r3+RkJBATk4OXl7qZhHTp0/ntttuY9y4ccTHx3PTTTdRVVWFn58fKSkpxMXFMW/ePGu9HMnaBqQAcL1PPi4GPa+vy9U4IFXT1owh3i7crf+Zehw4PeQWTGaFW0aFNZ/X3taMNrtlo50TvWmgqKXk5GQlLS3tvGMHDx4kJiZGo4i659y5c7i4uCCEYOnSpXz22Wd8++0FG4T1ebb8f9xlr48H9wBe8H2R97YUsPZPUwj3c9U6KtW5U/CvWJS42cwsuBUnBx3fPjah+eGUhWvO6/ppEuLtwub5l1kzUqmREGJX4x7iF5AtfCvZtWsXiYmJJCQk8Prrr/PPf/5T65Ck3iIiBY7t4IGUMPRC8Mb63tHKByBtCTTUkBV5N4dOVHFzi9Y9nN/108Rmt2zsA+SgrZVMnDiRzMxMrcOQeqOICbDjLYKqD3LzqFC+2FnI45dH08/LWdu4jLWw/S0YdAUf5LnibNBx7fDzF1s1DczKWTq2QSZ8SdJaYz8+BRt5aNJv+WzHMd7ckKv91OO9X8LZUqpH/pbUz4q4JiEYT+cLSynMSgqRCd5GyC4dSdKamz8ExEDBZsJ8XZmdFMIn249yvFLDgU+zCbb8F4LiWVoWybl6E/eMj9AuHskiZMKXpN4gIgWObgOTkceviAYF/vNLtnbx7P8GTmZhnvAEH2w7wugIX+JCvLSLR7IImfAlqTeImADGs3A8k1AfV+4YO4Av0o6RU1pt/VjMJlj/fxAwlF/EWI6dquGelAjrxyFZnEz4naTX60lMTCQuLo45c+Zw7ty5Ll/rnnvu4auvvgLg/vvv58CBA+2eu27dOrZs2dL8/eLFi/nwww+7fG+plxnQONUxfwMAj06NwsWg55+rNFjAdCAVTh6Gyf/DO5uOEOzlzPTYIOvHIVmcTPid5OLiQkZGBvv27cPR0ZHFixef93hXSiEDvPPOO8TGxrb7eOuE//DDD3PXXXd16V5SL+QeAEHxkPMLAH7uTjwwaSA/7jtB+tHT1oujRet+u8tEdhSc4sFJA3HQy1RhD2x3ls6P8+HEXstes188zFzY4dMnTpzInj17WLduHX/961/x8fHh0KFDHDx4kPnz57Nu3Trq6up49NFHeeihh1AUhd/97nf8/PPPhIWFnVdDf8qUKfzjH/8gOTmZn376iaeeegqTyYS/vz9Llixh8eLF6PV6Pv74Y1555RVWr16Nu7s7Tz75ZHN9/nPnzhEVFcW7776Lj48PU6ZMYcyYMaxdu5aKigqWLFnCxIkTLftvJlnO4Omw6WWoOQ0uPtw/cSAfbzvCs98fYNlvx6PTWWELyMzPoOwQO5L/yV3vqQsf39qQh7ero5yJYwfkn+0uamho4McffyQ+Ph6A3bt385///IesrCyWLFmCl5cXO3fuZOfOnbz99tvk5+fzzTffcPjwYQ4cOMCHH354Xou9SVlZGQ888ABff/01mZmZfPnll0RERJy34UrrpH3XXXfx0ksvsWfPHuLj43n22WfPi3PHjh28/PLL5x2XeqHoGaCYIHcNAO5ODsyfGUPGsQq+2l3Y8/evPwtrXuCUTwJ3bg2mrkHdlKW4spYFy/aSml7U8zFIPcp2W/idaIlbUk1NDYmJiYDawr/vvvvYsmULo0ePJjIyElBLHu/Zs6e5f76yspLs7Gw2bNjA3Llz0ev1BAcHc9llFy4937ZtG5MmTWq+lq/vxasnVlZWUlFRweTJkwG4++67mTNnTvPjs2fPBmDkyJGyAmdvF5oMLr6QtQribgRgdlIIn+04yks/HmJGbL+e3VJw62tQdZynHH9Hnen8kitNBdFkK9+22W7C10hTH35rLUshK4rCK6+8cl5tfIAVK1b0eHytOTk5Aepgc1fHFyQr0elh0BWQ87Pal67To9MJnrt+GNe+sol/rDrM87PiOn3ZDtWrrypRu5NiruOn9Ig2ryMLotk+2aXTA2bMmMEbb7yB0WgEICsri7NnzzJp0iQ+//xzTCYTx48fZ+3atRc8d+zYsWzYsIH8/HwATp06BdBuuWQvLy98fHzYuHEjAB99wxFTwgAADyBJREFU9FFza1+yQUOvgnPlcGRz86FhwV7cNS6Cj7YdYWtueacu11SvvqiiBoVf69Vf0D2z6mkw1WO6/O84tDNWEOzt0tlXI/UyMuH3gPvvv5/Y2FhGjBhBXFwcDz30EA0NDdxwww1ER0cTGxvLXXfdxbhx4y54bkBAAG+99RazZ89m+PDh3HLLLQBce+21fPPNNyQmJjYn9yYffPAB8+bNIyEhgYyMDJ555hmrvE6pB0TPAIMb7Ft23uE/XzmECD9X5n2VSXVdx9+pdahefe4a2PsFTHyCpbkONJgVHFvNypEF0eyDLI8s9Sry/xj46l7IWwd/ygL9r72uaQWnmPPmVuaODuf/3RDfoUtFzl9OW7/hAshfeDUYa+CN8YCg9I41XP7f7cT092TuqDD+sSpLFkSzQRcrjyz78CWptxl2A+z7GvLXw6DLmw8nR/jy4MSBvLkhj/FRflyTEHyRi6hab1XY8jigzrk/lYdy57f8/cdc6hrMLJwdz8AAd24YEWqxlyT1DrJLR5J6m0HTwMkT9nx+wUN/mj6EkQN8+PNXe8jqwHaIF61Xf2QrbH4ZEm/nq9NRrNh7gscvj2ZggLvFXorUu8iEL0m9jcEZEm6G/anqjlMtODroeP32Ebg6OvDAh2mUVdVd9FIttyoUqDtRvTg7nlkx7vDNg+AdTu7Ip3nm2/2MHejLw5OjevCFSVqTCV+SeqPk+8BUB+kfX/BQkKczb945gpIztdz97g7O1BoveqlZSSFsnn8Z+QuvZvP8y5iVGAwr5kFlERUzX+M3nx3G1VHPf25NQm+N1bySZmTCl6TeKCgWwsdB2rtgNl/w8MgBvrxxx0iySqq4590dVJyr7/i1d74Dez6nNuVJ7l4FpVW1LLlnFEGeGu+wJfU4mfAlqbca/QCczodD37f58NQhgbwyN4l9RWe4afFW3t6QR8rCNUTOX07KwjVtl0Io2Aw/zadu4DRu2DueA8fP8OrcESSGeffwi5F6g24lfCHEHCHEfiGEWYj/3975B0V1XXH8cxYWAUlNgqYoJI2kFBMFQfmltHVj/EElFfw1Y6Kp1unEpLYkTgdtHNOknSRTx5nM1KaJmpRgTH+Y1obSQCqY6GiMCWHIj4pipY6OkDZSbPBHUYI5/WMXArgLS3dheez9zOzMe7yz757vXva88+7ee564nQbksssRkeMiUi8iP/alzUDS3NxMSkoKKSkpxMTEEBsb27nf1tZ7hlVdXU1BQUGfbUyfPt1f7g4qUVHmhz6/c0c+RCfA/k1us3yAbyWNZceqDBr/08qT5cd6X2DV9HfYtZxLI29mzunlnDp3mV+vSGeWKX0cNPg6LfMIsBDY5slAREKAXwGzgQbgPREpVVXPxd/9hFdLyvtBdHR0Z1mFxx9/vLNaZQft7e2Ehrr/SNPS0khL83hN7MRdQTVDkGILgRnr4U/fc87YSbnHrdm026L5UkSoxwVW+amxXG4+DUXf5vIVJe/THxLx5RspWZpKYsx1g6HEMETwKcNX1WOq2tcTGjKAelU9qaptwO+BPF/a9Qavl5T7yMqVK3nggQfIzMxk3bp1VFVVMW3aNFJTU5k+fTrHjzs/nv3793P33XcDzovFqlWrcDgcxMfHs2XLls7zdWTK+/fvx+FwsHjxYiZMmMCyZcvoWCRXXl7OhAkTmDp1KgUFBZ3n7UptbS0ZGRmkpKSQnJzMiRPOx+Xl5+czdepUJk6cyPbt27u1W1hYyMSJE5k1axZVVVWd/pWWlgJQXFxMXl4eDoeDhIQEj9U3N2/eTHp6OsnJyTz22GMAXLp0idzcXCZPnsykSZPYtevaKYeG7pS838jXy26g5vOvcq5kPWVVxzzanj3vfrZO46et5D/5W/71i9m0/beF78sG7pt3JyVrsk2wD0IGY+FVLHCmy34DkOnOUETuB+4HuOWWW3xqtLcl5f5eMdjQ0MDbb79NSEgI58+f5+DBg4SGhrJ37142bNjA7t27r3lPXV0d+/bt48KFCyQmJvLggw9it3evhPj+++9TW1vLuHHjyM7O5tChQ6SlpbF69WoOHDjA+PHjuece91nf1q1beeihh1i2bBltbW1cver8LIqKirjxxhtpbW0lPT2dRYsWER0dzaVLl5g5cyabN29mwYIFbNy4kcrKSo4ePcqKFSuYP38+AFVVVRw5coTIyEjS09PJzc3tdudSUVHBiRMnqKqqQlWZP38+Bw4coKmpiXHjxlFWVgY4q3waPNORsLR+dpVHZRV/DtuIvLaWktAXyHezIMrTAqvksI/ZoT9nhP0KR2fu4MXMWYwIDbnGzhAc9Jnhi8heETni5uX3LF1Vt6tqmqqmjRkzxqdzearsNxAV/5YsWUJIiPNL1NLSwpIlS5g0aRJr166ltrbW7Xtyc3MZMWIEo0eP5qabbuKTTz65xiYjI4O4uDhsNhspKSmcOnWKuro64uPjO8snewr406ZN46mnnmLTpk2cPn2aiAjnysotW7YwefJksrKyOHPmTGfmHxYWRk5ODgBJSUnMmDEDu91OUlJSt7LKs2fPJjo6moiICBYuXMhbb73Vrd2KigoqKipITU1lypQp1NXVceLECZKSkqisrGT9+vUcPHiQUaPMA7F7o2vCUqu38nT7EubZDtNYvsmtvbsFVgvD3mW3/SeMCg8h/P49TMmea4J9kNNnhq+qs3xsoxG4uct+nOtvA0qfS8r9SNfSyI8++ih33nknr776KqdOncLhcLh9T0fZYvBcutgbG0/ce++9ZGZmUlZWxrx589i2bRs2m429e/dy+PBhIiMjcTgcXL58GQC73Y6Icw62zWbrbNtms3Vrt8PG076q8sgjj7B69eprfKqpqaG8vJyNGzdy1113mSJvvdAzMXnu6re5w3aKNbwEb8VD9sPQ5bPvuGvdvOc4Vz79Fz8d+Qdyr74J4zJh8YswytTBMQzOtMz3gAQRGS8iYcBSoHSgG+11SfkA0tLSQmys88tVXFzs9/MnJiZy8uTJzqzb01j4yZMniY+Pp6CggLy8PD766CNaWlq44YYbiIyMpK6ujnfeeaff7VdWVnLu3DlaW1spKSkhOzu72/G5c+dSVFTExYsXAWhsbOTs2bN8/PHHREZGsnz5cgoLC6mpqel328FEz8REsfHwZ2t4w5YNex+HnfnO0ggds3c+/5z8sec4lPoG1aPWk6sH4Rs/gpVlJtgbOvFpDF9EFgC/BMYAZSLygarOFZFxwAuqOk9V20XkB8AeIAQoUlX34xx+pGvGM5gV/9atW8eKFSt44oknyM3N9fv5IyIiePbZZ8nJyWHkyJGkp6e7tXvllVfYuXMndrudmJgYNmzYwMiRI9m6dSu33347iYmJZGVl9bv9jIwMFi1aRENDA8uXL79m5tGcOXM4duxYZ+nnqKgoXn75Zerr6yksLMRms2G323nuuef6Lz6IKJyb2DmG34HdPoILd2+H9tdh35PwYo6z5k5ktLOG/pXzICFwRx44HoExXwugAsNQxJRHtiAXL14kKioKVWXNmjUkJCSwdu3aAW+3uLiY6upqnnnmmQFrw/TxF/Q6rfjKBTj+V2ioctbbibgeYqfCbTPhupjAOm4IKKY88jDj+eefZ8eOHbS1tZGamup2vNxgffJTYz3fkY64DpKXOF8Gg5eYDN8wpDB9bDD4Rm8ZvuVq6QzVC5TBd0zfGgwDi6UCfnh4OM3NzSYwDENUlebmZsLDTcVGg2GgsNQYflxcHA0NDTQ1NQXaFcMAEB4eTlyceayewTBQWCrg2+32zhWmBoPBYOgflhrSMRgMBsP/jwn4BoPBECSYgG8wGAxBwpCdhy8iTcBpH04xGvi3n9wJJMNFBxgtQ5XhomW46ADftHxFVd2WGx6yAd9XRKTa0+IDKzFcdIDRMlQZLlqGiw4YOC1mSMdgMBiCBBPwDQaDIUgYzgF/e98mlmC46ACjZagyXLQMFx0wQFqG7Ri+wWAwGLoznDN8g8FgMHTBBHyDwWAIEiwd8EUkR0SOi0i9iPzYzfERIrLLdfxdEbl18L30Di+0rBSRJhH5wPX6XiD87AsRKRKRsyJyxMNxEZEtLp0ficiUwfbRW7zQ4hCRli59MiSfyi4iN4vIPhE5KiK1IvKQGxtL9IuXWqzSL+EiUiUiH7q0/NSNjX9jmKpa8oXz+bj/AOKBMOBD4I4eNt8Htrq2lwK7Au23D1pWAs8E2lcvtHwTmAIc8XB8HvA6IEAW8G6gffZBiwN4LdB+eqFjLDDFtX0d8Hc3/1+W6BcvtVilXwSIcm3bgXeBrB42fo1hVs7wM4B6VT2pqm3A74G8HjZ5wA7X9h+Bu0REBtFHb/FGiyVQ1QPAuV5M8oCX1Mk7wPUiMnZwvOsfXmixBKr6T1WtcW1fAI4BPZ+daIl+8VKLJXB91hddu3bXq+csGr/GMCsH/FjgTJf9Bq7t+E4bVW0HWoDoQfGuf3ijBWCR63b7jyJy8+C45ne81WoVprluyV8XkYmBdqYvXEMCqTizya5Yrl960QIW6RcRCRGRD4CzQKWqeuwXf8QwKwf8YOMvwK2qmgxU8sVV3xA4anDWLZkM/BIoCbA/vSIiUcBu4GFVPR9of3yhDy2W6RdVvaqqKUAckCEikwayPSsH/Eaga5Yb5/qbWxsRCQVGAc2D4l3/6FOLqjar6hXX7gvA1EHyzd9402+WQFXPd9ySq2o5YBeR0QF2yy0iYscZIH+jqn9yY2KZfulLi5X6pQNV/RTYB+T0OOTXGGblgP8ekCAi40UkDOcPGqU9bEqBFa7txcCb6vr1Y4jRp5Ye46nzcY5dWpFS4DuuWSFZQIuq/jPQTv0/iEhMx3iqiGTg/D4NuYTC5eOvgWOq+rQHM0v0izdaLNQvY0Tketd2BDAbqOth5tcYZqlHHHZFVdtF5AfAHpyzXIpUtVZEfgZUq2opzn+MnSJSj/PHt6WB89gzXmopEJH5QDtOLSsD5nAviMjvcM6SGC0iDcBjOH+MQlW3AuU4Z4TUA/8FvhsYT/vGCy2LgQdFpB1oBZYO0YQiG7gP+JtrvBhgA3ALWK5fvNFilX4ZC+wQkRCcF6VXVPW1gYxhprSCwWAwBAlWHtIxGAwGQz8wAd9gMBiCBBPwDQaDIUgwAd9gMBiCBBPwDQaDIUgwAd9gMBiCBBPwDQaDIUj4H/XFyzUC0gP3AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lZ36J2EN85b9"
      },
      "source": [
        "In order to implement a regularization we need to modify the loss function. Since the loss function in this exercise is computed during the training step, we define a new training step with a regularization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sLbcWwlt9Jwl",
        "colab": {}
      },
      "source": [
        "\"\"\" In order to avoid overfitting we implement a training step that also includes a regularization on the weights of our big model. For this we use the Frobenius/squared l2-norm of each weight matrix/vector. \n",
        "Hint: Use the tf.reduce_sum() function on a list of individual regularization terms for each matrix/vector of the network.\"\"\"\n",
        "\n",
        "def regularized_train_step(model, optimizer, x, y, lmbd):\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(model.trainable_variables)\n",
        "        y_pred = model(x)\n",
        "        # Compute a prediction with \"model\" on the input \"x\"\n",
        "        loss_val = tf.reduce_mean(tf.square(y-tf.reshape(y_pred,(-1))))\n",
        "#         loss_val = tf.compat.v1.losses.mean_squared_error(y,tf.reshape(y_pred,(-1)))\n",
        "        # Compute the Mean Squared Error (MSE) for the prediction \"y_pred\" and the targets \"y\"\n",
        "        regul_val = tf.reduce_sum(tf.convert_to_tensor([2*tf.nn.l2_loss(weight) for weight in model.trainable_variables]))\n",
        "        # Compute the regularization based on the list \"model.trainable_variables\"\n",
        "        total_loss = loss_val + lmbd*regul_val\n",
        "        # Add the loss with a the regularization term weighted by \"lmbd\"\n",
        "    grads = tape.gradient(total_loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "    return loss_val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ExK4FIw89s0M"
      },
      "source": [
        "We can now set the strength of the regularization and retrain the big model with a regularization. We create another instance of the big model in order to compare the big model with and without regularization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_PUUBGi496Vt",
        "scrolled": false,
        "outputId": "a913f2ef-d3d4-4005-c937-3d20b374ef08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\"\"\" Implement the training for the bigger model with the regularized_train_step function. Note: We are plotting the MSE loss without the regularization in order to compare it with the unregularized model. \"\"\"\n",
        "\n",
        "lmbd = 0.005\n",
        "\n",
        "big_reg_mdl = MyBigModel()\n",
        "big_opt = tf.optimizers.SGD(learning_rate)\n",
        "\n",
        "epoch = 0\n",
        "train_iters = 0\n",
        "train_loss = 0.0\n",
        "for x_t, y_t in train_overfit_ds:\n",
        "    train_loss += regularized_train_step(big_reg_mdl,big_opt, x_t, y_t,lmbd)\n",
        "    # Perform a regularized training step with the model \"big_mdl\" and the optimizer \"big_opt\" on the inputs \"x_t\" and the corresponding targets \"y_t\" with the regularization parameter being \"lmbd\"\n",
        "    train_iters += 1\n",
        "    if train_iters == math.ceil(N_train_samples_overfit/batch_size):\n",
        "        for x_v, y_v in validation_ds:\n",
        "            y_pred = big_reg_mdl(x_v)\n",
        "            # Compute a prediction with \"big_mdl\" on the input \"x_v\"\n",
        "            validation_loss = tf.reduce_mean(tf.square(y_v-tf.reshape(y_pred,(-1))))\n",
        "#             validation_loss = tf.compat.v1.losses.mean_squared_error(y_v,tf.reshape(y_pred,(-1)))\n",
        "            # Compute the Mean Squared Error (MSE) for the prediction \"y_pred\" and the targets \"y_v\"\n",
        "        print(\"Epoch: {} Train loss: {:.5} Validation loss: {:.5}\".format(epoch, train_loss/train_iters, validation_loss))\n",
        "        train_iters = 0\n",
        "        train_loss = 0.0\n",
        "        train_reg = 0.0\n",
        "        epoch += 1\n",
        "    if (epoch == N_epochs):\n",
        "        break"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 Train loss: 8.747 Validation loss: 1.3335\n",
            "Epoch: 1 Train loss: 1.7036 Validation loss: 0.0054854\n",
            "Epoch: 2 Train loss: 0.97398 Validation loss: 0.3385\n",
            "Epoch: 3 Train loss: 0.44376 Validation loss: 0.16994\n",
            "Epoch: 4 Train loss: 0.38217 Validation loss: 0.081501\n",
            "Epoch: 5 Train loss: 0.34155 Validation loss: 0.040034\n",
            "Epoch: 6 Train loss: 0.31203 Validation loss: 0.019799\n",
            "Epoch: 7 Train loss: 0.28912 Validation loss: 0.0094441\n",
            "Epoch: 8 Train loss: 0.27061 Validation loss: 0.0040182\n",
            "Epoch: 9 Train loss: 0.25531 Validation loss: 0.0012853\n",
            "Epoch: 10 Train loss: 0.24245 Validation loss: 0.00015891\n",
            "Epoch: 11 Train loss: 0.23147 Validation loss: 5.5319e-05\n",
            "Epoch: 12 Train loss: 0.22195 Validation loss: 0.00062199\n",
            "Epoch: 13 Train loss: 0.21356 Validation loss: 0.0016248\n",
            "Epoch: 14 Train loss: 0.20603 Validation loss: 0.0028991\n",
            "Epoch: 15 Train loss: 0.19914 Validation loss: 0.0043249\n",
            "Epoch: 16 Train loss: 0.19271 Validation loss: 0.0058164\n",
            "Epoch: 17 Train loss: 0.1866 Validation loss: 0.0073109\n",
            "Epoch: 18 Train loss: 0.18071 Validation loss: 0.0087673\n",
            "Epoch: 19 Train loss: 0.17493 Validation loss: 0.010158\n",
            "Epoch: 20 Train loss: 0.16921 Validation loss: 0.011467\n",
            "Epoch: 21 Train loss: 0.1635 Validation loss: 0.01269\n",
            "Epoch: 22 Train loss: 0.15778 Validation loss: 0.013826\n",
            "Epoch: 23 Train loss: 0.15203 Validation loss: 0.014884\n",
            "Epoch: 24 Train loss: 0.14628 Validation loss: 0.015875\n",
            "Epoch: 25 Train loss: 0.14054 Validation loss: 0.016814\n",
            "Epoch: 26 Train loss: 0.13485 Validation loss: 0.017713\n",
            "Epoch: 27 Train loss: 0.12925 Validation loss: 0.018588\n",
            "Epoch: 28 Train loss: 0.12379 Validation loss: 0.019449\n",
            "Epoch: 29 Train loss: 0.1185 Validation loss: 0.020298\n",
            "Epoch: 30 Train loss: 0.11342 Validation loss: 0.021133\n",
            "Epoch: 31 Train loss: 0.10857 Validation loss: 0.021948\n",
            "Epoch: 32 Train loss: 0.10395 Validation loss: 0.022734\n",
            "Epoch: 33 Train loss: 0.099581 Validation loss: 0.023479\n",
            "Epoch: 34 Train loss: 0.095454 Validation loss: 0.02417\n",
            "Epoch: 35 Train loss: 0.091567 Validation loss: 0.024802\n",
            "Epoch: 36 Train loss: 0.087912 Validation loss: 0.025365\n",
            "Epoch: 37 Train loss: 0.084483 Validation loss: 0.025858\n",
            "Epoch: 38 Train loss: 0.081273 Validation loss: 0.026281\n",
            "Epoch: 39 Train loss: 0.078277 Validation loss: 0.026635\n",
            "Epoch: 40 Train loss: 0.075488 Validation loss: 0.026922\n",
            "Epoch: 41 Train loss: 0.0729 Validation loss: 0.02715\n",
            "Epoch: 42 Train loss: 0.070508 Validation loss: 0.027323\n",
            "Epoch: 43 Train loss: 0.068306 Validation loss: 0.027448\n",
            "Epoch: 44 Train loss: 0.066286 Validation loss: 0.027533\n",
            "Epoch: 45 Train loss: 0.064442 Validation loss: 0.027584\n",
            "Epoch: 46 Train loss: 0.062763 Validation loss: 0.02761\n",
            "Epoch: 47 Train loss: 0.061242 Validation loss: 0.027616\n",
            "Epoch: 48 Train loss: 0.059867 Validation loss: 0.02761\n",
            "Epoch: 49 Train loss: 0.058628 Validation loss: 0.027599\n",
            "Epoch: 50 Train loss: 0.057513 Validation loss: 0.027587\n",
            "Epoch: 51 Train loss: 0.056511 Validation loss: 0.027578\n",
            "Epoch: 52 Train loss: 0.05561 Validation loss: 0.027577\n",
            "Epoch: 53 Train loss: 0.054802 Validation loss: 0.027583\n",
            "Epoch: 54 Train loss: 0.054076 Validation loss: 0.027603\n",
            "Epoch: 55 Train loss: 0.053422 Validation loss: 0.027632\n",
            "Epoch: 56 Train loss: 0.052834 Validation loss: 0.027675\n",
            "Epoch: 57 Train loss: 0.052302 Validation loss: 0.027729\n",
            "Epoch: 58 Train loss: 0.051822 Validation loss: 0.027793\n",
            "Epoch: 59 Train loss: 0.051386 Validation loss: 0.02787\n",
            "Epoch: 60 Train loss: 0.05099 Validation loss: 0.027956\n",
            "Epoch: 61 Train loss: 0.050629 Validation loss: 0.028049\n",
            "Epoch: 62 Train loss: 0.050299 Validation loss: 0.028151\n",
            "Epoch: 63 Train loss: 0.049996 Validation loss: 0.028259\n",
            "Epoch: 64 Train loss: 0.049719 Validation loss: 0.028372\n",
            "Epoch: 65 Train loss: 0.049463 Validation loss: 0.02849\n",
            "Epoch: 66 Train loss: 0.049227 Validation loss: 0.028609\n",
            "Epoch: 67 Train loss: 0.049008 Validation loss: 0.028735\n",
            "Epoch: 68 Train loss: 0.048805 Validation loss: 0.028858\n",
            "Epoch: 69 Train loss: 0.048616 Validation loss: 0.028986\n",
            "Epoch: 70 Train loss: 0.04844 Validation loss: 0.029109\n",
            "Epoch: 71 Train loss: 0.048275 Validation loss: 0.029238\n",
            "Epoch: 72 Train loss: 0.04812 Validation loss: 0.029358\n",
            "Epoch: 73 Train loss: 0.047975 Validation loss: 0.029487\n",
            "Epoch: 74 Train loss: 0.047839 Validation loss: 0.029602\n",
            "Epoch: 75 Train loss: 0.047709 Validation loss: 0.029731\n",
            "Epoch: 76 Train loss: 0.047588 Validation loss: 0.029837\n",
            "Epoch: 77 Train loss: 0.047472 Validation loss: 0.02997\n",
            "Epoch: 78 Train loss: 0.047362 Validation loss: 0.030062\n",
            "Epoch: 79 Train loss: 0.047258 Validation loss: 0.030201\n",
            "Epoch: 80 Train loss: 0.047159 Validation loss: 0.03027\n",
            "Epoch: 81 Train loss: 0.047064 Validation loss: 0.03043\n",
            "Epoch: 82 Train loss: 0.046973 Validation loss: 0.030458\n",
            "Epoch: 83 Train loss: 0.046886 Validation loss: 0.03066\n",
            "Epoch: 84 Train loss: 0.046802 Validation loss: 0.030618\n",
            "Epoch: 85 Train loss: 0.046722 Validation loss: 0.030906\n",
            "Epoch: 86 Train loss: 0.046645 Validation loss: 0.030731\n",
            "Epoch: 87 Train loss: 0.046571 Validation loss: 0.03119\n",
            "Epoch: 88 Train loss: 0.046502 Validation loss: 0.030764\n",
            "Epoch: 89 Train loss: 0.046435 Validation loss: 0.031564\n",
            "Epoch: 90 Train loss: 0.046376 Validation loss: 0.030647\n",
            "Epoch: 91 Train loss: 0.046325 Validation loss: 0.03213\n",
            "Epoch: 92 Train loss: 0.046294 Validation loss: 0.030241\n",
            "Epoch: 93 Train loss: 0.04629 Validation loss: 0.033103\n",
            "Epoch: 94 Train loss: 0.046357 Validation loss: 0.029274\n",
            "Epoch: 95 Train loss: 0.046535 Validation loss: 0.034929\n",
            "Epoch: 96 Train loss: 0.046991 Validation loss: 0.027215\n",
            "Epoch: 97 Train loss: 0.047886 Validation loss: 0.038595\n",
            "Epoch: 98 Train loss: 0.049962 Validation loss: 0.023149\n",
            "Epoch: 99 Train loss: 0.053592 Validation loss: 0.046303\n",
            "Epoch: 100 Train loss: 0.06238 Validation loss: 0.015946\n",
            "Epoch: 101 Train loss: 0.074727 Validation loss: 0.062559\n",
            "Epoch: 102 Train loss: 0.1077 Validation loss: 0.0063373\n",
            "Epoch: 103 Train loss: 0.13006 Validation loss: 0.09052\n",
            "Epoch: 104 Train loss: 0.2073 Validation loss: 0.00062211\n",
            "Epoch: 105 Train loss: 0.17292 Validation loss: 0.10551\n",
            "Epoch: 106 Train loss: 0.21483 Validation loss: 0.0011177\n",
            "Epoch: 107 Train loss: 0.13081 Validation loss: 0.086577\n",
            "Epoch: 108 Train loss: 0.11441 Validation loss: 0.010299\n",
            "Epoch: 109 Train loss: 0.080615 Validation loss: 0.065571\n",
            "Epoch: 110 Train loss: 0.069926 Validation loss: 0.021124\n",
            "Epoch: 111 Train loss: 0.060304 Validation loss: 0.053368\n",
            "Epoch: 112 Train loss: 0.056377 Validation loss: 0.027116\n",
            "Epoch: 113 Train loss: 0.05321 Validation loss: 0.046805\n",
            "Epoch: 114 Train loss: 0.051591 Validation loss: 0.029735\n",
            "Epoch: 115 Train loss: 0.050245 Validation loss: 0.043003\n",
            "Epoch: 116 Train loss: 0.049429 Validation loss: 0.030679\n",
            "Epoch: 117 Train loss: 0.048715 Validation loss: 0.040621\n",
            "Epoch: 118 Train loss: 0.048237 Validation loss: 0.030834\n",
            "Epoch: 119 Train loss: 0.0478 Validation loss: 0.039068\n",
            "Epoch: 120 Train loss: 0.047498 Validation loss: 0.030619\n",
            "Epoch: 121 Train loss: 0.047211 Validation loss: 0.03807\n",
            "Epoch: 122 Train loss: 0.047018 Validation loss: 0.030223\n",
            "Epoch: 123 Train loss: 0.046827 Validation loss: 0.037492\n",
            "Epoch: 124 Train loss: 0.046717 Validation loss: 0.029718\n",
            "Epoch: 125 Train loss: 0.046599 Validation loss: 0.03727\n",
            "Epoch: 126 Train loss: 0.046567 Validation loss: 0.029119\n",
            "Epoch: 127 Train loss: 0.046517 Validation loss: 0.037382\n",
            "Epoch: 128 Train loss: 0.046573 Validation loss: 0.028404\n",
            "Epoch: 129 Train loss: 0.046601 Validation loss: 0.037843\n",
            "Epoch: 130 Train loss: 0.046778 Validation loss: 0.027526\n",
            "Epoch: 131 Train loss: 0.046912 Validation loss: 0.038696\n",
            "Epoch: 132 Train loss: 0.04728 Validation loss: 0.026422\n",
            "Epoch: 133 Train loss: 0.047568 Validation loss: 0.040025\n",
            "Epoch: 134 Train loss: 0.048257 Validation loss: 0.025014\n",
            "Epoch: 135 Train loss: 0.048778 Validation loss: 0.041951\n",
            "Epoch: 136 Train loss: 0.050017 Validation loss: 0.023232\n",
            "Epoch: 137 Train loss: 0.050867 Validation loss: 0.044617\n",
            "Epoch: 138 Train loss: 0.053034 Validation loss: 0.021039\n",
            "Epoch: 139 Train loss: 0.054266 Validation loss: 0.048149\n",
            "Epoch: 140 Train loss: 0.057892 Validation loss: 0.018502\n",
            "Epoch: 141 Train loss: 0.059318 Validation loss: 0.052499\n",
            "Epoch: 142 Train loss: 0.064899 Validation loss: 0.015874\n",
            "Epoch: 143 Train loss: 0.065735 Validation loss: 0.057219\n",
            "Epoch: 144 Train loss: 0.073153 Validation loss: 0.013639\n",
            "Epoch: 145 Train loss: 0.071889 Validation loss: 0.061255\n",
            "Epoch: 146 Train loss: 0.07973 Validation loss: 0.012382\n",
            "Epoch: 147 Train loss: 0.075113 Validation loss: 0.063293\n",
            "Epoch: 148 Train loss: 0.081146 Validation loss: 0.012494\n",
            "Epoch: 149 Train loss: 0.07385 Validation loss: 0.06274\n",
            "Epoch: 150 Train loss: 0.076927 Validation loss: 0.013906\n",
            "Epoch: 151 Train loss: 0.069226 Validation loss: 0.060196\n",
            "Epoch: 152 Train loss: 0.070013 Validation loss: 0.016104\n",
            "Epoch: 153 Train loss: 0.063673 Validation loss: 0.056825\n",
            "Epoch: 154 Train loss: 0.063415 Validation loss: 0.018444\n",
            "Epoch: 155 Train loss: 0.058859 Validation loss: 0.053527\n",
            "Epoch: 156 Train loss: 0.058364 Validation loss: 0.020485\n",
            "Epoch: 157 Train loss: 0.055268 Validation loss: 0.050725\n",
            "Epoch: 158 Train loss: 0.054854 Validation loss: 0.022062\n",
            "Epoch: 159 Train loss: 0.052766 Validation loss: 0.048518\n",
            "Epoch: 160 Train loss: 0.052506 Validation loss: 0.023183\n",
            "Epoch: 161 Train loss: 0.051071 Validation loss: 0.046864\n",
            "Epoch: 162 Train loss: 0.050956 Validation loss: 0.023921\n",
            "Epoch: 163 Train loss: 0.04994 Validation loss: 0.045684\n",
            "Epoch: 164 Train loss: 0.049948 Validation loss: 0.024359\n",
            "Epoch: 165 Train loss: 0.049204 Validation loss: 0.044899\n",
            "Epoch: 166 Train loss: 0.049319 Validation loss: 0.024567\n",
            "Epoch: 167 Train loss: 0.048756 Validation loss: 0.044441\n",
            "Epoch: 168 Train loss: 0.048969 Validation loss: 0.024591\n",
            "Epoch: 169 Train loss: 0.04853 Validation loss: 0.044262\n",
            "Epoch: 170 Train loss: 0.04884 Validation loss: 0.024472\n",
            "Epoch: 171 Train loss: 0.048488 Validation loss: 0.044326\n",
            "Epoch: 172 Train loss: 0.048901 Validation loss: 0.024231\n",
            "Epoch: 173 Train loss: 0.048609 Validation loss: 0.044602\n",
            "Epoch: 174 Train loss: 0.049136 Validation loss: 0.02389\n",
            "Epoch: 175 Train loss: 0.04888 Validation loss: 0.045062\n",
            "Epoch: 176 Train loss: 0.049535 Validation loss: 0.023468\n",
            "Epoch: 177 Train loss: 0.04929 Validation loss: 0.045681\n",
            "Epoch: 178 Train loss: 0.050086 Validation loss: 0.022985\n",
            "Epoch: 179 Train loss: 0.049827 Validation loss: 0.046428\n",
            "Epoch: 180 Train loss: 0.050773 Validation loss: 0.022466\n",
            "Epoch: 181 Train loss: 0.050464 Validation loss: 0.047262\n",
            "Epoch: 182 Train loss: 0.051559 Validation loss: 0.021939\n",
            "Epoch: 183 Train loss: 0.051162 Validation loss: 0.048135\n",
            "Epoch: 184 Train loss: 0.05239 Validation loss: 0.021441\n",
            "Epoch: 185 Train loss: 0.05186 Validation loss: 0.048987\n",
            "Epoch: 186 Train loss: 0.053188 Validation loss: 0.02101\n",
            "Epoch: 187 Train loss: 0.052484 Validation loss: 0.049756\n",
            "Epoch: 188 Train loss: 0.053861 Validation loss: 0.020681\n",
            "Epoch: 189 Train loss: 0.052959 Validation loss: 0.050379\n",
            "Epoch: 190 Train loss: 0.05432 Validation loss: 0.020483\n",
            "Epoch: 191 Train loss: 0.053216 Validation loss: 0.050809\n",
            "Epoch: 192 Train loss: 0.0545 Validation loss: 0.020432\n",
            "Epoch: 193 Train loss: 0.05322 Validation loss: 0.051017\n",
            "Epoch: 194 Train loss: 0.054378 Validation loss: 0.020523\n",
            "Epoch: 195 Train loss: 0.052972 Validation loss: 0.051011\n",
            "Epoch: 196 Train loss: 0.053976 Validation loss: 0.020742\n",
            "Epoch: 197 Train loss: 0.052507 Validation loss: 0.050814\n",
            "Epoch: 198 Train loss: 0.053353 Validation loss: 0.021059\n",
            "Epoch: 199 Train loss: 0.051884 Validation loss: 0.050469\n",
            "Epoch: 200 Train loss: 0.052587 Validation loss: 0.021439\n",
            "Epoch: 201 Train loss: 0.051169 Validation loss: 0.050027\n",
            "Epoch: 202 Train loss: 0.051754 Validation loss: 0.021848\n",
            "Epoch: 203 Train loss: 0.05042 Validation loss: 0.049537\n",
            "Epoch: 204 Train loss: 0.050916 Validation loss: 0.022256\n",
            "Epoch: 205 Train loss: 0.049685 Validation loss: 0.049043\n",
            "Epoch: 206 Train loss: 0.050117 Validation loss: 0.02264\n",
            "Epoch: 207 Train loss: 0.048995 Validation loss: 0.048575\n",
            "Epoch: 208 Train loss: 0.049385 Validation loss: 0.022983\n",
            "Epoch: 209 Train loss: 0.048366 Validation loss: 0.048156\n",
            "Epoch: 210 Train loss: 0.048733 Validation loss: 0.023278\n",
            "Epoch: 211 Train loss: 0.047808 Validation loss: 0.047805\n",
            "Epoch: 212 Train loss: 0.048166 Validation loss: 0.023521\n",
            "Epoch: 213 Train loss: 0.047322 Validation loss: 0.047525\n",
            "Epoch: 214 Train loss: 0.04768 Validation loss: 0.023709\n",
            "Epoch: 215 Train loss: 0.046905 Validation loss: 0.047318\n",
            "Epoch: 216 Train loss: 0.047273 Validation loss: 0.023846\n",
            "Epoch: 217 Train loss: 0.046554 Validation loss: 0.047187\n",
            "Epoch: 218 Train loss: 0.046937 Validation loss: 0.023933\n",
            "Epoch: 219 Train loss: 0.046262 Validation loss: 0.047127\n",
            "Epoch: 220 Train loss: 0.046666 Validation loss: 0.023978\n",
            "Epoch: 221 Train loss: 0.046025 Validation loss: 0.047133\n",
            "Epoch: 222 Train loss: 0.046454 Validation loss: 0.023982\n",
            "Epoch: 223 Train loss: 0.045838 Validation loss: 0.0472\n",
            "Epoch: 224 Train loss: 0.046295 Validation loss: 0.023952\n",
            "Epoch: 225 Train loss: 0.045694 Validation loss: 0.04732\n",
            "Epoch: 226 Train loss: 0.046182 Validation loss: 0.023893\n",
            "Epoch: 227 Train loss: 0.045587 Validation loss: 0.047487\n",
            "Epoch: 228 Train loss: 0.046109 Validation loss: 0.02381\n",
            "Epoch: 229 Train loss: 0.045514 Validation loss: 0.047691\n",
            "Epoch: 230 Train loss: 0.046069 Validation loss: 0.023709\n",
            "Epoch: 231 Train loss: 0.045466 Validation loss: 0.047926\n",
            "Epoch: 232 Train loss: 0.046056 Validation loss: 0.023596\n",
            "Epoch: 233 Train loss: 0.045438 Validation loss: 0.048181\n",
            "Epoch: 234 Train loss: 0.046061 Validation loss: 0.023474\n",
            "Epoch: 235 Train loss: 0.045423 Validation loss: 0.048448\n",
            "Epoch: 236 Train loss: 0.046078 Validation loss: 0.023353\n",
            "Epoch: 237 Train loss: 0.045414 Validation loss: 0.048718\n",
            "Epoch: 238 Train loss: 0.046097 Validation loss: 0.023234\n",
            "Epoch: 239 Train loss: 0.045404 Validation loss: 0.048984\n",
            "Epoch: 240 Train loss: 0.046111 Validation loss: 0.023123\n",
            "Epoch: 241 Train loss: 0.045387 Validation loss: 0.049237\n",
            "Epoch: 242 Train loss: 0.046114 Validation loss: 0.023025\n",
            "Epoch: 243 Train loss: 0.045356 Validation loss: 0.049472\n",
            "Epoch: 244 Train loss: 0.046098 Validation loss: 0.02294\n",
            "Epoch: 245 Train loss: 0.045307 Validation loss: 0.049683\n",
            "Epoch: 246 Train loss: 0.046059 Validation loss: 0.022871\n",
            "Epoch: 247 Train loss: 0.045238 Validation loss: 0.049867\n",
            "Epoch: 248 Train loss: 0.045996 Validation loss: 0.022818\n",
            "Epoch: 249 Train loss: 0.045146 Validation loss: 0.05002\n",
            "Epoch: 250 Train loss: 0.045907 Validation loss: 0.022782\n",
            "Epoch: 251 Train loss: 0.045033 Validation loss: 0.050148\n",
            "Epoch: 252 Train loss: 0.045793 Validation loss: 0.02276\n",
            "Epoch: 253 Train loss: 0.0449 Validation loss: 0.050249\n",
            "Epoch: 254 Train loss: 0.045658 Validation loss: 0.022749\n",
            "Epoch: 255 Train loss: 0.044752 Validation loss: 0.050328\n",
            "Epoch: 256 Train loss: 0.045506 Validation loss: 0.022747\n",
            "Epoch: 257 Train loss: 0.044591 Validation loss: 0.050385\n",
            "Epoch: 258 Train loss: 0.045343 Validation loss: 0.02275\n",
            "Epoch: 259 Train loss: 0.044422 Validation loss: 0.050428\n",
            "Epoch: 260 Train loss: 0.045172 Validation loss: 0.022757\n",
            "Epoch: 261 Train loss: 0.04425 Validation loss: 0.050461\n",
            "Epoch: 262 Train loss: 0.045 Validation loss: 0.022763\n",
            "Epoch: 263 Train loss: 0.044079 Validation loss: 0.050485\n",
            "Epoch: 264 Train loss: 0.044831 Validation loss: 0.022766\n",
            "Epoch: 265 Train loss: 0.043914 Validation loss: 0.050511\n",
            "Epoch: 266 Train loss: 0.044668 Validation loss: 0.022765\n",
            "Epoch: 267 Train loss: 0.043756 Validation loss: 0.050536\n",
            "Epoch: 268 Train loss: 0.044517 Validation loss: 0.022758\n",
            "Epoch: 269 Train loss: 0.043609 Validation loss: 0.050567\n",
            "Epoch: 270 Train loss: 0.044378 Validation loss: 0.022743\n",
            "Epoch: 271 Train loss: 0.043475 Validation loss: 0.050602\n",
            "Epoch: 272 Train loss: 0.044253 Validation loss: 0.02272\n",
            "Epoch: 273 Train loss: 0.043353 Validation loss: 0.050644\n",
            "Epoch: 274 Train loss: 0.044142 Validation loss: 0.02269\n",
            "Epoch: 275 Train loss: 0.043244 Validation loss: 0.050693\n",
            "Epoch: 276 Train loss: 0.044046 Validation loss: 0.022654\n",
            "Epoch: 277 Train loss: 0.043147 Validation loss: 0.050746\n",
            "Epoch: 278 Train loss: 0.043961 Validation loss: 0.022611\n",
            "Epoch: 279 Train loss: 0.043062 Validation loss: 0.050806\n",
            "Epoch: 280 Train loss: 0.043888 Validation loss: 0.022565\n",
            "Epoch: 281 Train loss: 0.042985 Validation loss: 0.05087\n",
            "Epoch: 282 Train loss: 0.043824 Validation loss: 0.022515\n",
            "Epoch: 283 Train loss: 0.042915 Validation loss: 0.050935\n",
            "Epoch: 284 Train loss: 0.043766 Validation loss: 0.022463\n",
            "Epoch: 285 Train loss: 0.042849 Validation loss: 0.050999\n",
            "Epoch: 286 Train loss: 0.043711 Validation loss: 0.022412\n",
            "Epoch: 287 Train loss: 0.042787 Validation loss: 0.051063\n",
            "Epoch: 288 Train loss: 0.043657 Validation loss: 0.022364\n",
            "Epoch: 289 Train loss: 0.042724 Validation loss: 0.05112\n",
            "Epoch: 290 Train loss: 0.043602 Validation loss: 0.022317\n",
            "Epoch: 291 Train loss: 0.042659 Validation loss: 0.051173\n",
            "Epoch: 292 Train loss: 0.043542 Validation loss: 0.022275\n",
            "Epoch: 293 Train loss: 0.04259 Validation loss: 0.051217\n",
            "Epoch: 294 Train loss: 0.043477 Validation loss: 0.022238\n",
            "Epoch: 295 Train loss: 0.042516 Validation loss: 0.051252\n",
            "Epoch: 296 Train loss: 0.043405 Validation loss: 0.022205\n",
            "Epoch: 297 Train loss: 0.042436 Validation loss: 0.051279\n",
            "Epoch: 298 Train loss: 0.043325 Validation loss: 0.022177\n",
            "Epoch: 299 Train loss: 0.04235 Validation loss: 0.051294\n",
            "Epoch: 300 Train loss: 0.043237 Validation loss: 0.022156\n",
            "Epoch: 301 Train loss: 0.042256 Validation loss: 0.051301\n",
            "Epoch: 302 Train loss: 0.043141 Validation loss: 0.02214\n",
            "Epoch: 303 Train loss: 0.042157 Validation loss: 0.051296\n",
            "Epoch: 304 Train loss: 0.043037 Validation loss: 0.022128\n",
            "Epoch: 305 Train loss: 0.042052 Validation loss: 0.051286\n",
            "Epoch: 306 Train loss: 0.042928 Validation loss: 0.022121\n",
            "Epoch: 307 Train loss: 0.041942 Validation loss: 0.051267\n",
            "Epoch: 308 Train loss: 0.042813 Validation loss: 0.022116\n",
            "Epoch: 309 Train loss: 0.041828 Validation loss: 0.051243\n",
            "Epoch: 310 Train loss: 0.042695 Validation loss: 0.022114\n",
            "Epoch: 311 Train loss: 0.041712 Validation loss: 0.051211\n",
            "Epoch: 312 Train loss: 0.042574 Validation loss: 0.022115\n",
            "Epoch: 313 Train loss: 0.041595 Validation loss: 0.05118\n",
            "Epoch: 314 Train loss: 0.042452 Validation loss: 0.022115\n",
            "Epoch: 315 Train loss: 0.041478 Validation loss: 0.051143\n",
            "Epoch: 316 Train loss: 0.042331 Validation loss: 0.022116\n",
            "Epoch: 317 Train loss: 0.04136 Validation loss: 0.051104\n",
            "Epoch: 318 Train loss: 0.042209 Validation loss: 0.022118\n",
            "Epoch: 319 Train loss: 0.041245 Validation loss: 0.051064\n",
            "Epoch: 320 Train loss: 0.04209 Validation loss: 0.022119\n",
            "Epoch: 321 Train loss: 0.04113 Validation loss: 0.051026\n",
            "Epoch: 322 Train loss: 0.041972 Validation loss: 0.02212\n",
            "Epoch: 323 Train loss: 0.041018 Validation loss: 0.050987\n",
            "Epoch: 324 Train loss: 0.041856 Validation loss: 0.022119\n",
            "Epoch: 325 Train loss: 0.040908 Validation loss: 0.050948\n",
            "Epoch: 326 Train loss: 0.041743 Validation loss: 0.022118\n",
            "Epoch: 327 Train loss: 0.0408 Validation loss: 0.050909\n",
            "Epoch: 328 Train loss: 0.041632 Validation loss: 0.022119\n",
            "Epoch: 329 Train loss: 0.040694 Validation loss: 0.050872\n",
            "Epoch: 330 Train loss: 0.041523 Validation loss: 0.022118\n",
            "Epoch: 331 Train loss: 0.04059 Validation loss: 0.050836\n",
            "Epoch: 332 Train loss: 0.041415 Validation loss: 0.022117\n",
            "Epoch: 333 Train loss: 0.040487 Validation loss: 0.050796\n",
            "Epoch: 334 Train loss: 0.041308 Validation loss: 0.022116\n",
            "Epoch: 335 Train loss: 0.040384 Validation loss: 0.050759\n",
            "Epoch: 336 Train loss: 0.041202 Validation loss: 0.022117\n",
            "Epoch: 337 Train loss: 0.040282 Validation loss: 0.050721\n",
            "Epoch: 338 Train loss: 0.041095 Validation loss: 0.022117\n",
            "Epoch: 339 Train loss: 0.04018 Validation loss: 0.050683\n",
            "Epoch: 340 Train loss: 0.040988 Validation loss: 0.022119\n",
            "Epoch: 341 Train loss: 0.040077 Validation loss: 0.05064\n",
            "Epoch: 342 Train loss: 0.04088 Validation loss: 0.022122\n",
            "Epoch: 343 Train loss: 0.039973 Validation loss: 0.050597\n",
            "Epoch: 344 Train loss: 0.040771 Validation loss: 0.022127\n",
            "Epoch: 345 Train loss: 0.039868 Validation loss: 0.050553\n",
            "Epoch: 346 Train loss: 0.040661 Validation loss: 0.022133\n",
            "Epoch: 347 Train loss: 0.039762 Validation loss: 0.050506\n",
            "Epoch: 348 Train loss: 0.040549 Validation loss: 0.02214\n",
            "Epoch: 349 Train loss: 0.039655 Validation loss: 0.050455\n",
            "Epoch: 350 Train loss: 0.040435 Validation loss: 0.022149\n",
            "Epoch: 351 Train loss: 0.039546 Validation loss: 0.050404\n",
            "Epoch: 352 Train loss: 0.04032 Validation loss: 0.022159\n",
            "Epoch: 353 Train loss: 0.039436 Validation loss: 0.050352\n",
            "Epoch: 354 Train loss: 0.040202 Validation loss: 0.022171\n",
            "Epoch: 355 Train loss: 0.039325 Validation loss: 0.050296\n",
            "Epoch: 356 Train loss: 0.040084 Validation loss: 0.022184\n",
            "Epoch: 357 Train loss: 0.039212 Validation loss: 0.050236\n",
            "Epoch: 358 Train loss: 0.039965 Validation loss: 0.022197\n",
            "Epoch: 359 Train loss: 0.039099 Validation loss: 0.050178\n",
            "Epoch: 360 Train loss: 0.039844 Validation loss: 0.022212\n",
            "Epoch: 361 Train loss: 0.038985 Validation loss: 0.050116\n",
            "Epoch: 362 Train loss: 0.039723 Validation loss: 0.022229\n",
            "Epoch: 363 Train loss: 0.038871 Validation loss: 0.050054\n",
            "Epoch: 364 Train loss: 0.039601 Validation loss: 0.022244\n",
            "Epoch: 365 Train loss: 0.038756 Validation loss: 0.049991\n",
            "Epoch: 366 Train loss: 0.039479 Validation loss: 0.02226\n",
            "Epoch: 367 Train loss: 0.038641 Validation loss: 0.049926\n",
            "Epoch: 368 Train loss: 0.039357 Validation loss: 0.022278\n",
            "Epoch: 369 Train loss: 0.038526 Validation loss: 0.049861\n",
            "Epoch: 370 Train loss: 0.039234 Validation loss: 0.022296\n",
            "Epoch: 371 Train loss: 0.038412 Validation loss: 0.049797\n",
            "Epoch: 372 Train loss: 0.039113 Validation loss: 0.022313\n",
            "Epoch: 373 Train loss: 0.038297 Validation loss: 0.049731\n",
            "Epoch: 374 Train loss: 0.038991 Validation loss: 0.022332\n",
            "Epoch: 375 Train loss: 0.038183 Validation loss: 0.049664\n",
            "Epoch: 376 Train loss: 0.038869 Validation loss: 0.022349\n",
            "Epoch: 377 Train loss: 0.038069 Validation loss: 0.049597\n",
            "Epoch: 378 Train loss: 0.038748 Validation loss: 0.022367\n",
            "Epoch: 379 Train loss: 0.037955 Validation loss: 0.04953\n",
            "Epoch: 380 Train loss: 0.038628 Validation loss: 0.022386\n",
            "Epoch: 381 Train loss: 0.037842 Validation loss: 0.049463\n",
            "Epoch: 382 Train loss: 0.038508 Validation loss: 0.022404\n",
            "Epoch: 383 Train loss: 0.037729 Validation loss: 0.049396\n",
            "Epoch: 384 Train loss: 0.038388 Validation loss: 0.022423\n",
            "Epoch: 385 Train loss: 0.037617 Validation loss: 0.049328\n",
            "Epoch: 386 Train loss: 0.038268 Validation loss: 0.022442\n",
            "Epoch: 387 Train loss: 0.037505 Validation loss: 0.049258\n",
            "Epoch: 388 Train loss: 0.038149 Validation loss: 0.022461\n",
            "Epoch: 389 Train loss: 0.037393 Validation loss: 0.04919\n",
            "Epoch: 390 Train loss: 0.03803 Validation loss: 0.022479\n",
            "Epoch: 391 Train loss: 0.037281 Validation loss: 0.049121\n",
            "Epoch: 392 Train loss: 0.037911 Validation loss: 0.022499\n",
            "Epoch: 393 Train loss: 0.03717 Validation loss: 0.049051\n",
            "Epoch: 394 Train loss: 0.037793 Validation loss: 0.022518\n",
            "Epoch: 395 Train loss: 0.037058 Validation loss: 0.048982\n",
            "Epoch: 396 Train loss: 0.037674 Validation loss: 0.022538\n",
            "Epoch: 397 Train loss: 0.036947 Validation loss: 0.048911\n",
            "Epoch: 398 Train loss: 0.037556 Validation loss: 0.022558\n",
            "Epoch: 399 Train loss: 0.036836 Validation loss: 0.04884\n",
            "Epoch: 400 Train loss: 0.037438 Validation loss: 0.022579\n",
            "Epoch: 401 Train loss: 0.036725 Validation loss: 0.048769\n",
            "Epoch: 402 Train loss: 0.03732 Validation loss: 0.022599\n",
            "Epoch: 403 Train loss: 0.036614 Validation loss: 0.048697\n",
            "Epoch: 404 Train loss: 0.037202 Validation loss: 0.02262\n",
            "Epoch: 405 Train loss: 0.036503 Validation loss: 0.048624\n",
            "Epoch: 406 Train loss: 0.037083 Validation loss: 0.022641\n",
            "Epoch: 407 Train loss: 0.036392 Validation loss: 0.048551\n",
            "Epoch: 408 Train loss: 0.036965 Validation loss: 0.022662\n",
            "Epoch: 409 Train loss: 0.036281 Validation loss: 0.048477\n",
            "Epoch: 410 Train loss: 0.036847 Validation loss: 0.022684\n",
            "Epoch: 411 Train loss: 0.03617 Validation loss: 0.048403\n",
            "Epoch: 412 Train loss: 0.036729 Validation loss: 0.022706\n",
            "Epoch: 413 Train loss: 0.03606 Validation loss: 0.048328\n",
            "Epoch: 414 Train loss: 0.036612 Validation loss: 0.022727\n",
            "Epoch: 415 Train loss: 0.03595 Validation loss: 0.048254\n",
            "Epoch: 416 Train loss: 0.036495 Validation loss: 0.022748\n",
            "Epoch: 417 Train loss: 0.035841 Validation loss: 0.04818\n",
            "Epoch: 418 Train loss: 0.036379 Validation loss: 0.02277\n",
            "Epoch: 419 Train loss: 0.035731 Validation loss: 0.048104\n",
            "Epoch: 420 Train loss: 0.036262 Validation loss: 0.022792\n",
            "Epoch: 421 Train loss: 0.035622 Validation loss: 0.048029\n",
            "Epoch: 422 Train loss: 0.036146 Validation loss: 0.022814\n",
            "Epoch: 423 Train loss: 0.035513 Validation loss: 0.047953\n",
            "Epoch: 424 Train loss: 0.036031 Validation loss: 0.022836\n",
            "Epoch: 425 Train loss: 0.035405 Validation loss: 0.047877\n",
            "Epoch: 426 Train loss: 0.035915 Validation loss: 0.022858\n",
            "Epoch: 427 Train loss: 0.035297 Validation loss: 0.0478\n",
            "Epoch: 428 Train loss: 0.035801 Validation loss: 0.022879\n",
            "Epoch: 429 Train loss: 0.035189 Validation loss: 0.047725\n",
            "Epoch: 430 Train loss: 0.035686 Validation loss: 0.022902\n",
            "Epoch: 431 Train loss: 0.035082 Validation loss: 0.047648\n",
            "Epoch: 432 Train loss: 0.035573 Validation loss: 0.022922\n",
            "Epoch: 433 Train loss: 0.034976 Validation loss: 0.047573\n",
            "Epoch: 434 Train loss: 0.03546 Validation loss: 0.022945\n",
            "Epoch: 435 Train loss: 0.034869 Validation loss: 0.047496\n",
            "Epoch: 436 Train loss: 0.035347 Validation loss: 0.022966\n",
            "Epoch: 437 Train loss: 0.034764 Validation loss: 0.04742\n",
            "Epoch: 438 Train loss: 0.035235 Validation loss: 0.022988\n",
            "Epoch: 439 Train loss: 0.034658 Validation loss: 0.047343\n",
            "Epoch: 440 Train loss: 0.035123 Validation loss: 0.023008\n",
            "Epoch: 441 Train loss: 0.034554 Validation loss: 0.047267\n",
            "Epoch: 442 Train loss: 0.035013 Validation loss: 0.023029\n",
            "Epoch: 443 Train loss: 0.03445 Validation loss: 0.047191\n",
            "Epoch: 444 Train loss: 0.034902 Validation loss: 0.02305\n",
            "Epoch: 445 Train loss: 0.034346 Validation loss: 0.047114\n",
            "Epoch: 446 Train loss: 0.034793 Validation loss: 0.02307\n",
            "Epoch: 447 Train loss: 0.034243 Validation loss: 0.047039\n",
            "Epoch: 448 Train loss: 0.034684 Validation loss: 0.023092\n",
            "Epoch: 449 Train loss: 0.03414 Validation loss: 0.046962\n",
            "Epoch: 450 Train loss: 0.034575 Validation loss: 0.023111\n",
            "Epoch: 451 Train loss: 0.034039 Validation loss: 0.046887\n",
            "Epoch: 452 Train loss: 0.034467 Validation loss: 0.023132\n",
            "Epoch: 453 Train loss: 0.033937 Validation loss: 0.046812\n",
            "Epoch: 454 Train loss: 0.03436 Validation loss: 0.023153\n",
            "Epoch: 455 Train loss: 0.033836 Validation loss: 0.046735\n",
            "Epoch: 456 Train loss: 0.034253 Validation loss: 0.023172\n",
            "Epoch: 457 Train loss: 0.033736 Validation loss: 0.046659\n",
            "Epoch: 458 Train loss: 0.034147 Validation loss: 0.023192\n",
            "Epoch: 459 Train loss: 0.033636 Validation loss: 0.046585\n",
            "Epoch: 460 Train loss: 0.034042 Validation loss: 0.023211\n",
            "Epoch: 461 Train loss: 0.033537 Validation loss: 0.046509\n",
            "Epoch: 462 Train loss: 0.033938 Validation loss: 0.02323\n",
            "Epoch: 463 Train loss: 0.033439 Validation loss: 0.046433\n",
            "Epoch: 464 Train loss: 0.033834 Validation loss: 0.02325\n",
            "Epoch: 465 Train loss: 0.033341 Validation loss: 0.046359\n",
            "Epoch: 466 Train loss: 0.03373 Validation loss: 0.023269\n",
            "Epoch: 467 Train loss: 0.033243 Validation loss: 0.046284\n",
            "Epoch: 468 Train loss: 0.033628 Validation loss: 0.023287\n",
            "Epoch: 469 Train loss: 0.033147 Validation loss: 0.046209\n",
            "Epoch: 470 Train loss: 0.033526 Validation loss: 0.023305\n",
            "Epoch: 471 Train loss: 0.033051 Validation loss: 0.046135\n",
            "Epoch: 472 Train loss: 0.033425 Validation loss: 0.023323\n",
            "Epoch: 473 Train loss: 0.032956 Validation loss: 0.046061\n",
            "Epoch: 474 Train loss: 0.033325 Validation loss: 0.02334\n",
            "Epoch: 475 Train loss: 0.032861 Validation loss: 0.045987\n",
            "Epoch: 476 Train loss: 0.033225 Validation loss: 0.023358\n",
            "Epoch: 477 Train loss: 0.032767 Validation loss: 0.045914\n",
            "Epoch: 478 Train loss: 0.033126 Validation loss: 0.023375\n",
            "Epoch: 479 Train loss: 0.032674 Validation loss: 0.04584\n",
            "Epoch: 480 Train loss: 0.033028 Validation loss: 0.023391\n",
            "Epoch: 481 Train loss: 0.032581 Validation loss: 0.045767\n",
            "Epoch: 482 Train loss: 0.03293 Validation loss: 0.023407\n",
            "Epoch: 483 Train loss: 0.032489 Validation loss: 0.045694\n",
            "Epoch: 484 Train loss: 0.032834 Validation loss: 0.023423\n",
            "Epoch: 485 Train loss: 0.032398 Validation loss: 0.045622\n",
            "Epoch: 486 Train loss: 0.032738 Validation loss: 0.023439\n",
            "Epoch: 487 Train loss: 0.032307 Validation loss: 0.045549\n",
            "Epoch: 488 Train loss: 0.032643 Validation loss: 0.023454\n",
            "Epoch: 489 Train loss: 0.032217 Validation loss: 0.045478\n",
            "Epoch: 490 Train loss: 0.032548 Validation loss: 0.023469\n",
            "Epoch: 491 Train loss: 0.032128 Validation loss: 0.045408\n",
            "Epoch: 492 Train loss: 0.032455 Validation loss: 0.023484\n",
            "Epoch: 493 Train loss: 0.03204 Validation loss: 0.045336\n",
            "Epoch: 494 Train loss: 0.032362 Validation loss: 0.023496\n",
            "Epoch: 495 Train loss: 0.031952 Validation loss: 0.045266\n",
            "Epoch: 496 Train loss: 0.03227 Validation loss: 0.023511\n",
            "Epoch: 497 Train loss: 0.031865 Validation loss: 0.045195\n",
            "Epoch: 498 Train loss: 0.032179 Validation loss: 0.023524\n",
            "Epoch: 499 Train loss: 0.031779 Validation loss: 0.045127\n",
            "Epoch: 500 Train loss: 0.032088 Validation loss: 0.023536\n",
            "Epoch: 501 Train loss: 0.031693 Validation loss: 0.045057\n",
            "Epoch: 502 Train loss: 0.031999 Validation loss: 0.023549\n",
            "Epoch: 503 Train loss: 0.031609 Validation loss: 0.044989\n",
            "Epoch: 504 Train loss: 0.03191 Validation loss: 0.023562\n",
            "Epoch: 505 Train loss: 0.031525 Validation loss: 0.04492\n",
            "Epoch: 506 Train loss: 0.031822 Validation loss: 0.023572\n",
            "Epoch: 507 Train loss: 0.031441 Validation loss: 0.044853\n",
            "Epoch: 508 Train loss: 0.031735 Validation loss: 0.023583\n",
            "Epoch: 509 Train loss: 0.031359 Validation loss: 0.044785\n",
            "Epoch: 510 Train loss: 0.031649 Validation loss: 0.023593\n",
            "Epoch: 511 Train loss: 0.031277 Validation loss: 0.04472\n",
            "Epoch: 512 Train loss: 0.031564 Validation loss: 0.023604\n",
            "Epoch: 513 Train loss: 0.031197 Validation loss: 0.044653\n",
            "Epoch: 514 Train loss: 0.03148 Validation loss: 0.023613\n",
            "Epoch: 515 Train loss: 0.031117 Validation loss: 0.044588\n",
            "Epoch: 516 Train loss: 0.031397 Validation loss: 0.023621\n",
            "Epoch: 517 Train loss: 0.031038 Validation loss: 0.044524\n",
            "Epoch: 518 Train loss: 0.031315 Validation loss: 0.023629\n",
            "Epoch: 519 Train loss: 0.03096 Validation loss: 0.044459\n",
            "Epoch: 520 Train loss: 0.031233 Validation loss: 0.023636\n",
            "Epoch: 521 Train loss: 0.030883 Validation loss: 0.044398\n",
            "Epoch: 522 Train loss: 0.031153 Validation loss: 0.023644\n",
            "Epoch: 523 Train loss: 0.030806 Validation loss: 0.044335\n",
            "Epoch: 524 Train loss: 0.031073 Validation loss: 0.02365\n",
            "Epoch: 525 Train loss: 0.030731 Validation loss: 0.044273\n",
            "Epoch: 526 Train loss: 0.030995 Validation loss: 0.023655\n",
            "Epoch: 527 Train loss: 0.030656 Validation loss: 0.04421\n",
            "Epoch: 528 Train loss: 0.030917 Validation loss: 0.023661\n",
            "Epoch: 529 Train loss: 0.030582 Validation loss: 0.044151\n",
            "Epoch: 530 Train loss: 0.03084 Validation loss: 0.023665\n",
            "Epoch: 531 Train loss: 0.030509 Validation loss: 0.044091\n",
            "Epoch: 532 Train loss: 0.030764 Validation loss: 0.023669\n",
            "Epoch: 533 Train loss: 0.030437 Validation loss: 0.044031\n",
            "Epoch: 534 Train loss: 0.030689 Validation loss: 0.023672\n",
            "Epoch: 535 Train loss: 0.030366 Validation loss: 0.043972\n",
            "Epoch: 536 Train loss: 0.030615 Validation loss: 0.023674\n",
            "Epoch: 537 Train loss: 0.030295 Validation loss: 0.043915\n",
            "Epoch: 538 Train loss: 0.030542 Validation loss: 0.023677\n",
            "Epoch: 539 Train loss: 0.030226 Validation loss: 0.043857\n",
            "Epoch: 540 Train loss: 0.03047 Validation loss: 0.023677\n",
            "Epoch: 541 Train loss: 0.030157 Validation loss: 0.043803\n",
            "Epoch: 542 Train loss: 0.030399 Validation loss: 0.023679\n",
            "Epoch: 543 Train loss: 0.030089 Validation loss: 0.043747\n",
            "Epoch: 544 Train loss: 0.030329 Validation loss: 0.023678\n",
            "Epoch: 545 Train loss: 0.030022 Validation loss: 0.043693\n",
            "Epoch: 546 Train loss: 0.03026 Validation loss: 0.023678\n",
            "Epoch: 547 Train loss: 0.029956 Validation loss: 0.04364\n",
            "Epoch: 548 Train loss: 0.030192 Validation loss: 0.023676\n",
            "Epoch: 549 Train loss: 0.029892 Validation loss: 0.043587\n",
            "Epoch: 550 Train loss: 0.030124 Validation loss: 0.023674\n",
            "Epoch: 551 Train loss: 0.029828 Validation loss: 0.043534\n",
            "Epoch: 552 Train loss: 0.030058 Validation loss: 0.023671\n",
            "Epoch: 553 Train loss: 0.029764 Validation loss: 0.043484\n",
            "Epoch: 554 Train loss: 0.029993 Validation loss: 0.023667\n",
            "Epoch: 555 Train loss: 0.029702 Validation loss: 0.043433\n",
            "Epoch: 556 Train loss: 0.029929 Validation loss: 0.023662\n",
            "Epoch: 557 Train loss: 0.029641 Validation loss: 0.043384\n",
            "Epoch: 558 Train loss: 0.029866 Validation loss: 0.023657\n",
            "Epoch: 559 Train loss: 0.029581 Validation loss: 0.043335\n",
            "Epoch: 560 Train loss: 0.029804 Validation loss: 0.023652\n",
            "Epoch: 561 Train loss: 0.029522 Validation loss: 0.043288\n",
            "Epoch: 562 Train loss: 0.029743 Validation loss: 0.023645\n",
            "Epoch: 563 Train loss: 0.029463 Validation loss: 0.043242\n",
            "Epoch: 564 Train loss: 0.029683 Validation loss: 0.023638\n",
            "Epoch: 565 Train loss: 0.029406 Validation loss: 0.043196\n",
            "Epoch: 566 Train loss: 0.029624 Validation loss: 0.02363\n",
            "Epoch: 567 Train loss: 0.02935 Validation loss: 0.043152\n",
            "Epoch: 568 Train loss: 0.029566 Validation loss: 0.023621\n",
            "Epoch: 569 Train loss: 0.029294 Validation loss: 0.043108\n",
            "Epoch: 570 Train loss: 0.029509 Validation loss: 0.02361\n",
            "Epoch: 571 Train loss: 0.02924 Validation loss: 0.043064\n",
            "Epoch: 572 Train loss: 0.029453 Validation loss: 0.023601\n",
            "Epoch: 573 Train loss: 0.029186 Validation loss: 0.043024\n",
            "Epoch: 574 Train loss: 0.029398 Validation loss: 0.023589\n",
            "Epoch: 575 Train loss: 0.029133 Validation loss: 0.042982\n",
            "Epoch: 576 Train loss: 0.029344 Validation loss: 0.023577\n",
            "Epoch: 577 Train loss: 0.029081 Validation loss: 0.042942\n",
            "Epoch: 578 Train loss: 0.029291 Validation loss: 0.023565\n",
            "Epoch: 579 Train loss: 0.02903 Validation loss: 0.042903\n",
            "Epoch: 580 Train loss: 0.029238 Validation loss: 0.023552\n",
            "Epoch: 581 Train loss: 0.02898 Validation loss: 0.042864\n",
            "Epoch: 582 Train loss: 0.029187 Validation loss: 0.023538\n",
            "Epoch: 583 Train loss: 0.028931 Validation loss: 0.042826\n",
            "Epoch: 584 Train loss: 0.029137 Validation loss: 0.023523\n",
            "Epoch: 585 Train loss: 0.028883 Validation loss: 0.042789\n",
            "Epoch: 586 Train loss: 0.029087 Validation loss: 0.023507\n",
            "Epoch: 587 Train loss: 0.028835 Validation loss: 0.042752\n",
            "Epoch: 588 Train loss: 0.029039 Validation loss: 0.023491\n",
            "Epoch: 589 Train loss: 0.028789 Validation loss: 0.042718\n",
            "Epoch: 590 Train loss: 0.028991 Validation loss: 0.023475\n",
            "Epoch: 591 Train loss: 0.028743 Validation loss: 0.042684\n",
            "Epoch: 592 Train loss: 0.028945 Validation loss: 0.023457\n",
            "Epoch: 593 Train loss: 0.028698 Validation loss: 0.04265\n",
            "Epoch: 594 Train loss: 0.028899 Validation loss: 0.023438\n",
            "Epoch: 595 Train loss: 0.028654 Validation loss: 0.042617\n",
            "Epoch: 596 Train loss: 0.028854 Validation loss: 0.02342\n",
            "Epoch: 597 Train loss: 0.028611 Validation loss: 0.042585\n",
            "Epoch: 598 Train loss: 0.02881 Validation loss: 0.023401\n",
            "Epoch: 599 Train loss: 0.028569 Validation loss: 0.042553\n",
            "Epoch: 600 Train loss: 0.028767 Validation loss: 0.023381\n",
            "Epoch: 601 Train loss: 0.028527 Validation loss: 0.042524\n",
            "Epoch: 602 Train loss: 0.028724 Validation loss: 0.023361\n",
            "Epoch: 603 Train loss: 0.028486 Validation loss: 0.042494\n",
            "Epoch: 604 Train loss: 0.028683 Validation loss: 0.023339\n",
            "Epoch: 605 Train loss: 0.028446 Validation loss: 0.042465\n",
            "Epoch: 606 Train loss: 0.028642 Validation loss: 0.023317\n",
            "Epoch: 607 Train loss: 0.028407 Validation loss: 0.042436\n",
            "Epoch: 608 Train loss: 0.028602 Validation loss: 0.023294\n",
            "Epoch: 609 Train loss: 0.028369 Validation loss: 0.042408\n",
            "Epoch: 610 Train loss: 0.028563 Validation loss: 0.023271\n",
            "Epoch: 611 Train loss: 0.028331 Validation loss: 0.042382\n",
            "Epoch: 612 Train loss: 0.028525 Validation loss: 0.023249\n",
            "Epoch: 613 Train loss: 0.028294 Validation loss: 0.042356\n",
            "Epoch: 614 Train loss: 0.028487 Validation loss: 0.023224\n",
            "Epoch: 615 Train loss: 0.028258 Validation loss: 0.042329\n",
            "Epoch: 616 Train loss: 0.02845 Validation loss: 0.023201\n",
            "Epoch: 617 Train loss: 0.028222 Validation loss: 0.042305\n",
            "Epoch: 618 Train loss: 0.028414 Validation loss: 0.023176\n",
            "Epoch: 619 Train loss: 0.028187 Validation loss: 0.04228\n",
            "Epoch: 620 Train loss: 0.028378 Validation loss: 0.023151\n",
            "Epoch: 621 Train loss: 0.028153 Validation loss: 0.042255\n",
            "Epoch: 622 Train loss: 0.028343 Validation loss: 0.023125\n",
            "Epoch: 623 Train loss: 0.028119 Validation loss: 0.042232\n",
            "Epoch: 624 Train loss: 0.028308 Validation loss: 0.0231\n",
            "Epoch: 625 Train loss: 0.028086 Validation loss: 0.042209\n",
            "Epoch: 626 Train loss: 0.028275 Validation loss: 0.023074\n",
            "Epoch: 627 Train loss: 0.028053 Validation loss: 0.042185\n",
            "Epoch: 628 Train loss: 0.028241 Validation loss: 0.023046\n",
            "Epoch: 629 Train loss: 0.028021 Validation loss: 0.042163\n",
            "Epoch: 630 Train loss: 0.028209 Validation loss: 0.02302\n",
            "Epoch: 631 Train loss: 0.02799 Validation loss: 0.04214\n",
            "Epoch: 632 Train loss: 0.028177 Validation loss: 0.022993\n",
            "Epoch: 633 Train loss: 0.027959 Validation loss: 0.042118\n",
            "Epoch: 634 Train loss: 0.028145 Validation loss: 0.022966\n",
            "Epoch: 635 Train loss: 0.027928 Validation loss: 0.042097\n",
            "Epoch: 636 Train loss: 0.028114 Validation loss: 0.022937\n",
            "Epoch: 637 Train loss: 0.027898 Validation loss: 0.042075\n",
            "Epoch: 638 Train loss: 0.028083 Validation loss: 0.022909\n",
            "Epoch: 639 Train loss: 0.027869 Validation loss: 0.042053\n",
            "Epoch: 640 Train loss: 0.028053 Validation loss: 0.022881\n",
            "Epoch: 641 Train loss: 0.02784 Validation loss: 0.042033\n",
            "Epoch: 642 Train loss: 0.028023 Validation loss: 0.022854\n",
            "Epoch: 643 Train loss: 0.027811 Validation loss: 0.042012\n",
            "Epoch: 644 Train loss: 0.027993 Validation loss: 0.022826\n",
            "Epoch: 645 Train loss: 0.027782 Validation loss: 0.041992\n",
            "Epoch: 646 Train loss: 0.027964 Validation loss: 0.022797\n",
            "Epoch: 647 Train loss: 0.027754 Validation loss: 0.04197\n",
            "Epoch: 648 Train loss: 0.027935 Validation loss: 0.022768\n",
            "Epoch: 649 Train loss: 0.027726 Validation loss: 0.04195\n",
            "Epoch: 650 Train loss: 0.027907 Validation loss: 0.02274\n",
            "Epoch: 651 Train loss: 0.027699 Validation loss: 0.041928\n",
            "Epoch: 652 Train loss: 0.027878 Validation loss: 0.022711\n",
            "Epoch: 653 Train loss: 0.027671 Validation loss: 0.041908\n",
            "Epoch: 654 Train loss: 0.02785 Validation loss: 0.022683\n",
            "Epoch: 655 Train loss: 0.027644 Validation loss: 0.041888\n",
            "Epoch: 656 Train loss: 0.027823 Validation loss: 0.022654\n",
            "Epoch: 657 Train loss: 0.027618 Validation loss: 0.041867\n",
            "Epoch: 658 Train loss: 0.027795 Validation loss: 0.022625\n",
            "Epoch: 659 Train loss: 0.027591 Validation loss: 0.041846\n",
            "Epoch: 660 Train loss: 0.027768 Validation loss: 0.022598\n",
            "Epoch: 661 Train loss: 0.027565 Validation loss: 0.041826\n",
            "Epoch: 662 Train loss: 0.027741 Validation loss: 0.022569\n",
            "Epoch: 663 Train loss: 0.027539 Validation loss: 0.041804\n",
            "Epoch: 664 Train loss: 0.027713 Validation loss: 0.02254\n",
            "Epoch: 665 Train loss: 0.027513 Validation loss: 0.041784\n",
            "Epoch: 666 Train loss: 0.027686 Validation loss: 0.022513\n",
            "Epoch: 667 Train loss: 0.027487 Validation loss: 0.041763\n",
            "Epoch: 668 Train loss: 0.02766 Validation loss: 0.022484\n",
            "Epoch: 669 Train loss: 0.027461 Validation loss: 0.04174\n",
            "Epoch: 670 Train loss: 0.027633 Validation loss: 0.022457\n",
            "Epoch: 671 Train loss: 0.027436 Validation loss: 0.041719\n",
            "Epoch: 672 Train loss: 0.027607 Validation loss: 0.022429\n",
            "Epoch: 673 Train loss: 0.02741 Validation loss: 0.041697\n",
            "Epoch: 674 Train loss: 0.027581 Validation loss: 0.022401\n",
            "Epoch: 675 Train loss: 0.027385 Validation loss: 0.041676\n",
            "Epoch: 676 Train loss: 0.027554 Validation loss: 0.022372\n",
            "Epoch: 677 Train loss: 0.02736 Validation loss: 0.041652\n",
            "Epoch: 678 Train loss: 0.027528 Validation loss: 0.022346\n",
            "Epoch: 679 Train loss: 0.027335 Validation loss: 0.04163\n",
            "Epoch: 680 Train loss: 0.027502 Validation loss: 0.022318\n",
            "Epoch: 681 Train loss: 0.02731 Validation loss: 0.041608\n",
            "Epoch: 682 Train loss: 0.027476 Validation loss: 0.022291\n",
            "Epoch: 683 Train loss: 0.027285 Validation loss: 0.041584\n",
            "Epoch: 684 Train loss: 0.02745 Validation loss: 0.022264\n",
            "Epoch: 685 Train loss: 0.02726 Validation loss: 0.041561\n",
            "Epoch: 686 Train loss: 0.027424 Validation loss: 0.022237\n",
            "Epoch: 687 Train loss: 0.027236 Validation loss: 0.041537\n",
            "Epoch: 688 Train loss: 0.027398 Validation loss: 0.022211\n",
            "Epoch: 689 Train loss: 0.027211 Validation loss: 0.041513\n",
            "Epoch: 690 Train loss: 0.027373 Validation loss: 0.022184\n",
            "Epoch: 691 Train loss: 0.027186 Validation loss: 0.041491\n",
            "Epoch: 692 Train loss: 0.027347 Validation loss: 0.022158\n",
            "Epoch: 693 Train loss: 0.027162 Validation loss: 0.041466\n",
            "Epoch: 694 Train loss: 0.027321 Validation loss: 0.022133\n",
            "Epoch: 695 Train loss: 0.027137 Validation loss: 0.041442\n",
            "Epoch: 696 Train loss: 0.027296 Validation loss: 0.022106\n",
            "Epoch: 697 Train loss: 0.027113 Validation loss: 0.041416\n",
            "Epoch: 698 Train loss: 0.02727 Validation loss: 0.022081\n",
            "Epoch: 699 Train loss: 0.027089 Validation loss: 0.041392\n",
            "Epoch: 700 Train loss: 0.027245 Validation loss: 0.022056\n",
            "Epoch: 701 Train loss: 0.027064 Validation loss: 0.041367\n",
            "Epoch: 702 Train loss: 0.027219 Validation loss: 0.02203\n",
            "Epoch: 703 Train loss: 0.02704 Validation loss: 0.041341\n",
            "Epoch: 704 Train loss: 0.027194 Validation loss: 0.022005\n",
            "Epoch: 705 Train loss: 0.027016 Validation loss: 0.041314\n",
            "Epoch: 706 Train loss: 0.027169 Validation loss: 0.02198\n",
            "Epoch: 707 Train loss: 0.026992 Validation loss: 0.041289\n",
            "Epoch: 708 Train loss: 0.027143 Validation loss: 0.021955\n",
            "Epoch: 709 Train loss: 0.026968 Validation loss: 0.041263\n",
            "Epoch: 710 Train loss: 0.027118 Validation loss: 0.02193\n",
            "Epoch: 711 Train loss: 0.026944 Validation loss: 0.041236\n",
            "Epoch: 712 Train loss: 0.027093 Validation loss: 0.021905\n",
            "Epoch: 713 Train loss: 0.02692 Validation loss: 0.041209\n",
            "Epoch: 714 Train loss: 0.027068 Validation loss: 0.021881\n",
            "Epoch: 715 Train loss: 0.026897 Validation loss: 0.041183\n",
            "Epoch: 716 Train loss: 0.027043 Validation loss: 0.021856\n",
            "Epoch: 717 Train loss: 0.026873 Validation loss: 0.041155\n",
            "Epoch: 718 Train loss: 0.027018 Validation loss: 0.021833\n",
            "Epoch: 719 Train loss: 0.026849 Validation loss: 0.041127\n",
            "Epoch: 720 Train loss: 0.026994 Validation loss: 0.021808\n",
            "Epoch: 721 Train loss: 0.026826 Validation loss: 0.0411\n",
            "Epoch: 722 Train loss: 0.026969 Validation loss: 0.021784\n",
            "Epoch: 723 Train loss: 0.026803 Validation loss: 0.041073\n",
            "Epoch: 724 Train loss: 0.026944 Validation loss: 0.02176\n",
            "Epoch: 725 Train loss: 0.026779 Validation loss: 0.041044\n",
            "Epoch: 726 Train loss: 0.02692 Validation loss: 0.021737\n",
            "Epoch: 727 Train loss: 0.026756 Validation loss: 0.041016\n",
            "Epoch: 728 Train loss: 0.026895 Validation loss: 0.021713\n",
            "Epoch: 729 Train loss: 0.026733 Validation loss: 0.040989\n",
            "Epoch: 730 Train loss: 0.026871 Validation loss: 0.021691\n",
            "Epoch: 731 Train loss: 0.02671 Validation loss: 0.04096\n",
            "Epoch: 732 Train loss: 0.026847 Validation loss: 0.021667\n",
            "Epoch: 733 Train loss: 0.026687 Validation loss: 0.040931\n",
            "Epoch: 734 Train loss: 0.026823 Validation loss: 0.021644\n",
            "Epoch: 735 Train loss: 0.026664 Validation loss: 0.040902\n",
            "Epoch: 736 Train loss: 0.026798 Validation loss: 0.021621\n",
            "Epoch: 737 Train loss: 0.026641 Validation loss: 0.040874\n",
            "Epoch: 738 Train loss: 0.026775 Validation loss: 0.021599\n",
            "Epoch: 739 Train loss: 0.026618 Validation loss: 0.040843\n",
            "Epoch: 740 Train loss: 0.02675 Validation loss: 0.021575\n",
            "Epoch: 741 Train loss: 0.026596 Validation loss: 0.040814\n",
            "Epoch: 742 Train loss: 0.026726 Validation loss: 0.021553\n",
            "Epoch: 743 Train loss: 0.026573 Validation loss: 0.040785\n",
            "Epoch: 744 Train loss: 0.026702 Validation loss: 0.021531\n",
            "Epoch: 745 Train loss: 0.02655 Validation loss: 0.040755\n",
            "Epoch: 746 Train loss: 0.026679 Validation loss: 0.021509\n",
            "Epoch: 747 Train loss: 0.026528 Validation loss: 0.040725\n",
            "Epoch: 748 Train loss: 0.026655 Validation loss: 0.021486\n",
            "Epoch: 749 Train loss: 0.026505 Validation loss: 0.040694\n",
            "Epoch: 750 Train loss: 0.026631 Validation loss: 0.021464\n",
            "Epoch: 751 Train loss: 0.026483 Validation loss: 0.040663\n",
            "Epoch: 752 Train loss: 0.026607 Validation loss: 0.021443\n",
            "Epoch: 753 Train loss: 0.02646 Validation loss: 0.040632\n",
            "Epoch: 754 Train loss: 0.026584 Validation loss: 0.021421\n",
            "Epoch: 755 Train loss: 0.026438 Validation loss: 0.040601\n",
            "Epoch: 756 Train loss: 0.02656 Validation loss: 0.0214\n",
            "Epoch: 757 Train loss: 0.026416 Validation loss: 0.04057\n",
            "Epoch: 758 Train loss: 0.026536 Validation loss: 0.021378\n",
            "Epoch: 759 Train loss: 0.026394 Validation loss: 0.040539\n",
            "Epoch: 760 Train loss: 0.026513 Validation loss: 0.021357\n",
            "Epoch: 761 Train loss: 0.026371 Validation loss: 0.040507\n",
            "Epoch: 762 Train loss: 0.026489 Validation loss: 0.021336\n",
            "Epoch: 763 Train loss: 0.026349 Validation loss: 0.040476\n",
            "Epoch: 764 Train loss: 0.026466 Validation loss: 0.021315\n",
            "Epoch: 765 Train loss: 0.026327 Validation loss: 0.040443\n",
            "Epoch: 766 Train loss: 0.026442 Validation loss: 0.021294\n",
            "Epoch: 767 Train loss: 0.026305 Validation loss: 0.040411\n",
            "Epoch: 768 Train loss: 0.026419 Validation loss: 0.021273\n",
            "Epoch: 769 Train loss: 0.026283 Validation loss: 0.040379\n",
            "Epoch: 770 Train loss: 0.026396 Validation loss: 0.021252\n",
            "Epoch: 771 Train loss: 0.026261 Validation loss: 0.040346\n",
            "Epoch: 772 Train loss: 0.026373 Validation loss: 0.021232\n",
            "Epoch: 773 Train loss: 0.026239 Validation loss: 0.040313\n",
            "Epoch: 774 Train loss: 0.02635 Validation loss: 0.02121\n",
            "Epoch: 775 Train loss: 0.026218 Validation loss: 0.04028\n",
            "Epoch: 776 Train loss: 0.026327 Validation loss: 0.021191\n",
            "Epoch: 777 Train loss: 0.026196 Validation loss: 0.040249\n",
            "Epoch: 778 Train loss: 0.026304 Validation loss: 0.02117\n",
            "Epoch: 779 Train loss: 0.026175 Validation loss: 0.040215\n",
            "Epoch: 780 Train loss: 0.026281 Validation loss: 0.02115\n",
            "Epoch: 781 Train loss: 0.026153 Validation loss: 0.040181\n",
            "Epoch: 782 Train loss: 0.026259 Validation loss: 0.02113\n",
            "Epoch: 783 Train loss: 0.026131 Validation loss: 0.040148\n",
            "Epoch: 784 Train loss: 0.026236 Validation loss: 0.021111\n",
            "Epoch: 785 Train loss: 0.02611 Validation loss: 0.040115\n",
            "Epoch: 786 Train loss: 0.026213 Validation loss: 0.021089\n",
            "Epoch: 787 Train loss: 0.026089 Validation loss: 0.040081\n",
            "Epoch: 788 Train loss: 0.026191 Validation loss: 0.02107\n",
            "Epoch: 789 Train loss: 0.026068 Validation loss: 0.040047\n",
            "Epoch: 790 Train loss: 0.026168 Validation loss: 0.021049\n",
            "Epoch: 791 Train loss: 0.026046 Validation loss: 0.040013\n",
            "Epoch: 792 Train loss: 0.026146 Validation loss: 0.02103\n",
            "Epoch: 793 Train loss: 0.026026 Validation loss: 0.039979\n",
            "Epoch: 794 Train loss: 0.026124 Validation loss: 0.02101\n",
            "Epoch: 795 Train loss: 0.026005 Validation loss: 0.039945\n",
            "Epoch: 796 Train loss: 0.026102 Validation loss: 0.02099\n",
            "Epoch: 797 Train loss: 0.025984 Validation loss: 0.039911\n",
            "Epoch: 798 Train loss: 0.02608 Validation loss: 0.02097\n",
            "Epoch: 799 Train loss: 0.025963 Validation loss: 0.039877\n",
            "Epoch: 800 Train loss: 0.026058 Validation loss: 0.020951\n",
            "Epoch: 801 Train loss: 0.025942 Validation loss: 0.039843\n",
            "Epoch: 802 Train loss: 0.026036 Validation loss: 0.020931\n",
            "Epoch: 803 Train loss: 0.025922 Validation loss: 0.039808\n",
            "Epoch: 804 Train loss: 0.026014 Validation loss: 0.020912\n",
            "Epoch: 805 Train loss: 0.025901 Validation loss: 0.039774\n",
            "Epoch: 806 Train loss: 0.025993 Validation loss: 0.020893\n",
            "Epoch: 807 Train loss: 0.025881 Validation loss: 0.03974\n",
            "Epoch: 808 Train loss: 0.025971 Validation loss: 0.020874\n",
            "Epoch: 809 Train loss: 0.025861 Validation loss: 0.039706\n",
            "Epoch: 810 Train loss: 0.02595 Validation loss: 0.020853\n",
            "Epoch: 811 Train loss: 0.025841 Validation loss: 0.03967\n",
            "Epoch: 812 Train loss: 0.025929 Validation loss: 0.020834\n",
            "Epoch: 813 Train loss: 0.02582 Validation loss: 0.039635\n",
            "Epoch: 814 Train loss: 0.025907 Validation loss: 0.020816\n",
            "Epoch: 815 Train loss: 0.0258 Validation loss: 0.039601\n",
            "Epoch: 816 Train loss: 0.025886 Validation loss: 0.020796\n",
            "Epoch: 817 Train loss: 0.02578 Validation loss: 0.039565\n",
            "Epoch: 818 Train loss: 0.025865 Validation loss: 0.020776\n",
            "Epoch: 819 Train loss: 0.02576 Validation loss: 0.039529\n",
            "Epoch: 820 Train loss: 0.025844 Validation loss: 0.020758\n",
            "Epoch: 821 Train loss: 0.025741 Validation loss: 0.039496\n",
            "Epoch: 822 Train loss: 0.025823 Validation loss: 0.020737\n",
            "Epoch: 823 Train loss: 0.025721 Validation loss: 0.03946\n",
            "Epoch: 824 Train loss: 0.025803 Validation loss: 0.020719\n",
            "Epoch: 825 Train loss: 0.025701 Validation loss: 0.039425\n",
            "Epoch: 826 Train loss: 0.025782 Validation loss: 0.0207\n",
            "Epoch: 827 Train loss: 0.025682 Validation loss: 0.03939\n",
            "Epoch: 828 Train loss: 0.025761 Validation loss: 0.020681\n",
            "Epoch: 829 Train loss: 0.025662 Validation loss: 0.039354\n",
            "Epoch: 830 Train loss: 0.025741 Validation loss: 0.020662\n",
            "Epoch: 831 Train loss: 0.025643 Validation loss: 0.039318\n",
            "Epoch: 832 Train loss: 0.02572 Validation loss: 0.020643\n",
            "Epoch: 833 Train loss: 0.025624 Validation loss: 0.039283\n",
            "Epoch: 834 Train loss: 0.0257 Validation loss: 0.020625\n",
            "Epoch: 835 Train loss: 0.025604 Validation loss: 0.039247\n",
            "Epoch: 836 Train loss: 0.02568 Validation loss: 0.020606\n",
            "Epoch: 837 Train loss: 0.025585 Validation loss: 0.039213\n",
            "Epoch: 838 Train loss: 0.02566 Validation loss: 0.020587\n",
            "Epoch: 839 Train loss: 0.025566 Validation loss: 0.039177\n",
            "Epoch: 840 Train loss: 0.02564 Validation loss: 0.020568\n",
            "Epoch: 841 Train loss: 0.025547 Validation loss: 0.039141\n",
            "Epoch: 842 Train loss: 0.02562 Validation loss: 0.02055\n",
            "Epoch: 843 Train loss: 0.025528 Validation loss: 0.039105\n",
            "Epoch: 844 Train loss: 0.0256 Validation loss: 0.02053\n",
            "Epoch: 845 Train loss: 0.025509 Validation loss: 0.039069\n",
            "Epoch: 846 Train loss: 0.02558 Validation loss: 0.020512\n",
            "Epoch: 847 Train loss: 0.025491 Validation loss: 0.039033\n",
            "Epoch: 848 Train loss: 0.02556 Validation loss: 0.020493\n",
            "Epoch: 849 Train loss: 0.025472 Validation loss: 0.038999\n",
            "Epoch: 850 Train loss: 0.025541 Validation loss: 0.020474\n",
            "Epoch: 851 Train loss: 0.025453 Validation loss: 0.038962\n",
            "Epoch: 852 Train loss: 0.025521 Validation loss: 0.020455\n",
            "Epoch: 853 Train loss: 0.025435 Validation loss: 0.038926\n",
            "Epoch: 854 Train loss: 0.025502 Validation loss: 0.020437\n",
            "Epoch: 855 Train loss: 0.025417 Validation loss: 0.03889\n",
            "Epoch: 856 Train loss: 0.025483 Validation loss: 0.020418\n",
            "Epoch: 857 Train loss: 0.025399 Validation loss: 0.038855\n",
            "Epoch: 858 Train loss: 0.025463 Validation loss: 0.020399\n",
            "Epoch: 859 Train loss: 0.02538 Validation loss: 0.03882\n",
            "Epoch: 860 Train loss: 0.025444 Validation loss: 0.02038\n",
            "Epoch: 861 Train loss: 0.025362 Validation loss: 0.038784\n",
            "Epoch: 862 Train loss: 0.025425 Validation loss: 0.020362\n",
            "Epoch: 863 Train loss: 0.025344 Validation loss: 0.038747\n",
            "Epoch: 864 Train loss: 0.025407 Validation loss: 0.020343\n",
            "Epoch: 865 Train loss: 0.025327 Validation loss: 0.038712\n",
            "Epoch: 866 Train loss: 0.025388 Validation loss: 0.020325\n",
            "Epoch: 867 Train loss: 0.025309 Validation loss: 0.038675\n",
            "Epoch: 868 Train loss: 0.025369 Validation loss: 0.020307\n",
            "Epoch: 869 Train loss: 0.025291 Validation loss: 0.038639\n",
            "Epoch: 870 Train loss: 0.02535 Validation loss: 0.020287\n",
            "Epoch: 871 Train loss: 0.025273 Validation loss: 0.038603\n",
            "Epoch: 872 Train loss: 0.025332 Validation loss: 0.02027\n",
            "Epoch: 873 Train loss: 0.025256 Validation loss: 0.038568\n",
            "Epoch: 874 Train loss: 0.025314 Validation loss: 0.020251\n",
            "Epoch: 875 Train loss: 0.025238 Validation loss: 0.038531\n",
            "Epoch: 876 Train loss: 0.025295 Validation loss: 0.020232\n",
            "Epoch: 877 Train loss: 0.025221 Validation loss: 0.038495\n",
            "Epoch: 878 Train loss: 0.025277 Validation loss: 0.020214\n",
            "Epoch: 879 Train loss: 0.025204 Validation loss: 0.03846\n",
            "Epoch: 880 Train loss: 0.025259 Validation loss: 0.020195\n",
            "Epoch: 881 Train loss: 0.025186 Validation loss: 0.038423\n",
            "Epoch: 882 Train loss: 0.025241 Validation loss: 0.020176\n",
            "Epoch: 883 Train loss: 0.025169 Validation loss: 0.038387\n",
            "Epoch: 884 Train loss: 0.025223 Validation loss: 0.020158\n",
            "Epoch: 885 Train loss: 0.025152 Validation loss: 0.038352\n",
            "Epoch: 886 Train loss: 0.025205 Validation loss: 0.02014\n",
            "Epoch: 887 Train loss: 0.025135 Validation loss: 0.038316\n",
            "Epoch: 888 Train loss: 0.025187 Validation loss: 0.020121\n",
            "Epoch: 889 Train loss: 0.025118 Validation loss: 0.038279\n",
            "Epoch: 890 Train loss: 0.02517 Validation loss: 0.020102\n",
            "Epoch: 891 Train loss: 0.025101 Validation loss: 0.038243\n",
            "Epoch: 892 Train loss: 0.025152 Validation loss: 0.020085\n",
            "Epoch: 893 Train loss: 0.025085 Validation loss: 0.038209\n",
            "Epoch: 894 Train loss: 0.025134 Validation loss: 0.020066\n",
            "Epoch: 895 Train loss: 0.025068 Validation loss: 0.038172\n",
            "Epoch: 896 Train loss: 0.025117 Validation loss: 0.020047\n",
            "Epoch: 897 Train loss: 0.025051 Validation loss: 0.038136\n",
            "Epoch: 898 Train loss: 0.025099 Validation loss: 0.020029\n",
            "Epoch: 899 Train loss: 0.025035 Validation loss: 0.0381\n",
            "Epoch: 900 Train loss: 0.025082 Validation loss: 0.020011\n",
            "Epoch: 901 Train loss: 0.025018 Validation loss: 0.038065\n",
            "Epoch: 902 Train loss: 0.025065 Validation loss: 0.019992\n",
            "Epoch: 903 Train loss: 0.025002 Validation loss: 0.038029\n",
            "Epoch: 904 Train loss: 0.025048 Validation loss: 0.019974\n",
            "Epoch: 905 Train loss: 0.024986 Validation loss: 0.037993\n",
            "Epoch: 906 Train loss: 0.025031 Validation loss: 0.019955\n",
            "Epoch: 907 Train loss: 0.02497 Validation loss: 0.037958\n",
            "Epoch: 908 Train loss: 0.025014 Validation loss: 0.019938\n",
            "Epoch: 909 Train loss: 0.024954 Validation loss: 0.037922\n",
            "Epoch: 910 Train loss: 0.024997 Validation loss: 0.019918\n",
            "Epoch: 911 Train loss: 0.024938 Validation loss: 0.037886\n",
            "Epoch: 912 Train loss: 0.024981 Validation loss: 0.0199\n",
            "Epoch: 913 Train loss: 0.024922 Validation loss: 0.03785\n",
            "Epoch: 914 Train loss: 0.024964 Validation loss: 0.019882\n",
            "Epoch: 915 Train loss: 0.024906 Validation loss: 0.037814\n",
            "Epoch: 916 Train loss: 0.024948 Validation loss: 0.019862\n",
            "Epoch: 917 Train loss: 0.02489 Validation loss: 0.037779\n",
            "Epoch: 918 Train loss: 0.024931 Validation loss: 0.019845\n",
            "Epoch: 919 Train loss: 0.024875 Validation loss: 0.037743\n",
            "Epoch: 920 Train loss: 0.024915 Validation loss: 0.019826\n",
            "Epoch: 921 Train loss: 0.024859 Validation loss: 0.037708\n",
            "Epoch: 922 Train loss: 0.024899 Validation loss: 0.019809\n",
            "Epoch: 923 Train loss: 0.024844 Validation loss: 0.037672\n",
            "Epoch: 924 Train loss: 0.024882 Validation loss: 0.01979\n",
            "Epoch: 925 Train loss: 0.024828 Validation loss: 0.037637\n",
            "Epoch: 926 Train loss: 0.024866 Validation loss: 0.019771\n",
            "Epoch: 927 Train loss: 0.024813 Validation loss: 0.037601\n",
            "Epoch: 928 Train loss: 0.02485 Validation loss: 0.019754\n",
            "Epoch: 929 Train loss: 0.024798 Validation loss: 0.037566\n",
            "Epoch: 930 Train loss: 0.024834 Validation loss: 0.019735\n",
            "Epoch: 931 Train loss: 0.024782 Validation loss: 0.037531\n",
            "Epoch: 932 Train loss: 0.024818 Validation loss: 0.019717\n",
            "Epoch: 933 Train loss: 0.024767 Validation loss: 0.037495\n",
            "Epoch: 934 Train loss: 0.024803 Validation loss: 0.019698\n",
            "Epoch: 935 Train loss: 0.024752 Validation loss: 0.03746\n",
            "Epoch: 936 Train loss: 0.024787 Validation loss: 0.01968\n",
            "Epoch: 937 Train loss: 0.024737 Validation loss: 0.037424\n",
            "Epoch: 938 Train loss: 0.024771 Validation loss: 0.019662\n",
            "Epoch: 939 Train loss: 0.024723 Validation loss: 0.037389\n",
            "Epoch: 940 Train loss: 0.024756 Validation loss: 0.019643\n",
            "Epoch: 941 Train loss: 0.024708 Validation loss: 0.037355\n",
            "Epoch: 942 Train loss: 0.024741 Validation loss: 0.019625\n",
            "Epoch: 943 Train loss: 0.024693 Validation loss: 0.03732\n",
            "Epoch: 944 Train loss: 0.024726 Validation loss: 0.019607\n",
            "Epoch: 945 Train loss: 0.024679 Validation loss: 0.037284\n",
            "Epoch: 946 Train loss: 0.02471 Validation loss: 0.019588\n",
            "Epoch: 947 Train loss: 0.024664 Validation loss: 0.037249\n",
            "Epoch: 948 Train loss: 0.024695 Validation loss: 0.01957\n",
            "Epoch: 949 Train loss: 0.02465 Validation loss: 0.037214\n",
            "Epoch: 950 Train loss: 0.02468 Validation loss: 0.019551\n",
            "Epoch: 951 Train loss: 0.024635 Validation loss: 0.037179\n",
            "Epoch: 952 Train loss: 0.024665 Validation loss: 0.019533\n",
            "Epoch: 953 Train loss: 0.024621 Validation loss: 0.037145\n",
            "Epoch: 954 Train loss: 0.02465 Validation loss: 0.019514\n",
            "Epoch: 955 Train loss: 0.024607 Validation loss: 0.03711\n",
            "Epoch: 956 Train loss: 0.024635 Validation loss: 0.019496\n",
            "Epoch: 957 Train loss: 0.024593 Validation loss: 0.037075\n",
            "Epoch: 958 Train loss: 0.024621 Validation loss: 0.019478\n",
            "Epoch: 959 Train loss: 0.024579 Validation loss: 0.03704\n",
            "Epoch: 960 Train loss: 0.024606 Validation loss: 0.019459\n",
            "Epoch: 961 Train loss: 0.024565 Validation loss: 0.037006\n",
            "Epoch: 962 Train loss: 0.024592 Validation loss: 0.019441\n",
            "Epoch: 963 Train loss: 0.024551 Validation loss: 0.036972\n",
            "Epoch: 964 Train loss: 0.024577 Validation loss: 0.019422\n",
            "Epoch: 965 Train loss: 0.024537 Validation loss: 0.036936\n",
            "Epoch: 966 Train loss: 0.024563 Validation loss: 0.019404\n",
            "Epoch: 967 Train loss: 0.024524 Validation loss: 0.036902\n",
            "Epoch: 968 Train loss: 0.024549 Validation loss: 0.019386\n",
            "Epoch: 969 Train loss: 0.02451 Validation loss: 0.036869\n",
            "Epoch: 970 Train loss: 0.024535 Validation loss: 0.019367\n",
            "Epoch: 971 Train loss: 0.024497 Validation loss: 0.036835\n",
            "Epoch: 972 Train loss: 0.024521 Validation loss: 0.019349\n",
            "Epoch: 973 Train loss: 0.024483 Validation loss: 0.0368\n",
            "Epoch: 974 Train loss: 0.024507 Validation loss: 0.019331\n",
            "Epoch: 975 Train loss: 0.02447 Validation loss: 0.036767\n",
            "Epoch: 976 Train loss: 0.024493 Validation loss: 0.019312\n",
            "Epoch: 977 Train loss: 0.024457 Validation loss: 0.036733\n",
            "Epoch: 978 Train loss: 0.024479 Validation loss: 0.019294\n",
            "Epoch: 979 Train loss: 0.024444 Validation loss: 0.036697\n",
            "Epoch: 980 Train loss: 0.024466 Validation loss: 0.019275\n",
            "Epoch: 981 Train loss: 0.024431 Validation loss: 0.036664\n",
            "Epoch: 982 Train loss: 0.024452 Validation loss: 0.019256\n",
            "Epoch: 983 Train loss: 0.024417 Validation loss: 0.03663\n",
            "Epoch: 984 Train loss: 0.024438 Validation loss: 0.019239\n",
            "Epoch: 985 Train loss: 0.024404 Validation loss: 0.036596\n",
            "Epoch: 986 Train loss: 0.024425 Validation loss: 0.01922\n",
            "Epoch: 987 Train loss: 0.024391 Validation loss: 0.036563\n",
            "Epoch: 988 Train loss: 0.024411 Validation loss: 0.019202\n",
            "Epoch: 989 Train loss: 0.024378 Validation loss: 0.036529\n",
            "Epoch: 990 Train loss: 0.024398 Validation loss: 0.019183\n",
            "Epoch: 991 Train loss: 0.024366 Validation loss: 0.036496\n",
            "Epoch: 992 Train loss: 0.024385 Validation loss: 0.019164\n",
            "Epoch: 993 Train loss: 0.024353 Validation loss: 0.036461\n",
            "Epoch: 994 Train loss: 0.024371 Validation loss: 0.019146\n",
            "Epoch: 995 Train loss: 0.02434 Validation loss: 0.036428\n",
            "Epoch: 996 Train loss: 0.024358 Validation loss: 0.019128\n",
            "Epoch: 997 Train loss: 0.024328 Validation loss: 0.036394\n",
            "Epoch: 998 Train loss: 0.024345 Validation loss: 0.01911\n",
            "Epoch: 999 Train loss: 0.024315 Validation loss: 0.036362\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ylr1C2ovWXbO"
      },
      "source": [
        "During the training of the regularized model we can already notice, that, although there is still a difference between training and validation loss, the validation loss decreases as the training loss dreases. The effect of the regularization becomes even more evident if we plot the predictions of the regularized model and the overfitting model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UdMRV0vAWLmm",
        "outputId": "e3db6e22-f7eb-4c64-e377-d18a7919f444",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "\"\"\" We now want to plot the prediction of the regularized and unregularized big model. \"\"\"\n",
        "\n",
        "y_pred = big_reg_mdl(x)\n",
        "# Predict with \"big_reg_mdl\" on \"x\"\n",
        "y_pred_overfit = big_mdl(x)\n",
        "# Predict with \"reg_mdl\" on \"x\"\n",
        "plt.scatter(x_train_overfit, y_train_overfit)\n",
        "plt.plot(x, y_true)\n",
        "plt.plot(x, y_pred.numpy())\n",
        "plt.plot(x, y_pred_overfit.numpy())\n",
        "plt.legend([\"Target\", \"Regularization\", \"No regularization\", \"Training samples\"])\n",
        "plt.show()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sePQBaGqZzT6"
      },
      "source": [
        "The model with regularization seems to follow the overall trend of the data, while the model without any regularization very precisely fits the training samples. This is espacilly evident in the interval $\\left[0,0.5\\right]$, where the prediction of the unregularized model shows an oscillating behavior. Such oscillations are however not present in the ground truth and therefore undesirable. The regularized model on the other hand is not as flexible as the unregularized model and therefore does not fit the target function well in the interval $\\left[2.25, 3.0\\right]$.\n",
        "\n",
        "## Conclusion\n",
        "In this exercise we revisited the mathematical background for a simple regression task and covered it's practical implementation in Tensorflow 2. We also explored the phenomenon of overfitting and derived different regularizations from a probabilistic perspective. This exercise covers a very simple task with a very basic neural architecture and is intended as a primer for the second part of the regression exercise, which is dealing with a bigger and more realistic problem. In this second part we will consider the problem of estimating the age of a person from a potrait picture."
      ]
    }
  ]
}